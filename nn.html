<!DOCTYPE html>
<html>
<head>
	<title>Final Models - World Cup Predictions Using Neural Networks</title>

	<link rel="icon" href="Assets/favicon.ico">

	<link rel="stylesheet" type="text/css" href="styles.css">

</head>
<body>

	<div id="header">
	<div id="navbar">
	<table>
		<tr>
			<td><a href="index.html">
				Home</a>
				<div class="under"></div>
			</td>
			<td><a href="about.html">
				About</a>
				
			</td>
			<td><a href="dp.html">
				Data and EDA</a>
				
			</td>
			<td><a href="wiggo.html">
				WIGGO</a>
				
			</td>
			<td><a href="wiggofifa.html">
				WIGGO vs. FIFA</a>
				
			</td>
			<td><a href="baseline.html">
				Baseline Models</a>
				
			</td>
			<td><a href="nn.html">
				Final Models</a>
				
			</td>
			<td><a href="comparison.html">
				Comparison</a>
				
			</td>
		</tr>
	</table>


	</div>
	<div id="stripe"></div>
	</div>

	<div id="main">
		<div id="content">
			<h1>Final Models</h1>
			<hr />
			<h2>Outline</h2>
			<ol type="I">
				<li><a href="#section1">Logistic Regression With Penalization</a></li>
				<li><a href="#section2">Ensemble Techniques</a></li>
					<ol type="i">
						<li><a href="#section2i">Bagging</a></li>
						<li><a href="#section2ii">Random Forest</a></li>
						<li><a href="#section2iii">AdaBoost (Boosting)</a></li>
						<li><a href="#section2iv">Combined Ensemble</a></li>
						<li><a href="#section2v">Augmented Ensemble Decision Tree</a></li>
					</ol>
				<li><a href="#section3">Neural Networks</a></li>
				<li><a href="#section4">Summary</a></li>
			</ol>
			<hr />

			<br />
			<h2 id="section1">I. Logistic Regression With Penalization</h2>

				<p>As an extension of a simple multinomial or One-vs-Rest logistic regression model, a new logistic regression model was trained on the combined WIGGO and FIFA data to fit the best decision boundary using a limited subset of predictors. To do this, Ridge Regression was run on the data to add a penalty term to the overall loss function that penalizes the model for having too many predictors.</p>

				<p>Ridge Regression was used on four variations of the combined WIGGO and FIFA dataset:</p>

				<ul>
					<li>All Predictors (including all WIGGO and FIFA rankings and points)</li>
					<li>Only the WIGGO and FIFA rankings</li>
					<li>Only the WIGGO and FIFA points</li>
					<li>The WIGGO and FIFA rankings and points, but no other predictors</li>
				</ul>

				<p>For each regression model, KFold cross-validation was performed using <span class="code_text">RidgeClassifierCV</span> and <span class="code_text">KFold</span> from sklearn. Each time, the cross-validation chose from a list of 16 Ridge shrinkage parameters (lambdas): <span class="code_text">{0.001, 0.005, 0.1, 0.5, 1, 5, 10, 50, 100, 150, 200, 250, 1000, 10000, 50000, 100000}</span>. The results (chosen shrinkage parameters) of the 5-fold cross-validation on each data variation are shown below.</p>

				<ul>
					<li>
						<p>All Predictors:</p>
						<img src="Assets/finalmodels/Shrink1.png" class="code"/>
					</li>
					<li>
						<p>Rankings Only:</p>
						<img src="Assets/finalmodels/Shrink2.png" class="code"/>
					</li>
					<li>
						<p>Points Only:</p>
						<img src="Assets/finalmodels/Shrink3.png" class="code"/>
					</li>
					<li>
						<p>Rankings and Points Only:</p>
						<img src="Assets/finalmodels/Shrink3.png" class="code"/>
					</li>
				</ul>

				<p>Finally, the fitted models were scored against the three sets of data: the training set, which includes all international matches except for the 2018 and 2014 FIFA World Cup matches, the validation set, which includes all matches for the 2014 FIFA World Cup, and the test set, which includes all matches for the 2018 FIFA World Cup (i.e. the project's prediction goal). The accuracy of each model with respect to each dataset can be seen below.</p>


				<img src="Assets/finalmodels/Ridge_Acc.png" class="code"/>

			<br />
			<h2 id="section2">II. Ensemble Techniques</h2>

				<p>ON ALL PREDICTORS</p>

				<div class="subcontent">
					<br />
					<h3 id="section2i">i. Bagging</h3>

						<p>A Bagging model of 25 decision trees with max-depth of 4 predicting on bootsrapped samples of the training set was generated. Since the decision trees were fit on bootstrap samples, only the validation and test set accuracies are shown below.</p>

						<img src="Assets/finalmodels/Bagging_Acc.png" class="code"/>

					<br />
					<h3 id="section2ii">ii. Random Forest</h3>

						<p>As a second ensemble model, a random forest classifier was fit with 25 estimators and a max-depth of 5. While this model performed significantly better than the Bagging model on the validation set (2014 World Cup), it had the same test set accuracy of 54.7%.</p>

						<img src="Assets/finalmodels/RF_Acc.png" class="code"/>

					<br />
					<h3 id="section2iii">iii. AdaBoost (Boosting)</h3>

						<p>Building on the relative success of the random forest, an AdaBoost Boosting classifier was built with a random forest as the base classifier. This boosting model was fit with a max depth ranging from 1 to 4. The classification accuracies of each of the four AdaBoost variations as a function of the number of estimators can be seen below.</p>

						<img src="Assets/finalmodels/RF_Graph.png" class="code"/>

						<p>It is important to note that since the validation set is such a small set of data (Only 64 games are played at a FIFA World Cup), it is possible that the validation accuracy is higher than the training accuracy (as is the case above). While this won't always be the case, it is helpful to know that such variations are possible and that they don't necessarily constitute the theoretical validation accuracy for a larger validation set. The same is true for the test set, as it too only consists of 64 games.</p>

						<p>After reviewing the plot above, it was decided that the final AdaBoost model should have a max-depth of 4, seeing as both the training and validation accuracies were the highest at that depth. Accordingly, the final AdaBoost model was used for prediction, generating the train, validation, and test accuracies seen below. The plot shows the classification accuracy as a function of the number of estimators while the final accuracy printed below the plot gives the accuracies at 100 estimators.</p>

						<img src="Assets/finalmodels/Boosting_Graph.png" class="code"/>
						<img src="Assets/finalmodels/Boosting_Acc.png" class="code"/>


					<br />
					<h3 id="section2iv">iv. Combined Ensemble</h3>

						<p>In an effort to build off of the high accuracies of some of the ensemble methods, a meta-model was fit using the outputs of the Ridge Regression, Bagging, Random Forest, and AdaBoost models as the predictors. The meta-model used a simple logistic regression model to combine the four predictions into an output. While this increased the training and validation accuracies slightly, the test accuracy continued to hover around 55%. This is likely again attributable to the small sample size of the test set, which does not allow for us to measure the accuracy of a model as precisely as a larger test set would.</p>

						<img src="Assets/finalmodels/Ensemble_Acc.png" class="code"/>

						<p>The coefficients of the meta-model confirmed that AdaBoost had been the best prediction method thus far, as its logistic regression coefficient in the meta-model was significantly higher than the other three models.</p>

						<img src="Assets/finalmodels/Ensemble_Graph.png" class="code"/>

					<br />
					<h3 id="section2v">v. Augmented Ensemble Decision Tree</h3>

						<p>The final ensemble model was an augmented ensemble decision tree that included both the original predictors as well as the predictions (for each observation) of each of the four models used in the combined ensemble meta-model (i.e. Ridge Regression, Bagging, Random Forest, and AdaBoost). This model should perform better than the simple combined ensemble, as the model has both the raw match data as well as the predictions from other models. Indeed this augmented ensemble model did perform significantly better than any model before it, with high training, validation, and test accuracies, as can be seen below.</p>

						<img src="Assets/finalmodels/AT_Acc.png" class="code"/>

					<br />
					<h3 id="section2vi">vi. Ensemble Models Summary</h3>
						
						<p>The final classification accuracies for all ensemble models can be seen below.</p>

						<img src="Assets/finalmodels/All_Ensemble_Accuracy_2.png" class="code"/>
				</div>

			<br />
			<h2>III. Neural Networks</h2>

				<p>The final sophisticated model is a fully-trained neural network with a more complicated network architecture than that of the baseline neural network model. Against using the <em>keras</em> python library, a neural network was generated that attempted to match the 37 input nodes (all predictors including either FIFA or WIGGO rankings and points) with a match outcome classification (Home Win, Draw, or Home Loss). The network </p>

			<br />
			<h2>IV. Summary</h2>

				<table class="normal_table">
					<tr>
						<td class="left_align">Data Set</td>
						<td>Ridge Regression</td>
						<td>Bagging</td>
						<td>AdaBoost (Boosting)</td>
						<td>Random Forest</td>
						<td>Combined Ensemble</td>
						<td>Augmented Ensemble</td>
						<td>Neural Network (FIFA)</td>
						<td>Neural Network (WIGGO)</td>
					</tr>
					<tr>
						<td class="left_align">Training</td>
						<td>58.4%</td>
						<td>-</td>
						<td>61.4%</td>
						<td>58.9%</td>
						<td>59.4%</td>
						<td>61.7%</td>
						<td>56.7%</td>
						<td>57.7%</td>
					</tr>
					<tr>
						<td class="left_align">Validation</td>
						<td>57.8%</td>
						<td>46.9%</td>
						<td>64.1%</td>
						<td>59.4%</td>
						<td>60.9%</td>
						<td>64.1%</td>
						<td>56.0%</td>
						<td>58.1%</td>
					</tr>
					<tr>
						<td class="left_align">Test</td>
						<td>59.4%</td>
						<td>54.7%</td>
						<td>56.2%</td>
						<td>54.7%</td>
						<td>54.7%</td>
						<td>56.2%</td>
						<td>55.3%</td>
						<td>57.0%</td>
					</tr>
				</table>

		</div>
	</div>

</body>
</html>
