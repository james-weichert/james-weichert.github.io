{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIFA World Cup Match Predictions Using Neural Networks\n",
    "\n",
    "### CS109A\n",
    "\n",
    "**Nathan Goldberg, Erik Johnsson, James Weichert**\n",
    "\n",
    "**August, 2018**\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import statsmodels as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: International Men's Soccer Matches (2006-2018)\n",
    "\n",
    "### FIFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the match data with the FIFA rankings\n",
    "fifa_df = pd.read_csv(\"nb4a_fifa_updated_wins.csv\", \",\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FT H</th>\n",
       "      <th>FT G</th>\n",
       "      <th>AET H</th>\n",
       "      <th>AET G</th>\n",
       "      <th>Type</th>\n",
       "      <th>HomeAdv</th>\n",
       "      <th>Win</th>\n",
       "      <th>PrevDiffHome1</th>\n",
       "      <th>PrevDiffAway1</th>\n",
       "      <th>PrevDiffHome2</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_home</th>\n",
       "      <th>dist_away</th>\n",
       "      <th>TravelHome</th>\n",
       "      <th>TravelAway</th>\n",
       "      <th>TZDeltaHome</th>\n",
       "      <th>TZDeltaAway</th>\n",
       "      <th>team_a_ranking</th>\n",
       "      <th>team_a_points</th>\n",
       "      <th>team_b_ranking</th>\n",
       "      <th>team_b_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>109.811860</td>\n",
       "      <td>9305.286395</td>\n",
       "      <td>17.045896</td>\n",
       "      <td>72.694317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7737.037490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1289.506248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4613.786111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13064.115395</td>\n",
       "      <td>49.689910</td>\n",
       "      <td>490.153628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>80.068621</td>\n",
       "      <td>8452.618598</td>\n",
       "      <td>14.235933</td>\n",
       "      <td>296.477215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FT H  FT G  AET H  AET G Type  HomeAdv  Win  PrevDiffHome1  PrevDiffAway1  \\\n",
       "0     2     1    NaN    NaN  FSS        1  1.0              1             -1   \n",
       "1     0     0    NaN    NaN  FSS        1  0.0              0              2   \n",
       "2     0     1    NaN    NaN  FSS        1 -1.0             -1             -1   \n",
       "3     1     1    NaN    NaN  FSS        1  0.0              0              0   \n",
       "4     3     0    NaN    NaN  FSS        1  1.0              0              1   \n",
       "\n",
       "   PrevDiffHome2      ...         dist_home     dist_away  TravelHome  \\\n",
       "0              1      ...        109.811860   9305.286395   17.045896   \n",
       "1             -1      ...          0.000000   7737.037490    0.000000   \n",
       "2             -1      ...          0.000000   4613.786111    0.000000   \n",
       "3             -3      ...          0.000000  13064.115395   49.689910   \n",
       "4              7      ...         80.068621   8452.618598   14.235933   \n",
       "\n",
       "    TravelAway  TZDeltaHome  TZDeltaAway  team_a_ranking  team_a_points  \\\n",
       "0    72.694317          0.0     0.000000             3.0            0.0   \n",
       "1  1289.506248          0.0    -1.166667            40.0            0.0   \n",
       "2     0.000000          0.0     0.000000           123.0            0.0   \n",
       "3   490.153628          0.0     0.000000            16.0            0.0   \n",
       "4   296.477215          0.0     0.000000            19.0            0.0   \n",
       "\n",
       "   team_b_ranking  team_b_points  \n",
       "0             4.0            0.0  \n",
       "1            29.0            0.0  \n",
       "2            61.0            0.0  \n",
       "3            64.0            0.0  \n",
       "4            27.0            0.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate into a predictor DataFrame and response variable column\n",
    "y_train_fifa = fifa_df['Win']\n",
    "\n",
    "#Drop the response variable from the predictor DataFrame. Also drop 'Type', as the baseline models will not take\n",
    "#the type of game into account\n",
    "X_train_fifa = fifa_df.drop(['Win', 'FT H', 'FT G', 'AET H', 'AET G'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fifa = pd.concat([X_train_fifa, pd.get_dummies(X_train_fifa['Type'])], axis=1).drop(['Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeAdv</th>\n",
       "      <th>PrevDiffHome1</th>\n",
       "      <th>PrevDiffAway1</th>\n",
       "      <th>PrevDiffHome2</th>\n",
       "      <th>PrevDiffAway2</th>\n",
       "      <th>PrevDiffHome3</th>\n",
       "      <th>PrevDiffAway3</th>\n",
       "      <th>PrevDiffHome4</th>\n",
       "      <th>PrevDiffAway4</th>\n",
       "      <th>PrevDiffHome5</th>\n",
       "      <th>...</th>\n",
       "      <th>team_a_ranking</th>\n",
       "      <th>team_a_points</th>\n",
       "      <th>team_b_ranking</th>\n",
       "      <th>team_b_points</th>\n",
       "      <th>Cont</th>\n",
       "      <th>ContQ</th>\n",
       "      <th>FSS</th>\n",
       "      <th>KFC</th>\n",
       "      <th>WM</th>\n",
       "      <th>WM-Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10875</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>300.29</td>\n",
       "      <td>142.0</td>\n",
       "      <td>193.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10876</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>156.0</td>\n",
       "      <td>138.60</td>\n",
       "      <td>148.0</td>\n",
       "      <td>178.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>8</td>\n",
       "      <td>-8</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>622.63</td>\n",
       "      <td>60.0</td>\n",
       "      <td>560.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>282.94</td>\n",
       "      <td>59.0</td>\n",
       "      <td>563.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>300.29</td>\n",
       "      <td>138.0</td>\n",
       "      <td>215.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>336.22</td>\n",
       "      <td>187.0</td>\n",
       "      <td>53.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>156.0</td>\n",
       "      <td>138.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>178.85</td>\n",
       "      <td>185.0</td>\n",
       "      <td>54.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>350.19</td>\n",
       "      <td>121.0</td>\n",
       "      <td>268.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>560.60</td>\n",
       "      <td>114.0</td>\n",
       "      <td>282.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>622.63</td>\n",
       "      <td>59.0</td>\n",
       "      <td>563.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10887</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>138.0</td>\n",
       "      <td>215.88</td>\n",
       "      <td>74.0</td>\n",
       "      <td>470.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>473.61</td>\n",
       "      <td>79.0</td>\n",
       "      <td>437.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10889</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>282.39</td>\n",
       "      <td>188.0</td>\n",
       "      <td>52.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10890</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>52.30</td>\n",
       "      <td>63.0</td>\n",
       "      <td>543.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10891</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>351.32</td>\n",
       "      <td>73.0</td>\n",
       "      <td>476.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>282.39</td>\n",
       "      <td>79.0</td>\n",
       "      <td>437.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10893</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>328.69</td>\n",
       "      <td>120.0</td>\n",
       "      <td>268.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10894</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>107.0</td>\n",
       "      <td>312.92</td>\n",
       "      <td>88.0</td>\n",
       "      <td>399.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10895</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>351.32</td>\n",
       "      <td>189.0</td>\n",
       "      <td>52.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10896</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>476.21</td>\n",
       "      <td>63.0</td>\n",
       "      <td>543.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10897</th>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>268.05</td>\n",
       "      <td>115.0</td>\n",
       "      <td>282.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10898</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>437.62</td>\n",
       "      <td>102.0</td>\n",
       "      <td>328.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10899</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>543.38</td>\n",
       "      <td>101.0</td>\n",
       "      <td>351.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>52.30</td>\n",
       "      <td>73.0</td>\n",
       "      <td>476.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10901</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>328.69</td>\n",
       "      <td>115.0</td>\n",
       "      <td>282.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>437.62</td>\n",
       "      <td>120.0</td>\n",
       "      <td>268.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10903</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>351.32</td>\n",
       "      <td>115.0</td>\n",
       "      <td>282.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10904</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>437.62</td>\n",
       "      <td>73.0</td>\n",
       "      <td>476.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10905 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomeAdv  PrevDiffHome1  PrevDiffAway1  PrevDiffHome2  PrevDiffAway2  \\\n",
       "0            1              1             -1              1              1   \n",
       "1            1              0              2             -1              0   \n",
       "2            1             -1             -1             -1             -1   \n",
       "3            1              0              0             -3              1   \n",
       "4            1              0              1              7              0   \n",
       "5            1              3              1             -1              0   \n",
       "6            0             -1             -3              0              0   \n",
       "7            0             -2              1              2              0   \n",
       "8            0              0              4              3              0   \n",
       "9            1              0              0              1              1   \n",
       "10           1              2             -3              1              0   \n",
       "11           1              1             -2              2             -1   \n",
       "12           1              0             -1              0              2   \n",
       "13           1             -2              1              0             -3   \n",
       "14           1              0              0             -1             -1   \n",
       "15           0              0             -1              3              4   \n",
       "16           0             -7              3             -2              3   \n",
       "17           0              2              0             -2              0   \n",
       "18           0             -3             -1              1              1   \n",
       "19           1              0              4              0             -3   \n",
       "20           0              1              0              8              2   \n",
       "21           1              1              1              1              2   \n",
       "22           0              3              0              0              2   \n",
       "23           0              1              1              1             -1   \n",
       "24           0              0             -2              0             -2   \n",
       "25           0              0              0              4             -1   \n",
       "26           1              2             -3              1             -1   \n",
       "27           0              2             -1              0              0   \n",
       "28           0              0             -1              1             -1   \n",
       "29           1             -3              3             -7              0   \n",
       "...        ...            ...            ...            ...            ...   \n",
       "10875        1              0             -1              0             -1   \n",
       "10876        0              2              6             -1              0   \n",
       "10877        0              0             -2              0             -5   \n",
       "10878        1              1              0             -1             -4   \n",
       "10879        0             -1              0              3              0   \n",
       "10880        1              1              0              0              3   \n",
       "10881        1              0             -4             -1             -1   \n",
       "10882        0              4             -1              0              2   \n",
       "10883       -1              1             10              6              0   \n",
       "10884        1              2              0              2              0   \n",
       "10885        0             -1             -1              0             -1   \n",
       "10886        1              1              1              1              0   \n",
       "10887        0              0             -1              0              0   \n",
       "10888        1              1              0             -1              1   \n",
       "10889        1              3              0              2             -1   \n",
       "10890        1              0             -1              0             -3   \n",
       "10891        0              1              1              2              1   \n",
       "10892        0              0             -1              3              0   \n",
       "10893        0             -1             -1              0              0   \n",
       "10894        1              1              1              0              0   \n",
       "10895       -1             -1             -1              1              0   \n",
       "10896        0              1              1              1             -1   \n",
       "10897        0             -4              0             -1              0   \n",
       "10898        0              0              4             -1             -1   \n",
       "10899        0              0              1              1             -1   \n",
       "10900        1             -1              0             -1              1   \n",
       "10901        0             -1              1              4              0   \n",
       "10902        0              1             -1              0             -4   \n",
       "10903        0              2              0              1              1   \n",
       "10904        0              3              0              1              0   \n",
       "\n",
       "       PrevDiffHome3  PrevDiffAway3  PrevDiffHome4  PrevDiffAway4  \\\n",
       "0                 -2              1              0              1   \n",
       "1                 -5              1             -1              1   \n",
       "2                  3             -2             -2             -2   \n",
       "3                  0              1              0              3   \n",
       "4                  3              0             -3              0   \n",
       "5                  0              2             -3              1   \n",
       "6                 -1             -1             -3              2   \n",
       "7                  4              0             -1              0   \n",
       "8                  0              1              2              0   \n",
       "9                  0              3              4              2   \n",
       "10                 1             -5              1              1   \n",
       "11                 0              0              1              2   \n",
       "12                 2             -1             -2             -2   \n",
       "13                -4              0             -2              0   \n",
       "14                -1              2             -1              0   \n",
       "15                 1             -1              4              1   \n",
       "16                -1              0             -2              2   \n",
       "17                 1             -1             -3              0   \n",
       "18                 0              0              0              0   \n",
       "19                -3             -2              0              3   \n",
       "20                 3             -2              0             -1   \n",
       "21                 1              1             -2             -1   \n",
       "22                -1              0             -1              1   \n",
       "23                 0             -1              0              1   \n",
       "24                -1              0              1              0   \n",
       "25                 0              0              1             -1   \n",
       "26                -1              2              0             -1   \n",
       "27                 1              3              0              1   \n",
       "28                 2             -1              1              3   \n",
       "29                -2              4             -1              0   \n",
       "...              ...            ...            ...            ...   \n",
       "10875              2              0             -1              0   \n",
       "10876             -1              8              0              0   \n",
       "10877              8             -8             -2             -3   \n",
       "10878             -2             -2              0              1   \n",
       "10879              3              1             -5             -2   \n",
       "10880              0              0              2             -1   \n",
       "10881             -1             -8              2             -2   \n",
       "10882              0             -1              8             -1   \n",
       "10883              0              5              8              1   \n",
       "10884              0              0              5              0   \n",
       "10885             -4              3             -2              3   \n",
       "10886             -1              0             -2              1   \n",
       "10887              3              4              0              0   \n",
       "10888             -1              1              1              1   \n",
       "10889             -1              2              5              9   \n",
       "10890             -1              2              2              3   \n",
       "10891              2             -1              0             -1   \n",
       "10892              2              1             -1              1   \n",
       "10893             -1              0             -1              0   \n",
       "10894              0              0              3              0   \n",
       "10895              2              0              2             -1   \n",
       "10896              1             -3             -1              2   \n",
       "10897              0              3              0              2   \n",
       "10898              0              0              1             -1   \n",
       "10899             -1              1             -3              2   \n",
       "10900              0              1              0              1   \n",
       "10901             -1              0              0              3   \n",
       "10902             -1             -1              0              0   \n",
       "10903             -1              0              1              0   \n",
       "10904              0              1             -1              1   \n",
       "\n",
       "       PrevDiffHome5  ...   team_a_ranking  team_a_points  team_b_ranking  \\\n",
       "0                  2  ...              3.0           0.00             4.0   \n",
       "1                 -1  ...             40.0           0.00            29.0   \n",
       "2                  0  ...            123.0           0.00            61.0   \n",
       "3                  0  ...             16.0           0.00            64.0   \n",
       "4                  0  ...             19.0           0.00            27.0   \n",
       "5                  2  ...             21.0           0.00            22.0   \n",
       "6                 -1  ...             86.0           0.00            65.0   \n",
       "7                  1  ...             57.0           0.00            14.0   \n",
       "8                  1  ...             13.0           0.00            45.0   \n",
       "9                  6  ...              5.0           0.00            17.0   \n",
       "10                 1  ...             10.0           0.00            46.0   \n",
       "11                 1  ...              2.0           0.00            47.0   \n",
       "12                 2  ...             35.0           0.00            68.0   \n",
       "13                -3  ...            192.0           0.00           116.0   \n",
       "14                -2  ...            127.0           0.00            92.0   \n",
       "15                -2  ...             23.0           0.00            29.0   \n",
       "16                -4  ...            152.0           0.00             7.0   \n",
       "17                -1  ...             71.0           0.00            32.0   \n",
       "18                 0  ...             27.0           0.00            36.0   \n",
       "19                -3  ...             87.0           0.00            97.0   \n",
       "20                 5  ...              1.0           0.00           118.0   \n",
       "21                 0  ...              3.0           0.00            42.0   \n",
       "22                 1  ...             48.0           0.00            29.0   \n",
       "23                 0  ...             14.0           0.00            91.0   \n",
       "24                 0  ...             18.0           0.00           125.0   \n",
       "25                 0  ...             45.0           0.00            86.0   \n",
       "26                 1  ...              8.0           0.00            68.0   \n",
       "27                 4  ...              5.0           0.00            23.0   \n",
       "28                -1  ...             42.0           0.00           123.0   \n",
       "29                -2  ...            152.0           0.00            45.0   \n",
       "...              ...  ...              ...            ...             ...   \n",
       "10875             -1  ...            111.0         300.29           142.0   \n",
       "10876              1  ...            156.0         138.60           148.0   \n",
       "10877              0  ...            178.0          93.44           206.0   \n",
       "10878              1  ...             55.0         622.63            60.0   \n",
       "10879              0  ...            114.0         282.94            59.0   \n",
       "10880             -1  ...            111.0         300.29           138.0   \n",
       "10881             -1  ...            102.0         336.22           187.0   \n",
       "10882             -2  ...            178.0          93.44           156.0   \n",
       "10883              0  ...            148.0         178.85           185.0   \n",
       "10884              2  ...            101.0         350.19           121.0   \n",
       "10885              1  ...             60.0         560.60           114.0   \n",
       "10886              0  ...             55.0         622.63            59.0   \n",
       "10887             -1  ...            138.0         215.88            74.0   \n",
       "10888              0  ...             73.0         473.61            79.0   \n",
       "10889              0  ...            115.0         282.39           188.0   \n",
       "10890              9  ...            189.0          52.30            63.0   \n",
       "10891              5  ...            101.0         351.32            73.0   \n",
       "10892              5  ...            115.0         282.39            79.0   \n",
       "10893              2  ...            102.0         328.69           120.0   \n",
       "10894              0  ...            107.0         312.92            88.0   \n",
       "10895              0  ...            101.0         351.32           189.0   \n",
       "10896             -1  ...             73.0         476.21            63.0   \n",
       "10897              0  ...            120.0         268.05           115.0   \n",
       "10898              1  ...             79.0         437.62           102.0   \n",
       "10899              2  ...             63.0         543.38           101.0   \n",
       "10900             -1  ...            189.0          52.30            73.0   \n",
       "10901             -1  ...            102.0         328.69           115.0   \n",
       "10902              1  ...             79.0         437.62           120.0   \n",
       "10903              2  ...            101.0         351.32           115.0   \n",
       "10904              0  ...             79.0         437.62            73.0   \n",
       "\n",
       "       team_b_points  Cont  ContQ  FSS  KFC  WM  WM-Q  \n",
       "0               0.00     0      0    1    0   0     0  \n",
       "1               0.00     0      0    1    0   0     0  \n",
       "2               0.00     0      0    1    0   0     0  \n",
       "3               0.00     0      0    1    0   0     0  \n",
       "4               0.00     0      0    1    0   0     0  \n",
       "5               0.00     0      0    1    0   0     0  \n",
       "6               0.00     0      0    1    0   0     0  \n",
       "7               0.00     0      0    1    0   0     0  \n",
       "8               0.00     0      0    1    0   0     0  \n",
       "9               0.00     0      0    1    0   0     0  \n",
       "10              0.00     0      0    1    0   0     0  \n",
       "11              0.00     0      0    1    0   0     0  \n",
       "12              0.00     0      0    1    0   0     0  \n",
       "13              0.00     0      0    1    0   0     0  \n",
       "14              0.00     0      0    1    0   0     0  \n",
       "15              0.00     0      0    1    0   0     0  \n",
       "16              0.00     0      0    1    0   0     0  \n",
       "17              0.00     0      0    1    0   0     0  \n",
       "18              0.00     0      0    1    0   0     0  \n",
       "19              0.00     0      0    1    0   0     0  \n",
       "20              0.00     0      0    1    0   0     0  \n",
       "21              0.00     0      0    1    0   0     0  \n",
       "22              0.00     0      0    1    0   0     0  \n",
       "23              0.00     0      0    1    0   0     0  \n",
       "24              0.00     0      0    1    0   0     0  \n",
       "25              0.00     0      0    1    0   0     0  \n",
       "26              0.00     0      0    1    0   0     0  \n",
       "27              0.00     0      0    1    0   0     0  \n",
       "28              0.00     0      0    1    0   0     0  \n",
       "29              0.00     0      0    1    0   0     0  \n",
       "...              ...   ...    ...  ...  ...  ..   ...  \n",
       "10875         193.47     0      0    1    0   0     0  \n",
       "10876         178.85     0      0    1    0   0     0  \n",
       "10877           0.00     0      0    1    0   0     0  \n",
       "10878         560.60     0      0    1    0   0     0  \n",
       "10879         563.00     0      0    1    0   0     0  \n",
       "10880         215.88     0      0    1    0   0     0  \n",
       "10881          53.92     0      0    1    0   0     0  \n",
       "10882         138.60     0      0    1    0   0     0  \n",
       "10883          54.82     0      0    1    0   0     0  \n",
       "10884         268.05     0      0    1    0   0     0  \n",
       "10885         282.94     0      0    1    0   0     0  \n",
       "10886         563.00     0      0    1    0   0     0  \n",
       "10887         470.95     0      0    1    0   0     0  \n",
       "10888         437.62     0      0    1    0   0     0  \n",
       "10889          52.30     0      0    1    0   0     0  \n",
       "10890         543.38     0      0    1    0   0     0  \n",
       "10891         476.21     0      0    1    0   0     0  \n",
       "10892         437.62     0      0    1    0   0     0  \n",
       "10893         268.05     0      0    1    0   0     0  \n",
       "10894         399.01     0      0    1    0   0     0  \n",
       "10895          52.30     0      0    1    0   0     0  \n",
       "10896         543.38     0      0    1    0   0     0  \n",
       "10897         282.39     0      0    1    0   0     0  \n",
       "10898         328.69     0      0    1    0   0     0  \n",
       "10899         351.32     0      0    1    0   0     0  \n",
       "10900         476.21     0      0    1    0   0     0  \n",
       "10901         282.39     0      0    1    0   0     0  \n",
       "10902         268.05     0      0    1    0   0     0  \n",
       "10903         282.39     0      0    1    0   0     0  \n",
       "10904         476.21     0      0    1    0   0     0  \n",
       "\n",
       "[10905 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fifa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_fifa = pd.DataFrame(y_train_fifa)\n",
    "\n",
    "#Make a copy of the current state of y_train for use in Logistic Regression (which requires a different kind of \n",
    "#categorical encoding than the neural network)\n",
    "y_train_fifa_cat = y_train_fifa.copy()\n",
    "\n",
    "W = np.array(np.zeros(len(y_train_fifa)))\n",
    "D = np.array(np.zeros(len(y_train_fifa)))\n",
    "L = np.array(np.zeros(len(y_train_fifa)))\n",
    "\n",
    "#Convert the {-1, 0, 1} values in the response variable to one-hot encoded columns for win (home win), draw, and loss\n",
    "#(away win)\n",
    "for y in range(len(y_train_fifa)):\n",
    "    if y_train_fifa.iloc[y].Win == 1:\n",
    "        W[y] = 1\n",
    "    elif y_train_fifa.iloc[y].Win == 0:\n",
    "        D[y] = 1\n",
    "    elif y_train_fifa.iloc[y].Win == -1:\n",
    "        L[y] = 1\n",
    "\n",
    "#Add the one-hot encoded columns to the response variable DataFrame and delete the original 'Win' column\n",
    "y_train_fifa['W'] = W\n",
    "y_train_fifa['D'] = D\n",
    "y_train_fifa['L'] = L\n",
    "\n",
    "y_train_fifa = y_train_fifa.drop(['Win'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>D</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10875</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10891</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10892</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10893</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10894</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10896</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10898</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10899</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10903</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10904</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10905 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         W    D    L\n",
       "0      1.0  0.0  0.0\n",
       "1      0.0  1.0  0.0\n",
       "2      0.0  0.0  1.0\n",
       "3      0.0  1.0  0.0\n",
       "4      1.0  0.0  0.0\n",
       "5      0.0  1.0  0.0\n",
       "6      0.0  1.0  0.0\n",
       "7      0.0  0.0  1.0\n",
       "8      0.0  1.0  0.0\n",
       "9      1.0  0.0  0.0\n",
       "10     1.0  0.0  0.0\n",
       "11     1.0  0.0  0.0\n",
       "12     1.0  0.0  0.0\n",
       "13     0.0  1.0  0.0\n",
       "14     0.0  1.0  0.0\n",
       "15     0.0  0.0  1.0\n",
       "16     0.0  0.0  1.0\n",
       "17     0.0  0.0  1.0\n",
       "18     1.0  0.0  0.0\n",
       "19     1.0  0.0  0.0\n",
       "20     1.0  0.0  0.0\n",
       "21     0.0  1.0  0.0\n",
       "22     1.0  0.0  0.0\n",
       "23     0.0  0.0  1.0\n",
       "24     1.0  0.0  0.0\n",
       "25     1.0  0.0  0.0\n",
       "26     1.0  0.0  0.0\n",
       "27     1.0  0.0  0.0\n",
       "28     1.0  0.0  0.0\n",
       "29     0.0  0.0  1.0\n",
       "...    ...  ...  ...\n",
       "10875  1.0  0.0  0.0\n",
       "10876  0.0  0.0  1.0\n",
       "10877  1.0  0.0  0.0\n",
       "10878  1.0  0.0  0.0\n",
       "10879  0.0  0.0  1.0\n",
       "10880  1.0  0.0  0.0\n",
       "10881  0.0  0.0  1.0\n",
       "10882  1.0  0.0  0.0\n",
       "10883  0.0  0.0  1.0\n",
       "10884  1.0  0.0  0.0\n",
       "10885  0.0  1.0  0.0\n",
       "10886  0.0  0.0  1.0\n",
       "10887  0.0  0.0  1.0\n",
       "10888  1.0  0.0  0.0\n",
       "10889  0.0  1.0  0.0\n",
       "10890  0.0  0.0  1.0\n",
       "10891  0.0  0.0  1.0\n",
       "10892  0.0  1.0  0.0\n",
       "10893  1.0  0.0  0.0\n",
       "10894  0.0  1.0  0.0\n",
       "10895  1.0  0.0  0.0\n",
       "10896  0.0  1.0  0.0\n",
       "10897  0.0  0.0  1.0\n",
       "10898  1.0  0.0  0.0\n",
       "10899  0.0  0.0  1.0\n",
       "10900  0.0  1.0  0.0\n",
       "10901  0.0  1.0  0.0\n",
       "10902  1.0  0.0  0.0\n",
       "10903  1.0  0.0  0.0\n",
       "10904  0.0  1.0  0.0\n",
       "\n",
       "[10905 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_fifa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### WIGGO\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the match data with the FIFA rankings\n",
    "wiggo_df = pd.read_csv(\"nb4b_wiggo_updated_wins.csv\", \",\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FT H</th>\n",
       "      <th>FT G</th>\n",
       "      <th>AET H</th>\n",
       "      <th>AET G</th>\n",
       "      <th>Type</th>\n",
       "      <th>HomeAdv</th>\n",
       "      <th>Win</th>\n",
       "      <th>PrevDiffHome1</th>\n",
       "      <th>PrevDiffAway1</th>\n",
       "      <th>PrevDiffHome2</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_home</th>\n",
       "      <th>dist_away</th>\n",
       "      <th>TravelHome</th>\n",
       "      <th>TravelAway</th>\n",
       "      <th>TZDeltaHome</th>\n",
       "      <th>TZDeltaAway</th>\n",
       "      <th>team_a_ranking</th>\n",
       "      <th>team_a_points</th>\n",
       "      <th>team_b_ranking</th>\n",
       "      <th>team_b_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>109.811860</td>\n",
       "      <td>9305.286395</td>\n",
       "      <td>17.045896</td>\n",
       "      <td>72.694317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1828.100435</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1764.714989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7737.037490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1289.506248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1659.123301</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1661.105272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4613.786111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1267.787070</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1504.624820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13064.115395</td>\n",
       "      <td>49.689910</td>\n",
       "      <td>490.153628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1754.982681</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1619.366237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>80.068621</td>\n",
       "      <td>8452.618598</td>\n",
       "      <td>14.235933</td>\n",
       "      <td>296.477215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1767.390337</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1670.498015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FT H  FT G  AET H  AET G Type  HomeAdv  Win  PrevDiffHome1  PrevDiffAway1  \\\n",
       "0     2     1    NaN    NaN  FSS        1  1.0              1             -1   \n",
       "1     0     0    NaN    NaN  FSS        1  0.0              0              2   \n",
       "2     0     1    NaN    NaN  FSS        1 -1.0             -1             -1   \n",
       "3     1     1    NaN    NaN  FSS        1  0.0              0              0   \n",
       "4     3     0    NaN    NaN  FSS        1  1.0              0              1   \n",
       "\n",
       "   PrevDiffHome2      ...         dist_home     dist_away  TravelHome  \\\n",
       "0              1      ...        109.811860   9305.286395   17.045896   \n",
       "1             -1      ...          0.000000   7737.037490    0.000000   \n",
       "2             -1      ...          0.000000   4613.786111    0.000000   \n",
       "3             -3      ...          0.000000  13064.115395   49.689910   \n",
       "4              7      ...         80.068621   8452.618598   14.235933   \n",
       "\n",
       "    TravelAway  TZDeltaHome  TZDeltaAway  team_a_ranking  team_a_points  \\\n",
       "0    72.694317          0.0     0.000000             3.0    1828.100435   \n",
       "1  1289.506248          0.0    -1.166667            39.0    1659.123301   \n",
       "2     0.000000          0.0     0.000000           168.0    1267.787070   \n",
       "3   490.153628          0.0     0.000000            13.0    1754.982681   \n",
       "4   296.477215          0.0     0.000000            10.0    1767.390337   \n",
       "\n",
       "   team_b_ranking  team_b_points  \n",
       "0            11.0    1764.714989  \n",
       "1            38.0    1661.105272  \n",
       "2            87.0    1504.624820  \n",
       "3            49.0    1619.366237  \n",
       "4            36.0    1670.498015  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiggo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate into a predictor DataFrame and response variable column\n",
    "y_train_wiggo = wiggo_df['Win']\n",
    "\n",
    "#Drop the response variable from the predictor DataFrame. Also drop 'Type', as the baseline models will not take\n",
    "#the type of game into account\n",
    "X_train_wiggo = wiggo_df.drop(['Win', 'FT H', 'FT G', 'AET H', 'AET G'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wiggo = pd.concat([X_train_wiggo, pd.get_dummies(X_train_wiggo['Type'])], axis=1).drop(['Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_wiggo = pd.DataFrame(y_train_wiggo)\n",
    "\n",
    "#Make a copy of the current state of y_train for use in Logistic Regression (which requires a different kind of \n",
    "#categorical encoding than the neural network)\n",
    "y_train_wiggo_cat = y_train_wiggo.copy()\n",
    "\n",
    "W = np.array(np.zeros(len(y_train_wiggo)))\n",
    "D = np.array(np.zeros(len(y_train_wiggo)))\n",
    "L = np.array(np.zeros(len(y_train_wiggo)))\n",
    "\n",
    "#Convert the {0, 0.5, 1} values in the response variable to one-hot encoded columns for win (home win), draw, and loss\n",
    "#(away win)\n",
    "for y in range(len(y_train_wiggo)):\n",
    "    if y_train_wiggo.iloc[y].Win == 1:\n",
    "        W[y] = 1\n",
    "    elif y_train_wiggo.iloc[y].Win == 0:\n",
    "        D[y] = 1\n",
    "    elif y_train_wiggo.iloc[y].Win == -1:\n",
    "        L[y] = 1\n",
    "\n",
    "#Add the one-hot encoded columns to the response variable DataFrame and delete the original 'Win' column\n",
    "y_train_wiggo['W'] = W\n",
    "y_train_wiggo['D'] = D\n",
    "y_train_wiggo['L'] = L\n",
    "\n",
    "y_train_wiggo = y_train_wiggo.drop(['Win'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>D</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10875</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10891</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10892</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10893</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10894</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10896</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10898</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10899</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10903</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10904</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10905 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         W    D    L\n",
       "0      1.0  0.0  0.0\n",
       "1      0.0  1.0  0.0\n",
       "2      0.0  0.0  1.0\n",
       "3      0.0  1.0  0.0\n",
       "4      1.0  0.0  0.0\n",
       "5      0.0  1.0  0.0\n",
       "6      0.0  1.0  0.0\n",
       "7      0.0  0.0  1.0\n",
       "8      0.0  1.0  0.0\n",
       "9      1.0  0.0  0.0\n",
       "10     1.0  0.0  0.0\n",
       "11     1.0  0.0  0.0\n",
       "12     1.0  0.0  0.0\n",
       "13     0.0  1.0  0.0\n",
       "14     0.0  1.0  0.0\n",
       "15     0.0  0.0  1.0\n",
       "16     0.0  0.0  1.0\n",
       "17     0.0  0.0  1.0\n",
       "18     1.0  0.0  0.0\n",
       "19     1.0  0.0  0.0\n",
       "20     1.0  0.0  0.0\n",
       "21     0.0  1.0  0.0\n",
       "22     1.0  0.0  0.0\n",
       "23     0.0  0.0  1.0\n",
       "24     1.0  0.0  0.0\n",
       "25     1.0  0.0  0.0\n",
       "26     1.0  0.0  0.0\n",
       "27     1.0  0.0  0.0\n",
       "28     1.0  0.0  0.0\n",
       "29     0.0  0.0  1.0\n",
       "...    ...  ...  ...\n",
       "10875  1.0  0.0  0.0\n",
       "10876  0.0  0.0  1.0\n",
       "10877  1.0  0.0  0.0\n",
       "10878  1.0  0.0  0.0\n",
       "10879  0.0  0.0  1.0\n",
       "10880  1.0  0.0  0.0\n",
       "10881  0.0  0.0  1.0\n",
       "10882  1.0  0.0  0.0\n",
       "10883  0.0  0.0  1.0\n",
       "10884  1.0  0.0  0.0\n",
       "10885  0.0  1.0  0.0\n",
       "10886  0.0  0.0  1.0\n",
       "10887  0.0  0.0  1.0\n",
       "10888  1.0  0.0  0.0\n",
       "10889  0.0  1.0  0.0\n",
       "10890  0.0  0.0  1.0\n",
       "10891  0.0  0.0  1.0\n",
       "10892  0.0  1.0  0.0\n",
       "10893  1.0  0.0  0.0\n",
       "10894  0.0  1.0  0.0\n",
       "10895  1.0  0.0  0.0\n",
       "10896  0.0  1.0  0.0\n",
       "10897  0.0  0.0  1.0\n",
       "10898  1.0  0.0  0.0\n",
       "10899  0.0  0.0  1.0\n",
       "10900  0.0  1.0  0.0\n",
       "10901  0.0  1.0  0.0\n",
       "10902  1.0  0.0  0.0\n",
       "10903  1.0  0.0  0.0\n",
       "10904  0.0  1.0  0.0\n",
       "\n",
       "[10905 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_wiggo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### World Cup Test Data (FIFA)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>HomeAdv</th>\n",
       "      <th>Win</th>\n",
       "      <th>PrevDiffHome1</th>\n",
       "      <th>PrevDiffAway1</th>\n",
       "      <th>PrevDiffHome2</th>\n",
       "      <th>PrevDiffAway2</th>\n",
       "      <th>PrevDiffHome3</th>\n",
       "      <th>PrevDiffAway3</th>\n",
       "      <th>PrevDiffHome4</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_home</th>\n",
       "      <th>dist_away</th>\n",
       "      <th>TravelHome</th>\n",
       "      <th>TravelAway</th>\n",
       "      <th>TZDeltaHome</th>\n",
       "      <th>TZDeltaAway</th>\n",
       "      <th>team_a_ranking</th>\n",
       "      <th>team_a_points</th>\n",
       "      <th>team_b_ranking</th>\n",
       "      <th>team_b_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14248</th>\n",
       "      <td>WM</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3534.539231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>347.574603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>456.53</td>\n",
       "      <td>67</td>\n",
       "      <td>465.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14249</th>\n",
       "      <td>WM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3750.413399</td>\n",
       "      <td>14770.693705</td>\n",
       "      <td>405.969902</td>\n",
       "      <td>1846.336713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>649.43</td>\n",
       "      <td>14</td>\n",
       "      <td>1018.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14250</th>\n",
       "      <td>WM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4224.038712</td>\n",
       "      <td>3092.755264</td>\n",
       "      <td>53.101968</td>\n",
       "      <td>90.878998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>685.86</td>\n",
       "      <td>211</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14251</th>\n",
       "      <td>WM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>4077.831369</td>\n",
       "      <td>3573.971457</td>\n",
       "      <td>509.728921</td>\n",
       "      <td>28.632563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1273.69</td>\n",
       "      <td>10</td>\n",
       "      <td>1125.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14252</th>\n",
       "      <td>WM</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3214.759841</td>\n",
       "      <td>13767.992688</td>\n",
       "      <td>464.575231</td>\n",
       "      <td>322.033967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1198.13</td>\n",
       "      <td>36</td>\n",
       "      <td>718.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type  HomeAdv  Win  PrevDiffHome1  PrevDiffAway1  PrevDiffHome2  \\\n",
       "14248   WM        0  1.0              0             -1             -1   \n",
       "14249   WM        0  0.0             -3              3              0   \n",
       "14250   WM        0  0.0              2              1              1   \n",
       "14251   WM        0  0.5              3              1              0   \n",
       "14252   WM        0  1.0              0              1              2   \n",
       "\n",
       "       PrevDiffAway2  PrevDiffHome3  PrevDiffAway3  PrevDiffHome4  \\\n",
       "14248             -3             -2             -1             -3   \n",
       "14249              1              0              2             -1   \n",
       "14250             -1              0              1              2   \n",
       "14251              0              0              5             -3   \n",
       "14252              4              2              0              2   \n",
       "\n",
       "           ...          dist_home     dist_away  TravelHome   TravelAway  \\\n",
       "14248      ...           0.000000   3534.539231    0.000000   347.574603   \n",
       "14249      ...        3750.413399  14770.693705  405.969902  1846.336713   \n",
       "14250      ...        4224.038712   3092.755264   53.101968    90.878998   \n",
       "14251      ...        4077.831369   3573.971457  509.728921    28.632563   \n",
       "14252      ...        3214.759841  13767.992688  464.575231   322.033967   \n",
       "\n",
       "       TZDeltaHome  TZDeltaAway  team_a_ranking  team_a_points  \\\n",
       "14248            0            0              70         456.53   \n",
       "14249            0            0              45         649.43   \n",
       "14250            0            0              41         685.86   \n",
       "14251            0            0               4        1273.69   \n",
       "14252            0            0               7        1198.13   \n",
       "\n",
       "       team_b_ranking  team_b_points  \n",
       "14248              67         465.28  \n",
       "14249              14        1018.41  \n",
       "14250             211           0.00  \n",
       "14251              10        1125.50  \n",
       "14252              36         718.33  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in the .csv containing the World Cup fixtures and the corresponding statistics (statistics are accurate\n",
    "#up to the start of the match)\n",
    "\n",
    "fixtures_fifa_df = pd.read_csv(\"nb4c_wc_fixtures.csv\", \",\", index_col=0)\n",
    "\n",
    "fixtures_fifa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate X and y\n",
    "y_test_fifa = fixtures_fifa_df['Win']\n",
    "X_test_fifa = fixtures_fifa_df.drop(['Win'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fifa = pd.read_csv(\"nb4a_fifa_updated_wins.csv\", \",\", index_col=0).drop(['Win'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fifa = X_fifa.drop(['FT H', 'FT G', 'AET H', 'AET G'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_fifa = pd.concat([X_fifa, X_test_fifa], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_fifa_dummies = pd.concat([all_matches_fifa, pd.get_dummies(all_matches_fifa['Type'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fifa = all_matches_fifa_dummies.iloc[len(all_matches_fifa_dummies)-64:].drop(['Type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### World Cup Test Data (WIGGO)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>HomeAdv</th>\n",
       "      <th>Win</th>\n",
       "      <th>PrevDiffHome1</th>\n",
       "      <th>PrevDiffAway1</th>\n",
       "      <th>PrevDiffHome2</th>\n",
       "      <th>PrevDiffAway2</th>\n",
       "      <th>PrevDiffHome3</th>\n",
       "      <th>PrevDiffAway3</th>\n",
       "      <th>PrevDiffHome4</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_home</th>\n",
       "      <th>dist_away</th>\n",
       "      <th>TravelHome</th>\n",
       "      <th>TravelAway</th>\n",
       "      <th>TZDeltaHome</th>\n",
       "      <th>TZDeltaAway</th>\n",
       "      <th>team_a_ranking</th>\n",
       "      <th>team_a_points</th>\n",
       "      <th>team_b_ranking</th>\n",
       "      <th>team_b_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14248</th>\n",
       "      <td>WM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3534.539231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>347.574603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>45</td>\n",
       "      <td>1639.144591</td>\n",
       "      <td>56</td>\n",
       "      <td>1611.629202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14249</th>\n",
       "      <td>WM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3750.413399</td>\n",
       "      <td>14770.693705</td>\n",
       "      <td>405.969902</td>\n",
       "      <td>1846.336713</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>1622.222198</td>\n",
       "      <td>13</td>\n",
       "      <td>1778.383238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14250</th>\n",
       "      <td>WM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4224.038712</td>\n",
       "      <td>3092.755264</td>\n",
       "      <td>53.101968</td>\n",
       "      <td>90.878998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>1665.448222</td>\n",
       "      <td>19</td>\n",
       "      <td>1730.381002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14251</th>\n",
       "      <td>WM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>4077.831369</td>\n",
       "      <td>3573.971457</td>\n",
       "      <td>509.728921</td>\n",
       "      <td>28.632563</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1841.546136</td>\n",
       "      <td>3</td>\n",
       "      <td>1886.162292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14252</th>\n",
       "      <td>WM</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3214.759841</td>\n",
       "      <td>13767.992688</td>\n",
       "      <td>464.575231</td>\n",
       "      <td>322.033967</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>6</td>\n",
       "      <td>1824.543984</td>\n",
       "      <td>30</td>\n",
       "      <td>1680.660285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type  HomeAdv  Win  PrevDiffHome1  PrevDiffAway1  PrevDiffHome2  \\\n",
       "14248   WM        1  1.0              0             -1             -1   \n",
       "14249   WM        0  0.0             -3              3              0   \n",
       "14250   WM        0  0.0              2              1              1   \n",
       "14251   WM        0  0.5              3              1              0   \n",
       "14252   WM        0  1.0              0              1              2   \n",
       "\n",
       "       PrevDiffAway2  PrevDiffHome3  PrevDiffAway3  PrevDiffHome4  \\\n",
       "14248             -3             -2             -1             -3   \n",
       "14249              1              0              2             -1   \n",
       "14250             -1              0              1              2   \n",
       "14251              0              0              5             -3   \n",
       "14252              4              2              0              2   \n",
       "\n",
       "           ...          dist_home     dist_away  TravelHome   TravelAway  \\\n",
       "14248      ...           0.000000   3534.539231    0.000000   347.574603   \n",
       "14249      ...        3750.413399  14770.693705  405.969902  1846.336713   \n",
       "14250      ...        4224.038712   3092.755264   53.101968    90.878998   \n",
       "14251      ...        4077.831369   3573.971457  509.728921    28.632563   \n",
       "14252      ...        3214.759841  13767.992688  464.575231   322.033967   \n",
       "\n",
       "       TZDeltaHome  TZDeltaAway  team_a_ranking  team_a_points  \\\n",
       "14248     0.000000     0.166667              45    1639.144591   \n",
       "14249     0.333333     1.000000              52    1622.222198   \n",
       "14250     0.000000     0.000000              39    1665.448222   \n",
       "14251     0.250000     0.000000               5    1841.546136   \n",
       "14252     0.142857     0.142857               6    1824.543984   \n",
       "\n",
       "       team_b_ranking  team_b_points  \n",
       "14248              56    1611.629202  \n",
       "14249              13    1778.383238  \n",
       "14250              19    1730.381002  \n",
       "14251               3    1886.162292  \n",
       "14252              30    1680.660285  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in the .csv containing the World Cup fixtures and the corresponding statistics (statistics are accurate\n",
    "#up to the start of the match)\n",
    "\n",
    "fixtures_wiggo_df = pd.read_csv(\"nb4d_wc_wiggo_df.csv\", \",\", index_col=0)\n",
    "\n",
    "fixtures_wiggo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate X and y\n",
    "y_test_wiggo = fixtures_wiggo_df['Win']\n",
    "X_test_wiggo = fixtures_wiggo_df.drop(['Win'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wiggo = pd.read_csv(\"nb4b_wiggo_updated_wins.csv\", \",\", index_col=0).drop(['Win'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wiggo = X_wiggo.drop(['FT H', 'FT G', 'AET H', 'AET G'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_wiggo = pd.concat([X_wiggo, X_test_wiggo], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_wiggo_dummies = pd.concat([all_matches_wiggo, pd.get_dummies(all_matches_wiggo['Type'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_wiggo = all_matches_wiggo_dummies.iloc[len(all_matches_wiggo_dummies)-64:].drop(['Type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create keras neural network model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add layers to the network\n",
    "model.add(Dense(units=46, activation='relu', kernel_initializer='random_uniform', input_dim=37))\n",
    "model.add(Dense(units=29, activation='relu', kernel_initializer='random_uniform'))\n",
    "model.add(Dense(units=17, activation='relu', kernel_initializer='random_uniform'))\n",
    "model.add(Dense(units=8, activation='relu', kernel_initializer='random_uniform'))\n",
    "#model.add(Dense(units=20, activation='relu', kernel_initializer='random_uniform'))\n",
    "#model.add(Dense(units=10, activation='relu', kernel_initializer='random_uniform'))\n",
    "#Since this is a classification problem (win, draw, loss), a softmax will be used as the final activation\n",
    "model.add(Dense(units=3, activation='softmax', kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model using categorical cross-entropy as a loss function with a categorical_accuracy metric. Use the \n",
    "#'adam' optimizer for faster convergence on a minimum\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/100\n",
      "8724/8724 [==============================] - 3s 323us/step - loss: 1.0436 - categorical_accuracy: 0.4773 - val_loss: 0.9647 - val_categorical_accuracy: 0.5456\n",
      "Epoch 2/100\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9417 - categorical_accuracy: 0.5582 - val_loss: 0.9079 - val_categorical_accuracy: 0.5846\n",
      "Epoch 3/100\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9161 - categorical_accuracy: 0.5679 - val_loss: 0.8968 - val_categorical_accuracy: 0.5887\n",
      "Epoch 4/100\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9114 - categorical_accuracy: 0.5679 - val_loss: 0.8973 - val_categorical_accuracy: 0.5906\n",
      "Epoch 5/100\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9172 - categorical_accuracy: 0.5648 - val_loss: 0.8943 - val_categorical_accuracy: 0.5896\n",
      "Epoch 6/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9093 - categorical_accuracy: 0.5767 - val_loss: 0.9006 - val_categorical_accuracy: 0.5823\n",
      "Epoch 7/100\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9078 - categorical_accuracy: 0.5719 - val_loss: 0.8922 - val_categorical_accuracy: 0.5901\n",
      "Epoch 8/100\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9050 - categorical_accuracy: 0.5761 - val_loss: 0.9006 - val_categorical_accuracy: 0.5864\n",
      "Epoch 9/100\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9034 - categorical_accuracy: 0.5786 - val_loss: 0.8974 - val_categorical_accuracy: 0.5841\n",
      "Epoch 10/100\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9053 - categorical_accuracy: 0.5776 - val_loss: 0.9043 - val_categorical_accuracy: 0.5860\n",
      "Epoch 11/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9049 - categorical_accuracy: 0.5769 - val_loss: 0.8878 - val_categorical_accuracy: 0.5892\n",
      "Epoch 12/100\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9055 - categorical_accuracy: 0.5755 - val_loss: 0.8935 - val_categorical_accuracy: 0.5851\n",
      "Epoch 13/100\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9037 - categorical_accuracy: 0.5752 - val_loss: 0.8942 - val_categorical_accuracy: 0.5864\n",
      "Epoch 14/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9035 - categorical_accuracy: 0.5765 - val_loss: 0.9055 - val_categorical_accuracy: 0.5814\n",
      "Epoch 15/100\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9068 - categorical_accuracy: 0.5746 - val_loss: 0.8972 - val_categorical_accuracy: 0.5855\n",
      "Epoch 16/100\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9031 - categorical_accuracy: 0.5729 - val_loss: 0.8893 - val_categorical_accuracy: 0.5919\n",
      "Epoch 17/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9042 - categorical_accuracy: 0.5791 - val_loss: 0.8927 - val_categorical_accuracy: 0.5878\n",
      "Epoch 18/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9001 - categorical_accuracy: 0.5776 - val_loss: 0.8915 - val_categorical_accuracy: 0.5887\n",
      "Epoch 19/100\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9009 - categorical_accuracy: 0.5793 - val_loss: 0.8954 - val_categorical_accuracy: 0.5855\n",
      "Epoch 20/100\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9022 - categorical_accuracy: 0.5784 - val_loss: 0.8918 - val_categorical_accuracy: 0.5915\n",
      "Epoch 21/100\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9021 - categorical_accuracy: 0.5793 - val_loss: 0.8906 - val_categorical_accuracy: 0.5924\n",
      "Epoch 22/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9002 - categorical_accuracy: 0.5745 - val_loss: 0.8891 - val_categorical_accuracy: 0.5887\n",
      "Epoch 23/100\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.8999 - categorical_accuracy: 0.5793 - val_loss: 0.8941 - val_categorical_accuracy: 0.5855\n",
      "Epoch 24/100\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9025 - categorical_accuracy: 0.5771 - val_loss: 0.8908 - val_categorical_accuracy: 0.5892\n",
      "Epoch 25/100\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.8993 - categorical_accuracy: 0.5810 - val_loss: 0.8983 - val_categorical_accuracy: 0.5892\n",
      "Epoch 26/100\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.8995 - categorical_accuracy: 0.5800 - val_loss: 0.9085 - val_categorical_accuracy: 0.5851\n",
      "Epoch 27/100\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.8997 - categorical_accuracy: 0.5750 - val_loss: 0.9035 - val_categorical_accuracy: 0.5846\n",
      "Epoch 28/100\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9004 - categorical_accuracy: 0.5732 - val_loss: 0.9146 - val_categorical_accuracy: 0.5768\n",
      "Epoch 29/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.8986 - categorical_accuracy: 0.5791 - val_loss: 0.8912 - val_categorical_accuracy: 0.5846\n",
      "Epoch 30/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.8976 - categorical_accuracy: 0.5784 - val_loss: 0.8873 - val_categorical_accuracy: 0.5924\n",
      "Epoch 31/100\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.8982 - categorical_accuracy: 0.5791 - val_loss: 0.8983 - val_categorical_accuracy: 0.5915\n",
      "Epoch 32/100\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.8963 - categorical_accuracy: 0.5798 - val_loss: 0.8947 - val_categorical_accuracy: 0.5892\n",
      "Epoch 33/100\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.8976 - categorical_accuracy: 0.5791 - val_loss: 0.8962 - val_categorical_accuracy: 0.5869\n",
      "Epoch 34/100\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.8977 - categorical_accuracy: 0.5782 - val_loss: 0.8913 - val_categorical_accuracy: 0.5910\n",
      "Epoch 35/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.8974 - categorical_accuracy: 0.5777 - val_loss: 0.8898 - val_categorical_accuracy: 0.5906\n",
      "Epoch 36/100\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.8957 - categorical_accuracy: 0.5785 - val_loss: 0.8937 - val_categorical_accuracy: 0.5892\n",
      "Epoch 37/100\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.8965 - categorical_accuracy: 0.5761 - val_loss: 0.8985 - val_categorical_accuracy: 0.5796\n",
      "Epoch 38/100\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.8953 - categorical_accuracy: 0.5808 - val_loss: 0.8914 - val_categorical_accuracy: 0.5938\n",
      "Epoch 39/100\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.8955 - categorical_accuracy: 0.5832 - val_loss: 0.8953 - val_categorical_accuracy: 0.5851\n",
      "Epoch 40/100\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.8971 - categorical_accuracy: 0.5796 - val_loss: 0.8958 - val_categorical_accuracy: 0.5910\n",
      "Epoch 41/100\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.8991 - categorical_accuracy: 0.5775 - val_loss: 0.8934 - val_categorical_accuracy: 0.5883\n",
      "Epoch 42/100\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.8948 - categorical_accuracy: 0.5790 - val_loss: 0.8975 - val_categorical_accuracy: 0.5919\n",
      "Epoch 43/100\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.8952 - categorical_accuracy: 0.5818 - val_loss: 0.9080 - val_categorical_accuracy: 0.5883\n",
      "Epoch 44/100\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.8974 - categorical_accuracy: 0.5765 - val_loss: 0.8928 - val_categorical_accuracy: 0.5878\n",
      "Epoch 45/100\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.8953 - categorical_accuracy: 0.5785 - val_loss: 0.9124 - val_categorical_accuracy: 0.5828\n",
      "Epoch 46/100\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.8934 - categorical_accuracy: 0.5828 - val_loss: 0.9013 - val_categorical_accuracy: 0.5823\n",
      "Epoch 47/100\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.8947 - categorical_accuracy: 0.5825 - val_loss: 0.8961 - val_categorical_accuracy: 0.5887\n",
      "Epoch 48/100\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.8965 - categorical_accuracy: 0.5828 - val_loss: 0.8998 - val_categorical_accuracy: 0.5896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.8943 - categorical_accuracy: 0.5784 - val_loss: 0.8937 - val_categorical_accuracy: 0.5878\n",
      "Epoch 50/100\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.8933 - categorical_accuracy: 0.5822 - val_loss: 0.9054 - val_categorical_accuracy: 0.5796\n",
      "Epoch 51/100\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.8945 - categorical_accuracy: 0.5808 - val_loss: 0.8885 - val_categorical_accuracy: 0.5860\n",
      "Epoch 52/100\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.8938 - categorical_accuracy: 0.5785 - val_loss: 0.8962 - val_categorical_accuracy: 0.5906\n",
      "Epoch 53/100\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.8928 - categorical_accuracy: 0.5808 - val_loss: 0.8907 - val_categorical_accuracy: 0.5901\n",
      "Epoch 54/100\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.8950 - categorical_accuracy: 0.5781 - val_loss: 0.8932 - val_categorical_accuracy: 0.5915\n",
      "Epoch 55/100\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.8918 - categorical_accuracy: 0.5808 - val_loss: 0.9002 - val_categorical_accuracy: 0.5906\n",
      "Epoch 56/100\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.8956 - categorical_accuracy: 0.5797 - val_loss: 0.9132 - val_categorical_accuracy: 0.5828\n",
      "Epoch 57/100\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.8931 - categorical_accuracy: 0.5798 - val_loss: 0.9083 - val_categorical_accuracy: 0.5832\n",
      "Epoch 58/100\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.8951 - categorical_accuracy: 0.5809 - val_loss: 0.8953 - val_categorical_accuracy: 0.5901\n",
      "Epoch 59/100\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.8912 - categorical_accuracy: 0.5800 - val_loss: 0.9053 - val_categorical_accuracy: 0.5823\n",
      "Epoch 60/100\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.8924 - categorical_accuracy: 0.5810 - val_loss: 0.8932 - val_categorical_accuracy: 0.5915\n",
      "Epoch 61/100\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.8890 - categorical_accuracy: 0.5825 - val_loss: 0.9040 - val_categorical_accuracy: 0.5873\n",
      "Epoch 62/100\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.8909 - categorical_accuracy: 0.5818 - val_loss: 0.9068 - val_categorical_accuracy: 0.5896\n",
      "Epoch 63/100\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.8922 - categorical_accuracy: 0.5806 - val_loss: 0.8966 - val_categorical_accuracy: 0.5892\n",
      "Epoch 64/100\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.8916 - categorical_accuracy: 0.5791 - val_loss: 0.8966 - val_categorical_accuracy: 0.5919\n",
      "Epoch 65/100\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.8899 - categorical_accuracy: 0.5798 - val_loss: 0.8927 - val_categorical_accuracy: 0.5841\n",
      "Epoch 66/100\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.8916 - categorical_accuracy: 0.5794 - val_loss: 0.9009 - val_categorical_accuracy: 0.5915\n",
      "Epoch 67/100\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.8887 - categorical_accuracy: 0.5831 - val_loss: 0.8941 - val_categorical_accuracy: 0.5883\n",
      "Epoch 68/100\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.8912 - categorical_accuracy: 0.5762 - val_loss: 0.9081 - val_categorical_accuracy: 0.5763\n",
      "Epoch 69/100\n",
      "8724/8724 [==============================] - 2s 172us/step - loss: 0.8900 - categorical_accuracy: 0.5833 - val_loss: 0.9005 - val_categorical_accuracy: 0.5883\n",
      "Epoch 70/100\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.8902 - categorical_accuracy: 0.5813 - val_loss: 0.9030 - val_categorical_accuracy: 0.5906\n",
      "Epoch 71/100\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.8901 - categorical_accuracy: 0.5800 - val_loss: 0.8978 - val_categorical_accuracy: 0.5883\n",
      "Epoch 72/100\n",
      "8724/8724 [==============================] - 1s 74us/step - loss: 0.8909 - categorical_accuracy: 0.5822 - val_loss: 0.9038 - val_categorical_accuracy: 0.5887\n",
      "Epoch 73/100\n",
      "8724/8724 [==============================] - 1s 76us/step - loss: 0.8890 - categorical_accuracy: 0.5815 - val_loss: 0.8987 - val_categorical_accuracy: 0.5887\n",
      "Epoch 74/100\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.8902 - categorical_accuracy: 0.5793 - val_loss: 0.9050 - val_categorical_accuracy: 0.5924\n",
      "Epoch 75/100\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.8883 - categorical_accuracy: 0.5825 - val_loss: 0.8998 - val_categorical_accuracy: 0.5864\n",
      "Epoch 76/100\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.8886 - categorical_accuracy: 0.5809 - val_loss: 0.9105 - val_categorical_accuracy: 0.5887\n",
      "Epoch 77/100\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.8887 - categorical_accuracy: 0.5838 - val_loss: 0.8950 - val_categorical_accuracy: 0.5910\n",
      "Epoch 78/100\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.8870 - categorical_accuracy: 0.5833 - val_loss: 0.9043 - val_categorical_accuracy: 0.5919\n",
      "Epoch 79/100\n",
      "8724/8724 [==============================] - 1s 75us/step - loss: 0.8864 - categorical_accuracy: 0.5818 - val_loss: 0.8965 - val_categorical_accuracy: 0.5896\n",
      "Epoch 80/100\n",
      "8724/8724 [==============================] - 1s 76us/step - loss: 0.8860 - categorical_accuracy: 0.5837 - val_loss: 0.9011 - val_categorical_accuracy: 0.5928\n",
      "Epoch 81/100\n",
      "8724/8724 [==============================] - 1s 76us/step - loss: 0.8869 - categorical_accuracy: 0.5841 - val_loss: 0.9017 - val_categorical_accuracy: 0.5896\n",
      "Epoch 82/100\n",
      "8724/8724 [==============================] - 1s 72us/step - loss: 0.8881 - categorical_accuracy: 0.5834 - val_loss: 0.9064 - val_categorical_accuracy: 0.5873\n",
      "Epoch 83/100\n",
      "8724/8724 [==============================] - 1s 71us/step - loss: 0.8880 - categorical_accuracy: 0.5805 - val_loss: 0.9038 - val_categorical_accuracy: 0.5873\n",
      "Epoch 84/100\n",
      "8724/8724 [==============================] - 1s 74us/step - loss: 0.8851 - categorical_accuracy: 0.5861 - val_loss: 0.9183 - val_categorical_accuracy: 0.5832\n",
      "Epoch 85/100\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.8863 - categorical_accuracy: 0.5821 - val_loss: 0.9056 - val_categorical_accuracy: 0.5910\n",
      "Epoch 86/100\n",
      "8724/8724 [==============================] - 1s 72us/step - loss: 0.8863 - categorical_accuracy: 0.5828 - val_loss: 0.9087 - val_categorical_accuracy: 0.5869\n",
      "Epoch 87/100\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.8907 - categorical_accuracy: 0.5813 - val_loss: 0.9031 - val_categorical_accuracy: 0.5915\n",
      "Epoch 88/100\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.8852 - categorical_accuracy: 0.5848 - val_loss: 0.9010 - val_categorical_accuracy: 0.5915\n",
      "Epoch 89/100\n",
      "8724/8724 [==============================] - 1s 73us/step - loss: 0.8851 - categorical_accuracy: 0.5822 - val_loss: 0.9089 - val_categorical_accuracy: 0.5887\n",
      "Epoch 90/100\n",
      "8724/8724 [==============================] - 1s 71us/step - loss: 0.8855 - categorical_accuracy: 0.5845 - val_loss: 0.9068 - val_categorical_accuracy: 0.5924\n",
      "Epoch 91/100\n",
      "8724/8724 [==============================] - 1s 70us/step - loss: 0.8867 - categorical_accuracy: 0.5836 - val_loss: 0.9126 - val_categorical_accuracy: 0.5915\n",
      "Epoch 92/100\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.8885 - categorical_accuracy: 0.5814 - val_loss: 0.9031 - val_categorical_accuracy: 0.5896\n",
      "Epoch 93/100\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.8868 - categorical_accuracy: 0.5804 - val_loss: 0.9252 - val_categorical_accuracy: 0.5759\n",
      "Epoch 94/100\n",
      "8724/8724 [==============================] - 1s 77us/step - loss: 0.8858 - categorical_accuracy: 0.5839 - val_loss: 0.9117 - val_categorical_accuracy: 0.5832\n",
      "Epoch 95/100\n",
      "8724/8724 [==============================] - 1s 74us/step - loss: 0.8862 - categorical_accuracy: 0.5821 - val_loss: 0.9158 - val_categorical_accuracy: 0.5892\n",
      "Epoch 96/100\n",
      "8724/8724 [==============================] - 1s 77us/step - loss: 0.8855 - categorical_accuracy: 0.5840 - val_loss: 0.9088 - val_categorical_accuracy: 0.5915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.8865 - categorical_accuracy: 0.5810 - val_loss: 0.9062 - val_categorical_accuracy: 0.5823\n",
      "Epoch 98/100\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.8828 - categorical_accuracy: 0.5872 - val_loss: 0.9068 - val_categorical_accuracy: 0.5951\n",
      "Epoch 99/100\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.8836 - categorical_accuracy: 0.5825 - val_loss: 0.9165 - val_categorical_accuracy: 0.5800\n",
      "Epoch 100/100\n",
      "8724/8724 [==============================] - 1s 78us/step - loss: 0.8829 - categorical_accuracy: 0.5833 - val_loss: 0.9099 - val_categorical_accuracy: 0.5860\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(X_train_wiggo, y_train_wiggo, epochs=50, batch_size=32,verbose=1, validation_split = .2)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate neural network predictions for the test set\n",
    "predictions = pd.DataFrame(model.predict(X_test_wiggo, batch_size=5), columns=['Win', 'Draw', 'Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Win</th>\n",
       "      <th>Draw</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>6.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.083647e-01</td>\n",
       "      <td>2.422973e-01</td>\n",
       "      <td>3.493381e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.174072e-01</td>\n",
       "      <td>7.939528e-02</td>\n",
       "      <td>2.044795e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.920524e-13</td>\n",
       "      <td>6.110897e-07</td>\n",
       "      <td>1.928693e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.669481e-01</td>\n",
       "      <td>2.175186e-01</td>\n",
       "      <td>1.730078e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.493366e-01</td>\n",
       "      <td>2.645542e-01</td>\n",
       "      <td>3.281861e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.749508e-01</td>\n",
       "      <td>2.947084e-01</td>\n",
       "      <td>4.720138e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999992e-01</td>\n",
       "      <td>3.234785e-01</td>\n",
       "      <td>9.999994e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Win          Draw          Loss\n",
       "count  6.400000e+01  6.400000e+01  6.400000e+01\n",
       "mean   4.083647e-01  2.422973e-01  3.493381e-01\n",
       "std    2.174072e-01  7.939528e-02  2.044795e-01\n",
       "min    9.920524e-13  6.110897e-07  1.928693e-11\n",
       "25%    2.669481e-01  2.175186e-01  1.730078e-01\n",
       "50%    3.493366e-01  2.645542e-01  3.281861e-01\n",
       "75%    5.749508e-01  2.947084e-01  4.720138e-01\n",
       "max    9.999992e-01  3.234785e-01  9.999994e-01"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check: make sure the max values for each categorical column are close to 1, which idicates a high confidence\n",
    "#that at least one game will end in a win, draw, or loss (respectively)\n",
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the on-hot encoding back into a single column\n",
    "results = [0]*len(predictions)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if(predictions.iloc[i].Win > predictions.iloc[i].Draw and predictions.iloc[i].Win > predictions.iloc[i].Loss):\n",
    "        results[i] = 1\n",
    "    elif(predictions.iloc[i].Draw >= predictions.iloc[i].Win and predictions.iloc[i].Draw >= predictions.iloc[i].Loss):\n",
    "        results[i] = 0.5\n",
    "    elif(predictions.iloc[i].Loss > predictions.iloc[i].Win and predictions.iloc[i].Loss > predictions.iloc[i].Draw):\n",
    "        results[i] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Prediction Accuracy (2018 World Cup): 62.5%\n"
     ]
    }
   ],
   "source": [
    "#Count how many times the prediction is correct and print the percentage of correct predictions\n",
    "nn_correct_predictions = 0\n",
    "\n",
    "for i in range(len(y_test_wiggo)):\n",
    "    if (y_test_wiggo.iloc[i] == results[i]):\n",
    "        nn_correct_predictions += 1\n",
    "\n",
    "print(\"Neural Network Prediction Accuracy Using WIGGO (2018 World Cup): {0}%\".format(100*nn_correct_predictions/len(y_test_wiggo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Generate Multiple Prediction Accuracies (Average 10 Neural Network Accuracies)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn(X_train, y_train, e=50):\n",
    "    #Create keras neural network model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add layers to the network\n",
    "    model.add(Dense(units=29, activation='relu', kernel_initializer='random_uniform', input_dim=37))\n",
    "    #model.add(Dense(units=39, activation='relu', kernel_initializer='random_uniform', input_dim=31))\n",
    "    #model.add(Dense(units=21, activation='relu', kernel_initializer='random_uniform'))\n",
    "    #Since this is a classification problem (win, draw, loss), a softmax will be used as the final activation\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer='random_uniform'))\n",
    "    \n",
    "    #Compile the model using categorical cross-entropy as a loss function with a categorical_accuracy metric. Use the \n",
    "    #'adam' optimizer for faster convergence on a minimum\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    #Train the model\n",
    "    model.fit(X_train, y_train, epochs=e, batch_size=32,verbose=1, validation_split = .2)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(trained_model, X_test, y_test, data_type):\n",
    "    #Generate neural network predictions for the test set\n",
    "    predictions = pd.DataFrame(trained_model.predict(X_test, batch_size=5), columns=['Win', 'Draw', 'Loss'])\n",
    "    \n",
    "    #Sanity check: make sure the max values for each categorical column are close to 1, which idicates a high confidence\n",
    "    #that at least one game will end in a win, draw, or loss (respectively)\n",
    "    #print(predictions.describe())\n",
    "    \n",
    "    #Convert the on-hot encoding back into a single column\n",
    "    results = [0]*len(predictions)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if(predictions.iloc[i].Win > predictions.iloc[i].Draw and predictions.iloc[i].Win > predictions.iloc[i].Loss):\n",
    "            results[i] = 1\n",
    "        elif(predictions.iloc[i].Draw >= predictions.iloc[i].Win and predictions.iloc[i].Draw >= predictions.iloc[i].Loss):\n",
    "            results[i] = 0.5\n",
    "        elif(predictions.iloc[i].Loss > predictions.iloc[i].Win and predictions.iloc[i].Loss > predictions.iloc[i].Draw):\n",
    "            results[i] = 0\n",
    "            \n",
    "    #Count how many times the prediction is correct and print the percentage of correct predictions\n",
    "    nn_correct_predictions = 0\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        if (y_test.iloc[i] == results[i]):\n",
    "            nn_correct_predictions += 1\n",
    "\n",
    "    print(\"Neural Network Prediction Accuracy ({0}): {1}%\".format(data_type, 100*nn_correct_predictions/len(y_test)))\n",
    "    \n",
    "    return 100*nn_correct_predictions/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 3s 349us/step - loss: 1.4813 - categorical_accuracy: 0.4739 - val_loss: 0.9876 - val_categorical_accuracy: 0.5608\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 1.0955 - categorical_accuracy: 0.5282 - val_loss: 0.9528 - val_categorical_accuracy: 0.5896\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9788 - categorical_accuracy: 0.5501 - val_loss: 0.9270 - val_categorical_accuracy: 0.5828\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9768 - categorical_accuracy: 0.5531 - val_loss: 0.9204 - val_categorical_accuracy: 0.5681\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9571 - categorical_accuracy: 0.5565 - val_loss: 0.9261 - val_categorical_accuracy: 0.5695\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9409 - categorical_accuracy: 0.5616 - val_loss: 0.9079 - val_categorical_accuracy: 0.5832\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9239 - categorical_accuracy: 0.5702 - val_loss: 0.9291 - val_categorical_accuracy: 0.5676\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 108us/step - loss: 0.9311 - categorical_accuracy: 0.5664 - val_loss: 0.9000 - val_categorical_accuracy: 0.5864\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9193 - categorical_accuracy: 0.5659 - val_loss: 0.9269 - val_categorical_accuracy: 0.5617\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 108us/step - loss: 0.9117 - categorical_accuracy: 0.5739 - val_loss: 0.9084 - val_categorical_accuracy: 0.5809\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9134 - categorical_accuracy: 0.5744 - val_loss: 0.9137 - val_categorical_accuracy: 0.5873\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9156 - categorical_accuracy: 0.5706 - val_loss: 0.9201 - val_categorical_accuracy: 0.5727\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 75us/step - loss: 0.9185 - categorical_accuracy: 0.5704 - val_loss: 0.9051 - val_categorical_accuracy: 0.5841\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 77us/step - loss: 0.9164 - categorical_accuracy: 0.5704 - val_loss: 0.8970 - val_categorical_accuracy: 0.5906\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9146 - categorical_accuracy: 0.5708 - val_loss: 0.9020 - val_categorical_accuracy: 0.5823\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 77us/step - loss: 0.9131 - categorical_accuracy: 0.5718 - val_loss: 0.9291 - val_categorical_accuracy: 0.5672\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9136 - categorical_accuracy: 0.5708 - val_loss: 0.8939 - val_categorical_accuracy: 0.5901\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9103 - categorical_accuracy: 0.5727 - val_loss: 0.9115 - val_categorical_accuracy: 0.5846\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9100 - categorical_accuracy: 0.5743 - val_loss: 0.8969 - val_categorical_accuracy: 0.5910\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9154 - categorical_accuracy: 0.5708 - val_loss: 0.9067 - val_categorical_accuracy: 0.5864\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 75us/step - loss: 0.9144 - categorical_accuracy: 0.5743 - val_loss: 0.8947 - val_categorical_accuracy: 0.5942\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 76us/step - loss: 0.9092 - categorical_accuracy: 0.5790 - val_loss: 0.9015 - val_categorical_accuracy: 0.5805\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 78us/step - loss: 0.9159 - categorical_accuracy: 0.5720 - val_loss: 0.8937 - val_categorical_accuracy: 0.5873\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9122 - categorical_accuracy: 0.5734 - val_loss: 0.8957 - val_categorical_accuracy: 0.5878\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 122us/step - loss: 0.9093 - categorical_accuracy: 0.5770 - val_loss: 0.9018 - val_categorical_accuracy: 0.5841\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9107 - categorical_accuracy: 0.5740 - val_loss: 0.9043 - val_categorical_accuracy: 0.5823\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 78us/step - loss: 0.9113 - categorical_accuracy: 0.5704 - val_loss: 0.9047 - val_categorical_accuracy: 0.5832\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9096 - categorical_accuracy: 0.5762 - val_loss: 0.9359 - val_categorical_accuracy: 0.5828\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 114us/step - loss: 0.9093 - categorical_accuracy: 0.5776 - val_loss: 0.8937 - val_categorical_accuracy: 0.5901\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9133 - categorical_accuracy: 0.5720 - val_loss: 0.9104 - val_categorical_accuracy: 0.5878\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9139 - categorical_accuracy: 0.5735 - val_loss: 0.9029 - val_categorical_accuracy: 0.5887\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9128 - categorical_accuracy: 0.5706 - val_loss: 0.8965 - val_categorical_accuracy: 0.5910\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9149 - categorical_accuracy: 0.5735 - val_loss: 0.8946 - val_categorical_accuracy: 0.5924\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 110us/step - loss: 0.9153 - categorical_accuracy: 0.5685 - val_loss: 0.8932 - val_categorical_accuracy: 0.5823\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 77us/step - loss: 0.9151 - categorical_accuracy: 0.5588 - val_loss: 0.9152 - val_categorical_accuracy: 0.5786\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9121 - categorical_accuracy: 0.5710 - val_loss: 0.8963 - val_categorical_accuracy: 0.5933\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9061 - categorical_accuracy: 0.5713 - val_loss: 0.8978 - val_categorical_accuracy: 0.5763\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9118 - categorical_accuracy: 0.5657 - val_loss: 0.9138 - val_categorical_accuracy: 0.5828\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9102 - categorical_accuracy: 0.5716 - val_loss: 0.9027 - val_categorical_accuracy: 0.5901\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9087 - categorical_accuracy: 0.5770 - val_loss: 0.8976 - val_categorical_accuracy: 0.5823\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9105 - categorical_accuracy: 0.5734 - val_loss: 0.8945 - val_categorical_accuracy: 0.5906\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9120 - categorical_accuracy: 0.5684 - val_loss: 0.8954 - val_categorical_accuracy: 0.5841\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 135us/step - loss: 0.9109 - categorical_accuracy: 0.5691 - val_loss: 0.8981 - val_categorical_accuracy: 0.5901\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9123 - categorical_accuracy: 0.5712 - val_loss: 0.9057 - val_categorical_accuracy: 0.5727\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9106 - categorical_accuracy: 0.5703 - val_loss: 0.9061 - val_categorical_accuracy: 0.5837\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 144us/step - loss: 0.9093 - categorical_accuracy: 0.5679 - val_loss: 0.8887 - val_categorical_accuracy: 0.5887\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9130 - categorical_accuracy: 0.5620 - val_loss: 0.8930 - val_categorical_accuracy: 0.5864\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 108us/step - loss: 0.9091 - categorical_accuracy: 0.5710 - val_loss: 0.9048 - val_categorical_accuracy: 0.5860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 169us/step - loss: 0.9094 - categorical_accuracy: 0.5708 - val_loss: 0.8968 - val_categorical_accuracy: 0.5951\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 118us/step - loss: 0.9084 - categorical_accuracy: 0.5665 - val_loss: 0.9092 - val_categorical_accuracy: 0.5878\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 60.9375%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 3s 382us/step - loss: 2.1011 - categorical_accuracy: 0.4660 - val_loss: 0.9825 - val_categorical_accuracy: 0.5374\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 1.0640 - categorical_accuracy: 0.5269 - val_loss: 1.0366 - val_categorical_accuracy: 0.5786\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 1.0269 - categorical_accuracy: 0.5389 - val_loss: 0.9179 - val_categorical_accuracy: 0.5814\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9747 - categorical_accuracy: 0.5516 - val_loss: 0.9060 - val_categorical_accuracy: 0.5901\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9503 - categorical_accuracy: 0.5565 - val_loss: 0.9077 - val_categorical_accuracy: 0.5796\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9329 - categorical_accuracy: 0.5629 - val_loss: 0.9439 - val_categorical_accuracy: 0.5869\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9318 - categorical_accuracy: 0.5666 - val_loss: 0.9111 - val_categorical_accuracy: 0.5869\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 131us/step - loss: 0.9328 - categorical_accuracy: 0.5640 - val_loss: 0.9047 - val_categorical_accuracy: 0.5887\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 78us/step - loss: 0.9314 - categorical_accuracy: 0.5669 - val_loss: 0.8959 - val_categorical_accuracy: 0.5873\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9167 - categorical_accuracy: 0.5703 - val_loss: 0.9007 - val_categorical_accuracy: 0.5915\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9200 - categorical_accuracy: 0.5726 - val_loss: 0.9228 - val_categorical_accuracy: 0.5837\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9158 - categorical_accuracy: 0.5721 - val_loss: 0.9112 - val_categorical_accuracy: 0.5818\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9142 - categorical_accuracy: 0.5731 - val_loss: 0.9083 - val_categorical_accuracy: 0.5878\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 111us/step - loss: 0.9138 - categorical_accuracy: 0.5754 - val_loss: 0.9248 - val_categorical_accuracy: 0.5869\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9149 - categorical_accuracy: 0.5729 - val_loss: 0.9195 - val_categorical_accuracy: 0.5823\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9212 - categorical_accuracy: 0.5731 - val_loss: 0.8962 - val_categorical_accuracy: 0.5846\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9119 - categorical_accuracy: 0.5718 - val_loss: 0.8969 - val_categorical_accuracy: 0.5915\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9150 - categorical_accuracy: 0.5696 - val_loss: 0.9065 - val_categorical_accuracy: 0.5818\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 78us/step - loss: 0.9132 - categorical_accuracy: 0.5722 - val_loss: 0.8968 - val_categorical_accuracy: 0.5896\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 77us/step - loss: 0.9155 - categorical_accuracy: 0.5737 - val_loss: 0.9405 - val_categorical_accuracy: 0.5658\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9117 - categorical_accuracy: 0.5770 - val_loss: 0.9015 - val_categorical_accuracy: 0.5883\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9103 - categorical_accuracy: 0.5770 - val_loss: 0.9007 - val_categorical_accuracy: 0.5910\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9147 - categorical_accuracy: 0.5739 - val_loss: 0.9037 - val_categorical_accuracy: 0.5782\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9162 - categorical_accuracy: 0.5723 - val_loss: 0.8900 - val_categorical_accuracy: 0.5846\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 77us/step - loss: 0.9146 - categorical_accuracy: 0.5734 - val_loss: 0.9170 - val_categorical_accuracy: 0.5672\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9170 - categorical_accuracy: 0.5740 - val_loss: 0.8896 - val_categorical_accuracy: 0.5906\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9119 - categorical_accuracy: 0.5715 - val_loss: 0.9008 - val_categorical_accuracy: 0.5919\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 128us/step - loss: 0.9120 - categorical_accuracy: 0.5745 - val_loss: 0.8956 - val_categorical_accuracy: 0.5892\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9154 - categorical_accuracy: 0.5746 - val_loss: 0.8904 - val_categorical_accuracy: 0.5864\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9141 - categorical_accuracy: 0.5706 - val_loss: 0.8936 - val_categorical_accuracy: 0.5873\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9135 - categorical_accuracy: 0.5683 - val_loss: 0.8996 - val_categorical_accuracy: 0.5818\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9113 - categorical_accuracy: 0.5777 - val_loss: 0.8980 - val_categorical_accuracy: 0.5906\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9136 - categorical_accuracy: 0.5726 - val_loss: 0.8955 - val_categorical_accuracy: 0.5924\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9139 - categorical_accuracy: 0.5705 - val_loss: 0.9173 - val_categorical_accuracy: 0.5823\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9135 - categorical_accuracy: 0.5735 - val_loss: 0.9019 - val_categorical_accuracy: 0.5841\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9083 - categorical_accuracy: 0.5751 - val_loss: 0.9199 - val_categorical_accuracy: 0.5745\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9120 - categorical_accuracy: 0.5750 - val_loss: 0.8903 - val_categorical_accuracy: 0.5915\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9119 - categorical_accuracy: 0.5700 - val_loss: 0.9213 - val_categorical_accuracy: 0.5782\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 73us/step - loss: 0.9079 - categorical_accuracy: 0.5759 - val_loss: 0.9223 - val_categorical_accuracy: 0.5722\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 74us/step - loss: 0.9077 - categorical_accuracy: 0.5745 - val_loss: 0.9034 - val_categorical_accuracy: 0.5896\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9102 - categorical_accuracy: 0.5724 - val_loss: 0.8992 - val_categorical_accuracy: 0.5828\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9100 - categorical_accuracy: 0.5791 - val_loss: 0.9116 - val_categorical_accuracy: 0.5754\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9090 - categorical_accuracy: 0.5720 - val_loss: 0.8895 - val_categorical_accuracy: 0.5933\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9074 - categorical_accuracy: 0.5789 - val_loss: 0.8989 - val_categorical_accuracy: 0.5864\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 143us/step - loss: 0.9095 - categorical_accuracy: 0.5742 - val_loss: 0.8940 - val_categorical_accuracy: 0.5887\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9075 - categorical_accuracy: 0.5773 - val_loss: 0.8992 - val_categorical_accuracy: 0.5864\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 170us/step - loss: 0.9078 - categorical_accuracy: 0.5757 - val_loss: 0.8937 - val_categorical_accuracy: 0.5864\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 154us/step - loss: 0.9130 - categorical_accuracy: 0.5719 - val_loss: 0.9056 - val_categorical_accuracy: 0.5796\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 171us/step - loss: 0.9085 - categorical_accuracy: 0.5768 - val_loss: 0.9098 - val_categorical_accuracy: 0.5653\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9110 - categorical_accuracy: 0.5739 - val_loss: 0.8959 - val_categorical_accuracy: 0.5919\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 59.375%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 3s 390us/step - loss: 2.0726 - categorical_accuracy: 0.4669 - val_loss: 1.0326 - val_categorical_accuracy: 0.5612\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 1.0398 - categorical_accuracy: 0.5351 - val_loss: 0.9552 - val_categorical_accuracy: 0.5305\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9750 - categorical_accuracy: 0.5496 - val_loss: 0.9441 - val_categorical_accuracy: 0.5681\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9791 - categorical_accuracy: 0.5500 - val_loss: 1.0581 - val_categorical_accuracy: 0.4846\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9484 - categorical_accuracy: 0.5591 - val_loss: 0.9965 - val_categorical_accuracy: 0.5461\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9366 - categorical_accuracy: 0.5585 - val_loss: 0.9105 - val_categorical_accuracy: 0.5814\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 128us/step - loss: 0.9271 - categorical_accuracy: 0.5643 - val_loss: 0.8973 - val_categorical_accuracy: 0.5887\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9197 - categorical_accuracy: 0.5664 - val_loss: 0.9022 - val_categorical_accuracy: 0.5878\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9221 - categorical_accuracy: 0.5687 - val_loss: 0.8973 - val_categorical_accuracy: 0.5938\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9211 - categorical_accuracy: 0.5713 - val_loss: 0.8994 - val_categorical_accuracy: 0.5887\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9163 - categorical_accuracy: 0.5720 - val_loss: 0.9071 - val_categorical_accuracy: 0.5768\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9200 - categorical_accuracy: 0.5697 - val_loss: 0.8986 - val_categorical_accuracy: 0.5864\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9133 - categorical_accuracy: 0.5724 - val_loss: 0.9079 - val_categorical_accuracy: 0.5805\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9175 - categorical_accuracy: 0.5698 - val_loss: 0.9051 - val_categorical_accuracy: 0.5860\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9182 - categorical_accuracy: 0.5736 - val_loss: 0.8972 - val_categorical_accuracy: 0.5878\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 132us/step - loss: 0.9159 - categorical_accuracy: 0.5700 - val_loss: 0.8958 - val_categorical_accuracy: 0.5896\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 125us/step - loss: 0.9236 - categorical_accuracy: 0.5690 - val_loss: 0.9170 - val_categorical_accuracy: 0.5782\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 108us/step - loss: 0.9181 - categorical_accuracy: 0.5675 - val_loss: 0.9019 - val_categorical_accuracy: 0.5855\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9179 - categorical_accuracy: 0.5747 - val_loss: 0.9071 - val_categorical_accuracy: 0.5796\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 114us/step - loss: 0.9159 - categorical_accuracy: 0.5681 - val_loss: 0.8936 - val_categorical_accuracy: 0.5860\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9169 - categorical_accuracy: 0.5715 - val_loss: 0.9008 - val_categorical_accuracy: 0.5942\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9163 - categorical_accuracy: 0.5715 - val_loss: 0.9047 - val_categorical_accuracy: 0.5873\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 114us/step - loss: 0.9150 - categorical_accuracy: 0.5734 - val_loss: 0.9030 - val_categorical_accuracy: 0.5887\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9200 - categorical_accuracy: 0.5740 - val_loss: 0.8954 - val_categorical_accuracy: 0.5924\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 127us/step - loss: 0.9156 - categorical_accuracy: 0.5708 - val_loss: 0.9009 - val_categorical_accuracy: 0.5878\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 132us/step - loss: 0.9164 - categorical_accuracy: 0.5708 - val_loss: 0.9089 - val_categorical_accuracy: 0.5809\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9156 - categorical_accuracy: 0.5679 - val_loss: 0.9042 - val_categorical_accuracy: 0.5864\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9168 - categorical_accuracy: 0.5671 - val_loss: 0.8901 - val_categorical_accuracy: 0.5915\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9129 - categorical_accuracy: 0.5718 - val_loss: 0.8988 - val_categorical_accuracy: 0.5846\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9145 - categorical_accuracy: 0.5640 - val_loss: 0.9000 - val_categorical_accuracy: 0.5841\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9149 - categorical_accuracy: 0.5710 - val_loss: 0.9144 - val_categorical_accuracy: 0.5846\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9165 - categorical_accuracy: 0.5679 - val_loss: 0.9002 - val_categorical_accuracy: 0.5901\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9122 - categorical_accuracy: 0.5735 - val_loss: 0.9032 - val_categorical_accuracy: 0.5768\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9141 - categorical_accuracy: 0.5714 - val_loss: 0.9060 - val_categorical_accuracy: 0.5805\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 136us/step - loss: 0.9105 - categorical_accuracy: 0.5675 - val_loss: 0.8951 - val_categorical_accuracy: 0.5864\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9086 - categorical_accuracy: 0.5726 - val_loss: 0.8987 - val_categorical_accuracy: 0.5896\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9095 - categorical_accuracy: 0.5728 - val_loss: 0.9024 - val_categorical_accuracy: 0.5896\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9130 - categorical_accuracy: 0.5646 - val_loss: 0.8953 - val_categorical_accuracy: 0.5855\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9122 - categorical_accuracy: 0.5718 - val_loss: 0.8939 - val_categorical_accuracy: 0.5896\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 162us/step - loss: 0.9096 - categorical_accuracy: 0.5711 - val_loss: 0.9017 - val_categorical_accuracy: 0.5873\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9084 - categorical_accuracy: 0.5713 - val_loss: 0.8950 - val_categorical_accuracy: 0.5924\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9095 - categorical_accuracy: 0.5722 - val_loss: 0.9137 - val_categorical_accuracy: 0.5887\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9103 - categorical_accuracy: 0.5721 - val_loss: 0.9116 - val_categorical_accuracy: 0.5832\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9111 - categorical_accuracy: 0.5684 - val_loss: 0.8928 - val_categorical_accuracy: 0.5823\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9107 - categorical_accuracy: 0.5734 - val_loss: 0.8971 - val_categorical_accuracy: 0.5901\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9080 - categorical_accuracy: 0.5727 - val_loss: 0.8941 - val_categorical_accuracy: 0.5910\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 121us/step - loss: 0.9115 - categorical_accuracy: 0.5723 - val_loss: 0.9037 - val_categorical_accuracy: 0.5873\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9103 - categorical_accuracy: 0.5726 - val_loss: 0.8963 - val_categorical_accuracy: 0.5901\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 129us/step - loss: 0.9091 - categorical_accuracy: 0.5697 - val_loss: 0.8959 - val_categorical_accuracy: 0.5906\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9108 - categorical_accuracy: 0.5749 - val_loss: 0.8975 - val_categorical_accuracy: 0.5924\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 62.5%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 484us/step - loss: 1.2669 - categorical_accuracy: 0.4796 - val_loss: 0.9648 - val_categorical_accuracy: 0.5612\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 129us/step - loss: 1.0031 - categorical_accuracy: 0.5392 - val_loss: 0.9376 - val_categorical_accuracy: 0.5575\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9581 - categorical_accuracy: 0.5556 - val_loss: 0.9253 - val_categorical_accuracy: 0.5837\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9448 - categorical_accuracy: 0.5588 - val_loss: 0.9243 - val_categorical_accuracy: 0.5832\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9317 - categorical_accuracy: 0.5616 - val_loss: 0.9520 - val_categorical_accuracy: 0.5589\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9340 - categorical_accuracy: 0.5614 - val_loss: 0.9229 - val_categorical_accuracy: 0.5805\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 133us/step - loss: 0.9234 - categorical_accuracy: 0.5677 - val_loss: 0.9478 - val_categorical_accuracy: 0.5589\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9209 - categorical_accuracy: 0.5702 - val_loss: 0.9181 - val_categorical_accuracy: 0.5727\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9190 - categorical_accuracy: 0.5716 - val_loss: 0.9138 - val_categorical_accuracy: 0.5883\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9208 - categorical_accuracy: 0.5726 - val_loss: 0.8989 - val_categorical_accuracy: 0.5896\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9164 - categorical_accuracy: 0.5724 - val_loss: 0.8988 - val_categorical_accuracy: 0.5906\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9140 - categorical_accuracy: 0.5720 - val_loss: 0.9002 - val_categorical_accuracy: 0.5869\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9128 - categorical_accuracy: 0.5749 - val_loss: 0.9094 - val_categorical_accuracy: 0.5873\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9138 - categorical_accuracy: 0.5722 - val_loss: 0.9141 - val_categorical_accuracy: 0.5805\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9111 - categorical_accuracy: 0.5745 - val_loss: 0.9021 - val_categorical_accuracy: 0.5869\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9127 - categorical_accuracy: 0.5722 - val_loss: 0.9117 - val_categorical_accuracy: 0.5841\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 142us/step - loss: 0.9128 - categorical_accuracy: 0.5731 - val_loss: 0.8932 - val_categorical_accuracy: 0.5873\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9102 - categorical_accuracy: 0.5729 - val_loss: 0.8905 - val_categorical_accuracy: 0.5878\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9086 - categorical_accuracy: 0.5784 - val_loss: 0.9027 - val_categorical_accuracy: 0.5782\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 160us/step - loss: 0.9119 - categorical_accuracy: 0.5721 - val_loss: 0.9067 - val_categorical_accuracy: 0.5791\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9140 - categorical_accuracy: 0.5675 - val_loss: 0.9312 - val_categorical_accuracy: 0.5612\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9107 - categorical_accuracy: 0.5757 - val_loss: 0.8866 - val_categorical_accuracy: 0.5901\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9130 - categorical_accuracy: 0.5739 - val_loss: 0.8980 - val_categorical_accuracy: 0.5883\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 130us/step - loss: 0.9111 - categorical_accuracy: 0.5728 - val_loss: 0.9000 - val_categorical_accuracy: 0.5782\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9127 - categorical_accuracy: 0.5737 - val_loss: 0.9086 - val_categorical_accuracy: 0.5878\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9106 - categorical_accuracy: 0.5777 - val_loss: 0.8987 - val_categorical_accuracy: 0.5887\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9086 - categorical_accuracy: 0.5759 - val_loss: 0.8937 - val_categorical_accuracy: 0.5915\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9088 - categorical_accuracy: 0.5750 - val_loss: 0.8987 - val_categorical_accuracy: 0.5855\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9055 - categorical_accuracy: 0.5770 - val_loss: 0.8941 - val_categorical_accuracy: 0.5910\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9112 - categorical_accuracy: 0.5711 - val_loss: 0.8963 - val_categorical_accuracy: 0.5855\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9092 - categorical_accuracy: 0.5713 - val_loss: 0.8953 - val_categorical_accuracy: 0.5887\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9098 - categorical_accuracy: 0.5773 - val_loss: 0.8955 - val_categorical_accuracy: 0.5837\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 135us/step - loss: 0.9093 - categorical_accuracy: 0.5732 - val_loss: 0.8925 - val_categorical_accuracy: 0.5883\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9057 - categorical_accuracy: 0.5762 - val_loss: 0.8935 - val_categorical_accuracy: 0.5924\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 125us/step - loss: 0.9103 - categorical_accuracy: 0.5742 - val_loss: 0.8978 - val_categorical_accuracy: 0.5938\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9113 - categorical_accuracy: 0.5712 - val_loss: 0.9038 - val_categorical_accuracy: 0.5713\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9112 - categorical_accuracy: 0.5763 - val_loss: 0.8945 - val_categorical_accuracy: 0.5896\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 105us/step - loss: 0.9099 - categorical_accuracy: 0.5755 - val_loss: 0.8922 - val_categorical_accuracy: 0.5823\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9078 - categorical_accuracy: 0.5766 - val_loss: 0.8936 - val_categorical_accuracy: 0.5763\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9078 - categorical_accuracy: 0.5745 - val_loss: 0.8976 - val_categorical_accuracy: 0.5722\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9094 - categorical_accuracy: 0.5738 - val_loss: 0.8903 - val_categorical_accuracy: 0.5896\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9095 - categorical_accuracy: 0.5745 - val_loss: 0.8905 - val_categorical_accuracy: 0.5869\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9107 - categorical_accuracy: 0.5692 - val_loss: 0.8946 - val_categorical_accuracy: 0.5878\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9074 - categorical_accuracy: 0.5732 - val_loss: 0.8962 - val_categorical_accuracy: 0.5942\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9088 - categorical_accuracy: 0.5716 - val_loss: 0.9250 - val_categorical_accuracy: 0.5883\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9093 - categorical_accuracy: 0.5716 - val_loss: 0.9047 - val_categorical_accuracy: 0.5635\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9098 - categorical_accuracy: 0.5707 - val_loss: 0.9040 - val_categorical_accuracy: 0.5534\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9086 - categorical_accuracy: 0.5737 - val_loss: 0.8955 - val_categorical_accuracy: 0.5915\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 145us/step - loss: 0.9067 - categorical_accuracy: 0.5751 - val_loss: 0.8912 - val_categorical_accuracy: 0.5924\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 110us/step - loss: 0.9084 - categorical_accuracy: 0.5704 - val_loss: 0.8944 - val_categorical_accuracy: 0.5924\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 57.8125%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 3s 392us/step - loss: 1.4724 - categorical_accuracy: 0.4899 - val_loss: 0.9616 - val_categorical_accuracy: 0.5530\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 134us/step - loss: 1.0539 - categorical_accuracy: 0.5309 - val_loss: 0.9418 - val_categorical_accuracy: 0.5791\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 1.0042 - categorical_accuracy: 0.5395 - val_loss: 0.9321 - val_categorical_accuracy: 0.5598\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9879 - categorical_accuracy: 0.5494 - val_loss: 0.9190 - val_categorical_accuracy: 0.5768\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9735 - categorical_accuracy: 0.5486 - val_loss: 0.9574 - val_categorical_accuracy: 0.5612\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 116us/step - loss: 0.9456 - categorical_accuracy: 0.5542 - val_loss: 0.9135 - val_categorical_accuracy: 0.5754\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9303 - categorical_accuracy: 0.5652 - val_loss: 0.9176 - val_categorical_accuracy: 0.5768\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9331 - categorical_accuracy: 0.5630 - val_loss: 0.9131 - val_categorical_accuracy: 0.5796\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9264 - categorical_accuracy: 0.5634 - val_loss: 0.9249 - val_categorical_accuracy: 0.5672\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9148 - categorical_accuracy: 0.5692 - val_loss: 0.8999 - val_categorical_accuracy: 0.5883\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9151 - categorical_accuracy: 0.5669 - val_loss: 0.9166 - val_categorical_accuracy: 0.5796\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9134 - categorical_accuracy: 0.5753 - val_loss: 0.8985 - val_categorical_accuracy: 0.5883\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9165 - categorical_accuracy: 0.5713 - val_loss: 0.8959 - val_categorical_accuracy: 0.5901\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9149 - categorical_accuracy: 0.5742 - val_loss: 0.8954 - val_categorical_accuracy: 0.5873\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9110 - categorical_accuracy: 0.5757 - val_loss: 0.8970 - val_categorical_accuracy: 0.5892\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9144 - categorical_accuracy: 0.5687 - val_loss: 0.8973 - val_categorical_accuracy: 0.5864\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9191 - categorical_accuracy: 0.5695 - val_loss: 0.8961 - val_categorical_accuracy: 0.5919\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9137 - categorical_accuracy: 0.5752 - val_loss: 0.8983 - val_categorical_accuracy: 0.5910\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9131 - categorical_accuracy: 0.5750 - val_loss: 0.8999 - val_categorical_accuracy: 0.5860\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9171 - categorical_accuracy: 0.5689 - val_loss: 0.9027 - val_categorical_accuracy: 0.5860\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9118 - categorical_accuracy: 0.5754 - val_loss: 0.9033 - val_categorical_accuracy: 0.5814\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9121 - categorical_accuracy: 0.5759 - val_loss: 0.9069 - val_categorical_accuracy: 0.5818\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9107 - categorical_accuracy: 0.5707 - val_loss: 0.9046 - val_categorical_accuracy: 0.5896\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 111us/step - loss: 0.9133 - categorical_accuracy: 0.5726 - val_loss: 0.8944 - val_categorical_accuracy: 0.5910\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9103 - categorical_accuracy: 0.5710 - val_loss: 0.9095 - val_categorical_accuracy: 0.5878\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 108us/step - loss: 0.9139 - categorical_accuracy: 0.5740 - val_loss: 0.9084 - val_categorical_accuracy: 0.5887\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9092 - categorical_accuracy: 0.5760 - val_loss: 0.9038 - val_categorical_accuracy: 0.5901\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 114us/step - loss: 0.9092 - categorical_accuracy: 0.5762 - val_loss: 0.8983 - val_categorical_accuracy: 0.5906\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9111 - categorical_accuracy: 0.5680 - val_loss: 0.8955 - val_categorical_accuracy: 0.5919\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9092 - categorical_accuracy: 0.5751 - val_loss: 0.8964 - val_categorical_accuracy: 0.5901\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9091 - categorical_accuracy: 0.5711 - val_loss: 0.8948 - val_categorical_accuracy: 0.5956\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 114us/step - loss: 0.9127 - categorical_accuracy: 0.5703 - val_loss: 0.9206 - val_categorical_accuracy: 0.5805\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 129us/step - loss: 0.9118 - categorical_accuracy: 0.5718 - val_loss: 0.8991 - val_categorical_accuracy: 0.5915\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9120 - categorical_accuracy: 0.5761 - val_loss: 0.9124 - val_categorical_accuracy: 0.5878\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9087 - categorical_accuracy: 0.5730 - val_loss: 0.9092 - val_categorical_accuracy: 0.5814\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9100 - categorical_accuracy: 0.5735 - val_loss: 0.9059 - val_categorical_accuracy: 0.5878\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9097 - categorical_accuracy: 0.5730 - val_loss: 0.9032 - val_categorical_accuracy: 0.5919\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9084 - categorical_accuracy: 0.5762 - val_loss: 0.9081 - val_categorical_accuracy: 0.5841\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 159us/step - loss: 0.9116 - categorical_accuracy: 0.5758 - val_loss: 0.9215 - val_categorical_accuracy: 0.5837\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 129us/step - loss: 0.9097 - categorical_accuracy: 0.5747 - val_loss: 0.9013 - val_categorical_accuracy: 0.5892\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 141us/step - loss: 0.9097 - categorical_accuracy: 0.5739 - val_loss: 0.9181 - val_categorical_accuracy: 0.5892\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 2s 251us/step - loss: 0.9066 - categorical_accuracy: 0.5766 - val_loss: 0.9169 - val_categorical_accuracy: 0.5846\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 131us/step - loss: 0.9096 - categorical_accuracy: 0.5758 - val_loss: 0.8923 - val_categorical_accuracy: 0.5933\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 161us/step - loss: 0.9079 - categorical_accuracy: 0.5720 - val_loss: 0.8956 - val_categorical_accuracy: 0.5942\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 122us/step - loss: 0.9132 - categorical_accuracy: 0.5732 - val_loss: 0.9109 - val_categorical_accuracy: 0.5919\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 157us/step - loss: 0.9136 - categorical_accuracy: 0.5728 - val_loss: 0.9009 - val_categorical_accuracy: 0.5883\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9105 - categorical_accuracy: 0.5755 - val_loss: 0.9145 - val_categorical_accuracy: 0.5892\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9086 - categorical_accuracy: 0.5734 - val_loss: 0.9036 - val_categorical_accuracy: 0.5928\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 170us/step - loss: 0.9097 - categorical_accuracy: 0.5767 - val_loss: 0.9006 - val_categorical_accuracy: 0.5883\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 2s 174us/step - loss: 0.9083 - categorical_accuracy: 0.5728 - val_loss: 0.9051 - val_categorical_accuracy: 0.5878\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 62.5%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 3s 381us/step - loss: 1.3574 - categorical_accuracy: 0.4899 - val_loss: 0.9997 - val_categorical_accuracy: 0.5355\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9734 - categorical_accuracy: 0.5534 - val_loss: 0.9049 - val_categorical_accuracy: 0.5846\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9407 - categorical_accuracy: 0.5581 - val_loss: 0.8992 - val_categorical_accuracy: 0.5942\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9295 - categorical_accuracy: 0.5691 - val_loss: 0.9247 - val_categorical_accuracy: 0.5809\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9235 - categorical_accuracy: 0.5718 - val_loss: 0.9035 - val_categorical_accuracy: 0.5809\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 148us/step - loss: 0.9213 - categorical_accuracy: 0.5681 - val_loss: 0.9493 - val_categorical_accuracy: 0.5626\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9281 - categorical_accuracy: 0.5688 - val_loss: 0.9132 - val_categorical_accuracy: 0.5809\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9195 - categorical_accuracy: 0.5726 - val_loss: 0.9072 - val_categorical_accuracy: 0.5896\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9123 - categorical_accuracy: 0.5753 - val_loss: 0.9104 - val_categorical_accuracy: 0.5851\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9243 - categorical_accuracy: 0.5687 - val_loss: 0.9069 - val_categorical_accuracy: 0.5860\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9137 - categorical_accuracy: 0.5752 - val_loss: 0.8935 - val_categorical_accuracy: 0.5942\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9186 - categorical_accuracy: 0.5689 - val_loss: 0.9048 - val_categorical_accuracy: 0.5846\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9188 - categorical_accuracy: 0.5681 - val_loss: 0.9059 - val_categorical_accuracy: 0.5823\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9155 - categorical_accuracy: 0.5744 - val_loss: 0.9062 - val_categorical_accuracy: 0.5846\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9155 - categorical_accuracy: 0.5706 - val_loss: 0.9133 - val_categorical_accuracy: 0.5864\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9131 - categorical_accuracy: 0.5710 - val_loss: 0.8990 - val_categorical_accuracy: 0.5896\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9151 - categorical_accuracy: 0.5732 - val_loss: 0.8968 - val_categorical_accuracy: 0.5901\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 76us/step - loss: 0.9101 - categorical_accuracy: 0.5768 - val_loss: 0.9001 - val_categorical_accuracy: 0.5855\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 77us/step - loss: 0.9191 - categorical_accuracy: 0.5710 - val_loss: 0.8964 - val_categorical_accuracy: 0.5883\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9143 - categorical_accuracy: 0.5719 - val_loss: 0.9049 - val_categorical_accuracy: 0.5928\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 77us/step - loss: 0.9167 - categorical_accuracy: 0.5674 - val_loss: 0.9544 - val_categorical_accuracy: 0.5731\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9166 - categorical_accuracy: 0.5698 - val_loss: 0.9081 - val_categorical_accuracy: 0.5837\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 78us/step - loss: 0.9131 - categorical_accuracy: 0.5737 - val_loss: 0.8966 - val_categorical_accuracy: 0.5892\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 133us/step - loss: 0.9139 - categorical_accuracy: 0.5729 - val_loss: 0.8940 - val_categorical_accuracy: 0.5869\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9086 - categorical_accuracy: 0.5740 - val_loss: 0.8987 - val_categorical_accuracy: 0.5915\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9135 - categorical_accuracy: 0.5723 - val_loss: 0.9043 - val_categorical_accuracy: 0.5896\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 129us/step - loss: 0.9134 - categorical_accuracy: 0.5755 - val_loss: 0.9088 - val_categorical_accuracy: 0.5809\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 140us/step - loss: 0.9120 - categorical_accuracy: 0.5740 - val_loss: 0.8971 - val_categorical_accuracy: 0.5910\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9127 - categorical_accuracy: 0.5728 - val_loss: 0.8951 - val_categorical_accuracy: 0.5878\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9106 - categorical_accuracy: 0.5721 - val_loss: 0.9080 - val_categorical_accuracy: 0.5883\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9131 - categorical_accuracy: 0.5719 - val_loss: 0.8980 - val_categorical_accuracy: 0.5818\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9120 - categorical_accuracy: 0.5692 - val_loss: 0.9044 - val_categorical_accuracy: 0.5864\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9170 - categorical_accuracy: 0.5693 - val_loss: 0.8965 - val_categorical_accuracy: 0.5869\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9122 - categorical_accuracy: 0.5702 - val_loss: 0.9092 - val_categorical_accuracy: 0.5896\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9138 - categorical_accuracy: 0.5736 - val_loss: 0.8954 - val_categorical_accuracy: 0.5928\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9081 - categorical_accuracy: 0.5719 - val_loss: 0.8957 - val_categorical_accuracy: 0.5878\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9104 - categorical_accuracy: 0.5704 - val_loss: 0.8941 - val_categorical_accuracy: 0.5906\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9159 - categorical_accuracy: 0.5669 - val_loss: 0.9144 - val_categorical_accuracy: 0.5906\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9137 - categorical_accuracy: 0.5687 - val_loss: 0.8935 - val_categorical_accuracy: 0.5892\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9087 - categorical_accuracy: 0.5745 - val_loss: 0.9105 - val_categorical_accuracy: 0.5924\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9123 - categorical_accuracy: 0.5693 - val_loss: 0.8983 - val_categorical_accuracy: 0.5809\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9076 - categorical_accuracy: 0.5743 - val_loss: 0.8925 - val_categorical_accuracy: 0.5901\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 136us/step - loss: 0.9108 - categorical_accuracy: 0.5738 - val_loss: 0.8951 - val_categorical_accuracy: 0.5906\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 159us/step - loss: 0.9070 - categorical_accuracy: 0.5768 - val_loss: 0.9081 - val_categorical_accuracy: 0.5910\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9112 - categorical_accuracy: 0.5716 - val_loss: 0.8908 - val_categorical_accuracy: 0.5906\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9096 - categorical_accuracy: 0.5721 - val_loss: 0.8880 - val_categorical_accuracy: 0.5901\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9116 - categorical_accuracy: 0.5705 - val_loss: 0.9083 - val_categorical_accuracy: 0.5796\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9099 - categorical_accuracy: 0.5721 - val_loss: 0.9021 - val_categorical_accuracy: 0.5837\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9109 - categorical_accuracy: 0.5735 - val_loss: 0.8915 - val_categorical_accuracy: 0.5887\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9045 - categorical_accuracy: 0.5773 - val_loss: 0.9042 - val_categorical_accuracy: 0.5896\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 56.25%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 410us/step - loss: 5.7397 - categorical_accuracy: 0.4830 - val_loss: 1.0314 - val_categorical_accuracy: 0.5731\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9985 - categorical_accuracy: 0.5489 - val_loss: 0.9548 - val_categorical_accuracy: 0.5497\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9947 - categorical_accuracy: 0.5444 - val_loss: 0.9361 - val_categorical_accuracy: 0.5681\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9594 - categorical_accuracy: 0.5570 - val_loss: 0.9135 - val_categorical_accuracy: 0.5933\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9323 - categorical_accuracy: 0.5656 - val_loss: 0.9084 - val_categorical_accuracy: 0.5796\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9323 - categorical_accuracy: 0.5634 - val_loss: 0.9386 - val_categorical_accuracy: 0.5653\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9247 - categorical_accuracy: 0.5735 - val_loss: 0.9050 - val_categorical_accuracy: 0.5864\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9153 - categorical_accuracy: 0.5737 - val_loss: 0.9059 - val_categorical_accuracy: 0.5851\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 108us/step - loss: 0.9205 - categorical_accuracy: 0.5661 - val_loss: 0.9071 - val_categorical_accuracy: 0.5851\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9143 - categorical_accuracy: 0.5706 - val_loss: 0.9025 - val_categorical_accuracy: 0.5892\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9204 - categorical_accuracy: 0.5735 - val_loss: 0.8933 - val_categorical_accuracy: 0.5887\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9120 - categorical_accuracy: 0.5702 - val_loss: 0.9125 - val_categorical_accuracy: 0.5823\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9150 - categorical_accuracy: 0.5723 - val_loss: 0.9000 - val_categorical_accuracy: 0.5892\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9152 - categorical_accuracy: 0.5713 - val_loss: 0.8955 - val_categorical_accuracy: 0.5887\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 130us/step - loss: 0.9165 - categorical_accuracy: 0.5707 - val_loss: 0.8996 - val_categorical_accuracy: 0.5869\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9132 - categorical_accuracy: 0.5712 - val_loss: 0.8969 - val_categorical_accuracy: 0.5846\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9176 - categorical_accuracy: 0.5739 - val_loss: 0.8958 - val_categorical_accuracy: 0.5823\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9132 - categorical_accuracy: 0.5710 - val_loss: 0.9162 - val_categorical_accuracy: 0.5713\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 78us/step - loss: 0.9136 - categorical_accuracy: 0.5740 - val_loss: 0.8971 - val_categorical_accuracy: 0.5938\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 79us/step - loss: 0.9208 - categorical_accuracy: 0.5682 - val_loss: 0.8940 - val_categorical_accuracy: 0.5883\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9119 - categorical_accuracy: 0.5746 - val_loss: 0.8996 - val_categorical_accuracy: 0.5887\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9127 - categorical_accuracy: 0.5738 - val_loss: 0.9226 - val_categorical_accuracy: 0.5805\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9202 - categorical_accuracy: 0.5712 - val_loss: 0.8993 - val_categorical_accuracy: 0.5887\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9114 - categorical_accuracy: 0.5752 - val_loss: 0.8968 - val_categorical_accuracy: 0.5906\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9108 - categorical_accuracy: 0.5753 - val_loss: 0.9079 - val_categorical_accuracy: 0.5887\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9089 - categorical_accuracy: 0.5761 - val_loss: 0.8964 - val_categorical_accuracy: 0.5892\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9077 - categorical_accuracy: 0.5743 - val_loss: 0.8980 - val_categorical_accuracy: 0.5906\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9074 - categorical_accuracy: 0.5790 - val_loss: 0.9014 - val_categorical_accuracy: 0.5915\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9122 - categorical_accuracy: 0.5728 - val_loss: 0.9174 - val_categorical_accuracy: 0.5520\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9087 - categorical_accuracy: 0.5754 - val_loss: 0.8957 - val_categorical_accuracy: 0.5956\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9066 - categorical_accuracy: 0.5739 - val_loss: 0.9029 - val_categorical_accuracy: 0.5910\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9085 - categorical_accuracy: 0.5750 - val_loss: 0.8945 - val_categorical_accuracy: 0.5896\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9103 - categorical_accuracy: 0.5762 - val_loss: 0.8913 - val_categorical_accuracy: 0.5942\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9100 - categorical_accuracy: 0.5702 - val_loss: 0.9001 - val_categorical_accuracy: 0.5915\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9145 - categorical_accuracy: 0.5719 - val_loss: 0.8942 - val_categorical_accuracy: 0.5883\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9062 - categorical_accuracy: 0.5747 - val_loss: 0.9056 - val_categorical_accuracy: 0.5704\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9069 - categorical_accuracy: 0.5763 - val_loss: 0.9173 - val_categorical_accuracy: 0.5699\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9071 - categorical_accuracy: 0.5752 - val_loss: 0.9033 - val_categorical_accuracy: 0.5873\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9120 - categorical_accuracy: 0.5751 - val_loss: 0.8996 - val_categorical_accuracy: 0.5791\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9072 - categorical_accuracy: 0.5732 - val_loss: 0.9010 - val_categorical_accuracy: 0.5901\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9042 - categorical_accuracy: 0.5789 - val_loss: 0.9028 - val_categorical_accuracy: 0.5892\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9106 - categorical_accuracy: 0.5721 - val_loss: 0.9192 - val_categorical_accuracy: 0.5745\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 76us/step - loss: 0.9094 - categorical_accuracy: 0.5706 - val_loss: 0.8995 - val_categorical_accuracy: 0.5887\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 78us/step - loss: 0.9091 - categorical_accuracy: 0.5737 - val_loss: 0.9057 - val_categorical_accuracy: 0.5841\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 75us/step - loss: 0.9088 - categorical_accuracy: 0.5736 - val_loss: 0.9012 - val_categorical_accuracy: 0.5869\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9062 - categorical_accuracy: 0.5706 - val_loss: 0.9097 - val_categorical_accuracy: 0.5841\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9048 - categorical_accuracy: 0.5786 - val_loss: 0.9102 - val_categorical_accuracy: 0.5731\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 124us/step - loss: 0.9107 - categorical_accuracy: 0.5747 - val_loss: 0.9032 - val_categorical_accuracy: 0.5846\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9079 - categorical_accuracy: 0.5708 - val_loss: 0.9035 - val_categorical_accuracy: 0.5901\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9065 - categorical_accuracy: 0.5757 - val_loss: 0.9132 - val_categorical_accuracy: 0.5809\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 54.6875%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 451us/step - loss: 1.6523 - categorical_accuracy: 0.4820 - val_loss: 1.3013 - val_categorical_accuracy: 0.4915\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 1.1503 - categorical_accuracy: 0.5158 - val_loss: 0.9290 - val_categorical_accuracy: 0.5869\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 1.0476 - categorical_accuracy: 0.5392 - val_loss: 0.9909 - val_categorical_accuracy: 0.5126\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 1.0191 - categorical_accuracy: 0.5444 - val_loss: 0.9635 - val_categorical_accuracy: 0.5740\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 1.0253 - categorical_accuracy: 0.5449 - val_loss: 0.9627 - val_categorical_accuracy: 0.5617\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9723 - categorical_accuracy: 0.5430 - val_loss: 0.9736 - val_categorical_accuracy: 0.5245\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9613 - categorical_accuracy: 0.5551 - val_loss: 0.9070 - val_categorical_accuracy: 0.5823\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9583 - categorical_accuracy: 0.5572 - val_loss: 0.9433 - val_categorical_accuracy: 0.5878\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 121us/step - loss: 0.9387 - categorical_accuracy: 0.5605 - val_loss: 0.9552 - val_categorical_accuracy: 0.5731\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 114us/step - loss: 0.9301 - categorical_accuracy: 0.5674 - val_loss: 0.9271 - val_categorical_accuracy: 0.5759\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9408 - categorical_accuracy: 0.5597 - val_loss: 0.9299 - val_categorical_accuracy: 0.5695\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9235 - categorical_accuracy: 0.5696 - val_loss: 0.9228 - val_categorical_accuracy: 0.5841\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 122us/step - loss: 0.9156 - categorical_accuracy: 0.5724 - val_loss: 0.9038 - val_categorical_accuracy: 0.5915\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 80us/step - loss: 0.9164 - categorical_accuracy: 0.5696 - val_loss: 0.8980 - val_categorical_accuracy: 0.5933\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9150 - categorical_accuracy: 0.5707 - val_loss: 0.9019 - val_categorical_accuracy: 0.5910\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 130us/step - loss: 0.9117 - categorical_accuracy: 0.5706 - val_loss: 0.8945 - val_categorical_accuracy: 0.5892\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9137 - categorical_accuracy: 0.5693 - val_loss: 0.8958 - val_categorical_accuracy: 0.5938\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 139us/step - loss: 0.9131 - categorical_accuracy: 0.5712 - val_loss: 0.9048 - val_categorical_accuracy: 0.5832\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9129 - categorical_accuracy: 0.5723 - val_loss: 0.9132 - val_categorical_accuracy: 0.5800\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9127 - categorical_accuracy: 0.5710 - val_loss: 0.8985 - val_categorical_accuracy: 0.5878\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9113 - categorical_accuracy: 0.5746 - val_loss: 0.9360 - val_categorical_accuracy: 0.5630\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9181 - categorical_accuracy: 0.5673 - val_loss: 0.9001 - val_categorical_accuracy: 0.5800\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9147 - categorical_accuracy: 0.5730 - val_loss: 0.9249 - val_categorical_accuracy: 0.5763\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9122 - categorical_accuracy: 0.5721 - val_loss: 0.9163 - val_categorical_accuracy: 0.5763\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9099 - categorical_accuracy: 0.5742 - val_loss: 0.8891 - val_categorical_accuracy: 0.5910\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9116 - categorical_accuracy: 0.5767 - val_loss: 0.8985 - val_categorical_accuracy: 0.5938\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9105 - categorical_accuracy: 0.5735 - val_loss: 0.9096 - val_categorical_accuracy: 0.5846\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9096 - categorical_accuracy: 0.5712 - val_loss: 0.8927 - val_categorical_accuracy: 0.5892\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9115 - categorical_accuracy: 0.5739 - val_loss: 0.9215 - val_categorical_accuracy: 0.5805\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 122us/step - loss: 0.9108 - categorical_accuracy: 0.5747 - val_loss: 0.9034 - val_categorical_accuracy: 0.5910\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9113 - categorical_accuracy: 0.5718 - val_loss: 0.8946 - val_categorical_accuracy: 0.5878\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9137 - categorical_accuracy: 0.5676 - val_loss: 0.8966 - val_categorical_accuracy: 0.5828\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9164 - categorical_accuracy: 0.5692 - val_loss: 0.8979 - val_categorical_accuracy: 0.5883\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9124 - categorical_accuracy: 0.5715 - val_loss: 0.9041 - val_categorical_accuracy: 0.5786\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9140 - categorical_accuracy: 0.5747 - val_loss: 0.8882 - val_categorical_accuracy: 0.5942\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9132 - categorical_accuracy: 0.5724 - val_loss: 0.8974 - val_categorical_accuracy: 0.5906\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9104 - categorical_accuracy: 0.5760 - val_loss: 0.9126 - val_categorical_accuracy: 0.5851\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9151 - categorical_accuracy: 0.5732 - val_loss: 0.9066 - val_categorical_accuracy: 0.5704\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 132us/step - loss: 0.9118 - categorical_accuracy: 0.5716 - val_loss: 0.8950 - val_categorical_accuracy: 0.5887\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9102 - categorical_accuracy: 0.5723 - val_loss: 0.8948 - val_categorical_accuracy: 0.5901\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9104 - categorical_accuracy: 0.5738 - val_loss: 0.8917 - val_categorical_accuracy: 0.5864\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9083 - categorical_accuracy: 0.5765 - val_loss: 0.9035 - val_categorical_accuracy: 0.5906\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9097 - categorical_accuracy: 0.5723 - val_loss: 0.9125 - val_categorical_accuracy: 0.5878\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9141 - categorical_accuracy: 0.5727 - val_loss: 0.8918 - val_categorical_accuracy: 0.5841\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9078 - categorical_accuracy: 0.5774 - val_loss: 0.9132 - val_categorical_accuracy: 0.5805\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9121 - categorical_accuracy: 0.5688 - val_loss: 0.9066 - val_categorical_accuracy: 0.5841\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 158us/step - loss: 0.9076 - categorical_accuracy: 0.5747 - val_loss: 0.8983 - val_categorical_accuracy: 0.5906\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9083 - categorical_accuracy: 0.5708 - val_loss: 0.9150 - val_categorical_accuracy: 0.5589\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9102 - categorical_accuracy: 0.5719 - val_loss: 0.9130 - val_categorical_accuracy: 0.5878\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9079 - categorical_accuracy: 0.5747 - val_loss: 0.9186 - val_categorical_accuracy: 0.5786\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 53.125%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 484us/step - loss: 1.2568 - categorical_accuracy: 0.4993 - val_loss: 0.9948 - val_categorical_accuracy: 0.5030\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9901 - categorical_accuracy: 0.5450 - val_loss: 0.9314 - val_categorical_accuracy: 0.5841\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9512 - categorical_accuracy: 0.5603 - val_loss: 0.9001 - val_categorical_accuracy: 0.5901\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9361 - categorical_accuracy: 0.5614 - val_loss: 0.9691 - val_categorical_accuracy: 0.5461\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 146us/step - loss: 0.9297 - categorical_accuracy: 0.5675 - val_loss: 0.9073 - val_categorical_accuracy: 0.5796\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 162us/step - loss: 0.9231 - categorical_accuracy: 0.5668 - val_loss: 0.9221 - val_categorical_accuracy: 0.5763\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 154us/step - loss: 0.9161 - categorical_accuracy: 0.5715 - val_loss: 0.9229 - val_categorical_accuracy: 0.5773\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 160us/step - loss: 0.9171 - categorical_accuracy: 0.5692 - val_loss: 0.9123 - val_categorical_accuracy: 0.5777\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 165us/step - loss: 0.9123 - categorical_accuracy: 0.5745 - val_loss: 0.9046 - val_categorical_accuracy: 0.5896\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9139 - categorical_accuracy: 0.5714 - val_loss: 0.9115 - val_categorical_accuracy: 0.5809\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9140 - categorical_accuracy: 0.5719 - val_loss: 0.9147 - val_categorical_accuracy: 0.5782\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9140 - categorical_accuracy: 0.5713 - val_loss: 0.9006 - val_categorical_accuracy: 0.5910\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9137 - categorical_accuracy: 0.5728 - val_loss: 0.8928 - val_categorical_accuracy: 0.5869\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9172 - categorical_accuracy: 0.5714 - val_loss: 0.9090 - val_categorical_accuracy: 0.5791\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9119 - categorical_accuracy: 0.5723 - val_loss: 0.9136 - val_categorical_accuracy: 0.5864\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9100 - categorical_accuracy: 0.5689 - val_loss: 0.8979 - val_categorical_accuracy: 0.5887\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9106 - categorical_accuracy: 0.5742 - val_loss: 0.8887 - val_categorical_accuracy: 0.5951\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9114 - categorical_accuracy: 0.5751 - val_loss: 0.9018 - val_categorical_accuracy: 0.5906\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 118us/step - loss: 0.9130 - categorical_accuracy: 0.5714 - val_loss: 0.8951 - val_categorical_accuracy: 0.5928\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9130 - categorical_accuracy: 0.5751 - val_loss: 0.9004 - val_categorical_accuracy: 0.5892\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9131 - categorical_accuracy: 0.5762 - val_loss: 0.9169 - val_categorical_accuracy: 0.5841\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9128 - categorical_accuracy: 0.5699 - val_loss: 0.8956 - val_categorical_accuracy: 0.5910\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9112 - categorical_accuracy: 0.5722 - val_loss: 0.8933 - val_categorical_accuracy: 0.5901\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 132us/step - loss: 0.9075 - categorical_accuracy: 0.5791 - val_loss: 0.8987 - val_categorical_accuracy: 0.5814\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 133us/step - loss: 0.9092 - categorical_accuracy: 0.5770 - val_loss: 0.8943 - val_categorical_accuracy: 0.5846\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 108us/step - loss: 0.9094 - categorical_accuracy: 0.5768 - val_loss: 0.8921 - val_categorical_accuracy: 0.5896\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9115 - categorical_accuracy: 0.5775 - val_loss: 0.8952 - val_categorical_accuracy: 0.5942\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9073 - categorical_accuracy: 0.5760 - val_loss: 0.8978 - val_categorical_accuracy: 0.5851\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9091 - categorical_accuracy: 0.5726 - val_loss: 0.8975 - val_categorical_accuracy: 0.5864\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9122 - categorical_accuracy: 0.5674 - val_loss: 0.8957 - val_categorical_accuracy: 0.5896\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9126 - categorical_accuracy: 0.5704 - val_loss: 0.9006 - val_categorical_accuracy: 0.5685\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9113 - categorical_accuracy: 0.5726 - val_loss: 0.9125 - val_categorical_accuracy: 0.5841\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9061 - categorical_accuracy: 0.5754 - val_loss: 0.8878 - val_categorical_accuracy: 0.5942\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 143us/step - loss: 0.9112 - categorical_accuracy: 0.5705 - val_loss: 0.9026 - val_categorical_accuracy: 0.5878\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 117us/step - loss: 0.9088 - categorical_accuracy: 0.5755 - val_loss: 0.8998 - val_categorical_accuracy: 0.5919\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9111 - categorical_accuracy: 0.5718 - val_loss: 0.8902 - val_categorical_accuracy: 0.5892\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9067 - categorical_accuracy: 0.5737 - val_loss: 0.8945 - val_categorical_accuracy: 0.5851\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9080 - categorical_accuracy: 0.5770 - val_loss: 0.9072 - val_categorical_accuracy: 0.5589\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 165us/step - loss: 0.9084 - categorical_accuracy: 0.5731 - val_loss: 0.8938 - val_categorical_accuracy: 0.5883\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 2s 249us/step - loss: 0.9077 - categorical_accuracy: 0.5739 - val_loss: 0.8939 - val_categorical_accuracy: 0.5956\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 2s 244us/step - loss: 0.9075 - categorical_accuracy: 0.5759 - val_loss: 0.9040 - val_categorical_accuracy: 0.5860\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 2s 205us/step - loss: 0.9061 - categorical_accuracy: 0.5757 - val_loss: 0.9049 - val_categorical_accuracy: 0.5575\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 118us/step - loss: 0.9104 - categorical_accuracy: 0.5705 - val_loss: 0.8912 - val_categorical_accuracy: 0.5851\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 2s 183us/step - loss: 0.9065 - categorical_accuracy: 0.5710 - val_loss: 0.9025 - val_categorical_accuracy: 0.5658\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9111 - categorical_accuracy: 0.5728 - val_loss: 0.8986 - val_categorical_accuracy: 0.5786\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 108us/step - loss: 0.9080 - categorical_accuracy: 0.5738 - val_loss: 0.9010 - val_categorical_accuracy: 0.5708\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 164us/step - loss: 0.9133 - categorical_accuracy: 0.5658 - val_loss: 0.9057 - val_categorical_accuracy: 0.5855\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9059 - categorical_accuracy: 0.5759 - val_loss: 0.9086 - val_categorical_accuracy: 0.5800\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 149us/step - loss: 0.9090 - categorical_accuracy: 0.5730 - val_loss: 0.9074 - val_categorical_accuracy: 0.5630\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 128us/step - loss: 0.9070 - categorical_accuracy: 0.5762 - val_loss: 0.8916 - val_categorical_accuracy: 0.5928\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 53.125%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 410us/step - loss: 1.4501 - categorical_accuracy: 0.4951 - val_loss: 0.9455 - val_categorical_accuracy: 0.5713\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 1.0418 - categorical_accuracy: 0.5342 - val_loss: 0.9789 - val_categorical_accuracy: 0.5796\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 105us/step - loss: 1.0185 - categorical_accuracy: 0.5342 - val_loss: 0.9025 - val_categorical_accuracy: 0.5883\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 105us/step - loss: 0.9631 - categorical_accuracy: 0.5492 - val_loss: 0.9275 - val_categorical_accuracy: 0.5791\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9701 - categorical_accuracy: 0.5522 - val_loss: 1.0416 - val_categorical_accuracy: 0.5520\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9559 - categorical_accuracy: 0.5569 - val_loss: 0.9212 - val_categorical_accuracy: 0.5800\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9402 - categorical_accuracy: 0.5593 - val_loss: 0.9028 - val_categorical_accuracy: 0.5818\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9278 - categorical_accuracy: 0.5620 - val_loss: 0.9142 - val_categorical_accuracy: 0.5873\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9330 - categorical_accuracy: 0.5544 - val_loss: 0.9273 - val_categorical_accuracy: 0.5493\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9296 - categorical_accuracy: 0.5632 - val_loss: 0.8946 - val_categorical_accuracy: 0.5933\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 110us/step - loss: 0.9182 - categorical_accuracy: 0.5699 - val_loss: 0.8977 - val_categorical_accuracy: 0.5906\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9190 - categorical_accuracy: 0.5707 - val_loss: 0.9289 - val_categorical_accuracy: 0.5745\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9204 - categorical_accuracy: 0.5689 - val_loss: 0.9056 - val_categorical_accuracy: 0.5814\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9207 - categorical_accuracy: 0.5682 - val_loss: 0.9014 - val_categorical_accuracy: 0.5864\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9141 - categorical_accuracy: 0.5710 - val_loss: 0.9016 - val_categorical_accuracy: 0.5883\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9190 - categorical_accuracy: 0.5734 - val_loss: 0.9046 - val_categorical_accuracy: 0.5841\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9133 - categorical_accuracy: 0.5712 - val_loss: 0.8989 - val_categorical_accuracy: 0.5864\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9099 - categorical_accuracy: 0.5693 - val_loss: 0.9100 - val_categorical_accuracy: 0.5873\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9145 - categorical_accuracy: 0.5728 - val_loss: 0.8932 - val_categorical_accuracy: 0.5855\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9133 - categorical_accuracy: 0.5731 - val_loss: 0.9201 - val_categorical_accuracy: 0.5869\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9126 - categorical_accuracy: 0.5722 - val_loss: 0.9165 - val_categorical_accuracy: 0.5745\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9101 - categorical_accuracy: 0.5738 - val_loss: 0.8895 - val_categorical_accuracy: 0.5919\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9114 - categorical_accuracy: 0.5696 - val_loss: 0.8987 - val_categorical_accuracy: 0.5892\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 156us/step - loss: 0.9101 - categorical_accuracy: 0.5716 - val_loss: 0.8916 - val_categorical_accuracy: 0.5910\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9132 - categorical_accuracy: 0.5708 - val_loss: 0.8909 - val_categorical_accuracy: 0.5938\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9085 - categorical_accuracy: 0.5757 - val_loss: 0.9008 - val_categorical_accuracy: 0.5823\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 117us/step - loss: 0.9076 - categorical_accuracy: 0.5762 - val_loss: 0.9029 - val_categorical_accuracy: 0.5855\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 2s 174us/step - loss: 0.9141 - categorical_accuracy: 0.5718 - val_loss: 0.9006 - val_categorical_accuracy: 0.5864\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9151 - categorical_accuracy: 0.5707 - val_loss: 0.9080 - val_categorical_accuracy: 0.5791\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9121 - categorical_accuracy: 0.5724 - val_loss: 0.9067 - val_categorical_accuracy: 0.5786\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9134 - categorical_accuracy: 0.5705 - val_loss: 0.9108 - val_categorical_accuracy: 0.5718\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 152us/step - loss: 0.9107 - categorical_accuracy: 0.5746 - val_loss: 0.8988 - val_categorical_accuracy: 0.5947\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9088 - categorical_accuracy: 0.5765 - val_loss: 0.8902 - val_categorical_accuracy: 0.5851\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 105us/step - loss: 0.9107 - categorical_accuracy: 0.5752 - val_loss: 0.8912 - val_categorical_accuracy: 0.5892\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9093 - categorical_accuracy: 0.5751 - val_loss: 0.8912 - val_categorical_accuracy: 0.5910\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9115 - categorical_accuracy: 0.5743 - val_loss: 0.9065 - val_categorical_accuracy: 0.5814\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9119 - categorical_accuracy: 0.5740 - val_loss: 0.8882 - val_categorical_accuracy: 0.5910\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9099 - categorical_accuracy: 0.5734 - val_loss: 0.9191 - val_categorical_accuracy: 0.5672\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9105 - categorical_accuracy: 0.5716 - val_loss: 0.8918 - val_categorical_accuracy: 0.5883\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 105us/step - loss: 0.9128 - categorical_accuracy: 0.5702 - val_loss: 0.9109 - val_categorical_accuracy: 0.5878\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 134us/step - loss: 0.9110 - categorical_accuracy: 0.5734 - val_loss: 0.9103 - val_categorical_accuracy: 0.5796\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 111us/step - loss: 0.9093 - categorical_accuracy: 0.5735 - val_loss: 0.9054 - val_categorical_accuracy: 0.5892\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 134us/step - loss: 0.9085 - categorical_accuracy: 0.5768 - val_loss: 0.9087 - val_categorical_accuracy: 0.5860\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9107 - categorical_accuracy: 0.5760 - val_loss: 0.8912 - val_categorical_accuracy: 0.5901\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9120 - categorical_accuracy: 0.5714 - val_loss: 0.8928 - val_categorical_accuracy: 0.5892\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 137us/step - loss: 0.9091 - categorical_accuracy: 0.5755 - val_loss: 0.8893 - val_categorical_accuracy: 0.5938\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9075 - categorical_accuracy: 0.5749 - val_loss: 0.9101 - val_categorical_accuracy: 0.5873\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9096 - categorical_accuracy: 0.5786 - val_loss: 0.8953 - val_categorical_accuracy: 0.5915\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9067 - categorical_accuracy: 0.5724 - val_loss: 0.8977 - val_categorical_accuracy: 0.5869\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 137us/step - loss: 0.9092 - categorical_accuracy: 0.5766 - val_loss: 0.9239 - val_categorical_accuracy: 0.5814\n",
      "Done\n",
      "Neural Network Prediction Accuracy (WIGGO): 50.0%\n"
     ]
    }
   ],
   "source": [
    "sample_wiggo = [np.nan]*10\n",
    "\n",
    "for sample in range(len(sample_wiggo)):\n",
    "    model = run_nn(X_train_wiggo, y_train_wiggo, e=50)\n",
    "    \n",
    "    sample_wiggo[sample] = test_nn(model, X_test_wiggo, y_test_wiggo, \"WIGGO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60.9375, 59.375, 62.5, 57.8125, 62.5, 56.25, 54.6875, 53.125, 53.125, 50.0]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_wiggo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIGGO Average Test Accuracy (10 Identical Neural Networks): 57.03125%\n"
     ]
    }
   ],
   "source": [
    "print(\"WIGGO Average Test Accuracy (10 Identical Neural Networks): {0}%\".format(np.mean(sample_wiggo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 422us/step - loss: 1.4282 - categorical_accuracy: 0.4665 - val_loss: 1.0520 - val_categorical_accuracy: 0.4842\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 154us/step - loss: 1.0605 - categorical_accuracy: 0.5170 - val_loss: 1.0588 - val_categorical_accuracy: 0.5589\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 116us/step - loss: 1.0112 - categorical_accuracy: 0.5354 - val_loss: 0.9910 - val_categorical_accuracy: 0.5539\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 110us/step - loss: 1.0359 - categorical_accuracy: 0.5291 - val_loss: 0.9653 - val_categorical_accuracy: 0.5328\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9792 - categorical_accuracy: 0.5476 - val_loss: 0.9622 - val_categorical_accuracy: 0.5589\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9694 - categorical_accuracy: 0.5477 - val_loss: 0.9828 - val_categorical_accuracy: 0.5360\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9618 - categorical_accuracy: 0.5531 - val_loss: 0.9470 - val_categorical_accuracy: 0.5488\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9492 - categorical_accuracy: 0.5569 - val_loss: 0.9681 - val_categorical_accuracy: 0.5676\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9408 - categorical_accuracy: 0.5596 - val_loss: 0.9296 - val_categorical_accuracy: 0.5598\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9490 - categorical_accuracy: 0.5567 - val_loss: 0.9377 - val_categorical_accuracy: 0.5617\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 2s 177us/step - loss: 0.9393 - categorical_accuracy: 0.5635 - val_loss: 0.9277 - val_categorical_accuracy: 0.5653\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 159us/step - loss: 0.9337 - categorical_accuracy: 0.5672 - val_loss: 0.9344 - val_categorical_accuracy: 0.5621\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 140us/step - loss: 0.9373 - categorical_accuracy: 0.5635 - val_loss: 0.9262 - val_categorical_accuracy: 0.5681\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 105us/step - loss: 0.9382 - categorical_accuracy: 0.5596 - val_loss: 0.9274 - val_categorical_accuracy: 0.5663\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 123us/step - loss: 0.9341 - categorical_accuracy: 0.5641 - val_loss: 0.9337 - val_categorical_accuracy: 0.5695\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 116us/step - loss: 0.9365 - categorical_accuracy: 0.5664 - val_loss: 0.9242 - val_categorical_accuracy: 0.5699\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 150us/step - loss: 0.9377 - categorical_accuracy: 0.5605 - val_loss: 0.9368 - val_categorical_accuracy: 0.5612\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9337 - categorical_accuracy: 0.5641 - val_loss: 0.9300 - val_categorical_accuracy: 0.5681\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 150us/step - loss: 0.9330 - categorical_accuracy: 0.5641 - val_loss: 0.9310 - val_categorical_accuracy: 0.5667\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9360 - categorical_accuracy: 0.5622 - val_loss: 0.9303 - val_categorical_accuracy: 0.5658\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9355 - categorical_accuracy: 0.5610 - val_loss: 0.9282 - val_categorical_accuracy: 0.5731\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9315 - categorical_accuracy: 0.5665 - val_loss: 0.9312 - val_categorical_accuracy: 0.5681\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9327 - categorical_accuracy: 0.5683 - val_loss: 0.9390 - val_categorical_accuracy: 0.5575\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9323 - categorical_accuracy: 0.5668 - val_loss: 0.9382 - val_categorical_accuracy: 0.5672\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9317 - categorical_accuracy: 0.5692 - val_loss: 0.9310 - val_categorical_accuracy: 0.5695\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 123us/step - loss: 0.9372 - categorical_accuracy: 0.5652 - val_loss: 0.9327 - val_categorical_accuracy: 0.5612\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9328 - categorical_accuracy: 0.5642 - val_loss: 0.9366 - val_categorical_accuracy: 0.5690\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9318 - categorical_accuracy: 0.5680 - val_loss: 0.9283 - val_categorical_accuracy: 0.5667\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9319 - categorical_accuracy: 0.5684 - val_loss: 0.9428 - val_categorical_accuracy: 0.5681\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9360 - categorical_accuracy: 0.5672 - val_loss: 0.9373 - val_categorical_accuracy: 0.5658 - loss: 0.9317 - categorical_accuracy\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9309 - categorical_accuracy: 0.5661 - val_loss: 0.9344 - val_categorical_accuracy: 0.5681\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9326 - categorical_accuracy: 0.5664 - val_loss: 0.9376 - val_categorical_accuracy: 0.5676\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9295 - categorical_accuracy: 0.5695 - val_loss: 0.9291 - val_categorical_accuracy: 0.5644\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9309 - categorical_accuracy: 0.5665 - val_loss: 0.9331 - val_categorical_accuracy: 0.5676\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9303 - categorical_accuracy: 0.5667 - val_loss: 0.9306 - val_categorical_accuracy: 0.5649\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9283 - categorical_accuracy: 0.5707 - val_loss: 0.9528 - val_categorical_accuracy: 0.5580\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9301 - categorical_accuracy: 0.5659 - val_loss: 0.9383 - val_categorical_accuracy: 0.5644\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 125us/step - loss: 0.9320 - categorical_accuracy: 0.5687 - val_loss: 0.9382 - val_categorical_accuracy: 0.5621\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9310 - categorical_accuracy: 0.5661 - val_loss: 0.9367 - val_categorical_accuracy: 0.5580\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 143us/step - loss: 0.9292 - categorical_accuracy: 0.5674 - val_loss: 0.9369 - val_categorical_accuracy: 0.5635\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9277 - categorical_accuracy: 0.5698 - val_loss: 0.9460 - val_categorical_accuracy: 0.5502\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9306 - categorical_accuracy: 0.5667 - val_loss: 0.9346 - val_categorical_accuracy: 0.5580\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9267 - categorical_accuracy: 0.5687 - val_loss: 0.9433 - val_categorical_accuracy: 0.5663\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9270 - categorical_accuracy: 0.5655 - val_loss: 0.9355 - val_categorical_accuracy: 0.5617\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9254 - categorical_accuracy: 0.5705 - val_loss: 0.9452 - val_categorical_accuracy: 0.5621\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9268 - categorical_accuracy: 0.5696 - val_loss: 0.9553 - val_categorical_accuracy: 0.5621\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9268 - categorical_accuracy: 0.5707 - val_loss: 0.9352 - val_categorical_accuracy: 0.5598\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9238 - categorical_accuracy: 0.5726 - val_loss: 0.9548 - val_categorical_accuracy: 0.5630\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9254 - categorical_accuracy: 0.5687 - val_loss: 0.9358 - val_categorical_accuracy: 0.5585\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9296 - categorical_accuracy: 0.5699 - val_loss: 0.9413 - val_categorical_accuracy: 0.5585\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 53.125%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 456us/step - loss: 1.4748 - categorical_accuracy: 0.4731 - val_loss: 0.9907 - val_categorical_accuracy: 0.5580\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 1.0540 - categorical_accuracy: 0.5269 - val_loss: 0.9586 - val_categorical_accuracy: 0.5525\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 1.0092 - categorical_accuracy: 0.5377 - val_loss: 0.9966 - val_categorical_accuracy: 0.5585\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9896 - categorical_accuracy: 0.5468 - val_loss: 0.9560 - val_categorical_accuracy: 0.5429\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9775 - categorical_accuracy: 0.5465 - val_loss: 0.9621 - val_categorical_accuracy: 0.5589\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9620 - categorical_accuracy: 0.5504 - val_loss: 0.9370 - val_categorical_accuracy: 0.5695\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9638 - categorical_accuracy: 0.5536 - val_loss: 0.9402 - val_categorical_accuracy: 0.5685\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9563 - categorical_accuracy: 0.5555 - val_loss: 0.9306 - val_categorical_accuracy: 0.5672\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9422 - categorical_accuracy: 0.5633 - val_loss: 0.9267 - val_categorical_accuracy: 0.5672\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9391 - categorical_accuracy: 0.5632 - val_loss: 0.9279 - val_categorical_accuracy: 0.5640\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9373 - categorical_accuracy: 0.5624 - val_loss: 0.9410 - val_categorical_accuracy: 0.5640\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 137us/step - loss: 0.9397 - categorical_accuracy: 0.5625 - val_loss: 0.9427 - val_categorical_accuracy: 0.5663\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9377 - categorical_accuracy: 0.5628 - val_loss: 0.9327 - val_categorical_accuracy: 0.5640\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9341 - categorical_accuracy: 0.5636 - val_loss: 0.9277 - val_categorical_accuracy: 0.5653\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 160us/step - loss: 0.9380 - categorical_accuracy: 0.5660 - val_loss: 0.9208 - val_categorical_accuracy: 0.5663\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 114us/step - loss: 0.9368 - categorical_accuracy: 0.5651 - val_loss: 0.9266 - val_categorical_accuracy: 0.5649\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9407 - categorical_accuracy: 0.5626 - val_loss: 0.9234 - val_categorical_accuracy: 0.5667\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9371 - categorical_accuracy: 0.5614 - val_loss: 0.9330 - val_categorical_accuracy: 0.5722\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9361 - categorical_accuracy: 0.5630 - val_loss: 0.9382 - val_categorical_accuracy: 0.5653\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9371 - categorical_accuracy: 0.5659 - val_loss: 0.9245 - val_categorical_accuracy: 0.5663\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9356 - categorical_accuracy: 0.5661 - val_loss: 0.9357 - val_categorical_accuracy: 0.5649\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 129us/step - loss: 0.9351 - categorical_accuracy: 0.5646 - val_loss: 0.9311 - val_categorical_accuracy: 0.5594\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 140us/step - loss: 0.9382 - categorical_accuracy: 0.5612 - val_loss: 0.9311 - val_categorical_accuracy: 0.5681\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9317 - categorical_accuracy: 0.5657 - val_loss: 0.9276 - val_categorical_accuracy: 0.5695\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9328 - categorical_accuracy: 0.5669 - val_loss: 0.9347 - val_categorical_accuracy: 0.5663\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9321 - categorical_accuracy: 0.5660 - val_loss: 0.9510 - val_categorical_accuracy: 0.5626\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 138us/step - loss: 0.9375 - categorical_accuracy: 0.5642 - val_loss: 0.9525 - val_categorical_accuracy: 0.5575\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9354 - categorical_accuracy: 0.5621 - val_loss: 0.9476 - val_categorical_accuracy: 0.5612\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9325 - categorical_accuracy: 0.5665 - val_loss: 0.9318 - val_categorical_accuracy: 0.5585\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9315 - categorical_accuracy: 0.5643 - val_loss: 0.9340 - val_categorical_accuracy: 0.5658\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9341 - categorical_accuracy: 0.5672 - val_loss: 0.9284 - val_categorical_accuracy: 0.5663\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9336 - categorical_accuracy: 0.5671 - val_loss: 0.9291 - val_categorical_accuracy: 0.5649\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9316 - categorical_accuracy: 0.5618 - val_loss: 0.9318 - val_categorical_accuracy: 0.5603\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9336 - categorical_accuracy: 0.5665 - val_loss: 0.9367 - val_categorical_accuracy: 0.5598\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9338 - categorical_accuracy: 0.5652 - val_loss: 0.9303 - val_categorical_accuracy: 0.5612\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9308 - categorical_accuracy: 0.5643 - val_loss: 0.9305 - val_categorical_accuracy: 0.5722\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9288 - categorical_accuracy: 0.5665 - val_loss: 0.9437 - val_categorical_accuracy: 0.5630\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 122us/step - loss: 0.9293 - categorical_accuracy: 0.5699 - val_loss: 0.9294 - val_categorical_accuracy: 0.5626\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 133us/step - loss: 0.9278 - categorical_accuracy: 0.5668 - val_loss: 0.9334 - val_categorical_accuracy: 0.5589\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9278 - categorical_accuracy: 0.5664 - val_loss: 0.9342 - val_categorical_accuracy: 0.5617\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9267 - categorical_accuracy: 0.5684 - val_loss: 0.9360 - val_categorical_accuracy: 0.5630\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9321 - categorical_accuracy: 0.5637 - val_loss: 0.9474 - val_categorical_accuracy: 0.5621\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9262 - categorical_accuracy: 0.5712 - val_loss: 0.9316 - val_categorical_accuracy: 0.5630\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9278 - categorical_accuracy: 0.5674 - val_loss: 0.9324 - val_categorical_accuracy: 0.5585\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9294 - categorical_accuracy: 0.5672 - val_loss: 0.9364 - val_categorical_accuracy: 0.5690\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 124us/step - loss: 0.9273 - categorical_accuracy: 0.5672 - val_loss: 0.9387 - val_categorical_accuracy: 0.5621\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9251 - categorical_accuracy: 0.5691 - val_loss: 0.9398 - val_categorical_accuracy: 0.5672\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 148us/step - loss: 0.9252 - categorical_accuracy: 0.5661 - val_loss: 0.9422 - val_categorical_accuracy: 0.5676\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 2s 251us/step - loss: 0.9264 - categorical_accuracy: 0.5689 - val_loss: 0.9461 - val_categorical_accuracy: 0.5585\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9236 - categorical_accuracy: 0.5713 - val_loss: 0.9318 - val_categorical_accuracy: 0.5695\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 51.5625%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 455us/step - loss: 1.4112 - categorical_accuracy: 0.4911 - val_loss: 0.9769 - val_categorical_accuracy: 0.5608\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 1.0014 - categorical_accuracy: 0.5358 - val_loss: 0.9442 - val_categorical_accuracy: 0.5626\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 2s 196us/step - loss: 0.9757 - categorical_accuracy: 0.5497 - val_loss: 0.9639 - val_categorical_accuracy: 0.5612\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9608 - categorical_accuracy: 0.5548 - val_loss: 0.9411 - val_categorical_accuracy: 0.5571\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9575 - categorical_accuracy: 0.5559 - val_loss: 0.9328 - val_categorical_accuracy: 0.5594\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9472 - categorical_accuracy: 0.5591 - val_loss: 0.9403 - val_categorical_accuracy: 0.5649\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9443 - categorical_accuracy: 0.5582 - val_loss: 0.9354 - val_categorical_accuracy: 0.5617\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9439 - categorical_accuracy: 0.5585 - val_loss: 0.9277 - val_categorical_accuracy: 0.5667\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9441 - categorical_accuracy: 0.5617 - val_loss: 0.9873 - val_categorical_accuracy: 0.5603\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9466 - categorical_accuracy: 0.5574 - val_loss: 0.9319 - val_categorical_accuracy: 0.5617\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9403 - categorical_accuracy: 0.5588 - val_loss: 0.9325 - val_categorical_accuracy: 0.5612\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9424 - categorical_accuracy: 0.5566 - val_loss: 0.9250 - val_categorical_accuracy: 0.5676\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9398 - categorical_accuracy: 0.5590 - val_loss: 0.9347 - val_categorical_accuracy: 0.5617\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9400 - categorical_accuracy: 0.5636 - val_loss: 0.9304 - val_categorical_accuracy: 0.5690\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9413 - categorical_accuracy: 0.5648 - val_loss: 0.9231 - val_categorical_accuracy: 0.5672\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9428 - categorical_accuracy: 0.5570 - val_loss: 0.9400 - val_categorical_accuracy: 0.5507\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9415 - categorical_accuracy: 0.5605 - val_loss: 0.9324 - val_categorical_accuracy: 0.5663\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9457 - categorical_accuracy: 0.5580 - val_loss: 0.9277 - val_categorical_accuracy: 0.5676\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9406 - categorical_accuracy: 0.5593 - val_loss: 0.9380 - val_categorical_accuracy: 0.5617\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9391 - categorical_accuracy: 0.5620 - val_loss: 0.9315 - val_categorical_accuracy: 0.5598\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9412 - categorical_accuracy: 0.5602 - val_loss: 0.9411 - val_categorical_accuracy: 0.5571\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9377 - categorical_accuracy: 0.5596 - val_loss: 0.9302 - val_categorical_accuracy: 0.5644\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9346 - categorical_accuracy: 0.5611 - val_loss: 0.9288 - val_categorical_accuracy: 0.5690\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9368 - categorical_accuracy: 0.5640 - val_loss: 0.9320 - val_categorical_accuracy: 0.5640\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9366 - categorical_accuracy: 0.5620 - val_loss: 0.9359 - val_categorical_accuracy: 0.5608\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9368 - categorical_accuracy: 0.5625 - val_loss: 0.9261 - val_categorical_accuracy: 0.5649\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9340 - categorical_accuracy: 0.5652 - val_loss: 0.9319 - val_categorical_accuracy: 0.5644\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9371 - categorical_accuracy: 0.5624 - val_loss: 0.9318 - val_categorical_accuracy: 0.5630\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9370 - categorical_accuracy: 0.5628 - val_loss: 0.9348 - val_categorical_accuracy: 0.5644\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9339 - categorical_accuracy: 0.5644 - val_loss: 0.9275 - val_categorical_accuracy: 0.5640\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9354 - categorical_accuracy: 0.5681 - val_loss: 0.9323 - val_categorical_accuracy: 0.5672\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9331 - categorical_accuracy: 0.5635 - val_loss: 0.9275 - val_categorical_accuracy: 0.5713\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9336 - categorical_accuracy: 0.5646 - val_loss: 0.9276 - val_categorical_accuracy: 0.5630\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - ETA: 0s - loss: 0.9375 - categorical_accuracy: 0.55 - 1s 94us/step - loss: 0.9373 - categorical_accuracy: 0.5599 - val_loss: 0.9294 - val_categorical_accuracy: 0.5649\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9344 - categorical_accuracy: 0.5656 - val_loss: 0.9297 - val_categorical_accuracy: 0.5649\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9358 - categorical_accuracy: 0.5627 - val_loss: 0.9330 - val_categorical_accuracy: 0.5667\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9344 - categorical_accuracy: 0.5645 - val_loss: 0.9390 - val_categorical_accuracy: 0.5667\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9353 - categorical_accuracy: 0.5663 - val_loss: 0.9357 - val_categorical_accuracy: 0.5658\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9312 - categorical_accuracy: 0.5635 - val_loss: 0.9262 - val_categorical_accuracy: 0.5704\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9334 - categorical_accuracy: 0.5594 - val_loss: 0.9349 - val_categorical_accuracy: 0.5676\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9292 - categorical_accuracy: 0.5642 - val_loss: 0.9406 - val_categorical_accuracy: 0.5658\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9333 - categorical_accuracy: 0.5629 - val_loss: 0.9319 - val_categorical_accuracy: 0.5663\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9330 - categorical_accuracy: 0.5652 - val_loss: 0.9385 - val_categorical_accuracy: 0.5690\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9279 - categorical_accuracy: 0.5665 - val_loss: 0.9333 - val_categorical_accuracy: 0.5630\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 2s 191us/step - loss: 0.9360 - categorical_accuracy: 0.5632 - val_loss: 0.9372 - val_categorical_accuracy: 0.5630\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 122us/step - loss: 0.9283 - categorical_accuracy: 0.5690 - val_loss: 0.9374 - val_categorical_accuracy: 0.5594\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9320 - categorical_accuracy: 0.5679 - val_loss: 0.9300 - val_categorical_accuracy: 0.5635\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9296 - categorical_accuracy: 0.5669 - val_loss: 0.9390 - val_categorical_accuracy: 0.5644\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9299 - categorical_accuracy: 0.5611 - val_loss: 0.9365 - val_categorical_accuracy: 0.5649\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9280 - categorical_accuracy: 0.5666 - val_loss: 0.9281 - val_categorical_accuracy: 0.5663\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 51.5625%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 411us/step - loss: 1.3131 - categorical_accuracy: 0.4856 - val_loss: 0.9704 - val_categorical_accuracy: 0.5424\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 1.0470 - categorical_accuracy: 0.5246 - val_loss: 0.9671 - val_categorical_accuracy: 0.5401\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 129us/step - loss: 0.9902 - categorical_accuracy: 0.5428 - val_loss: 0.9653 - val_categorical_accuracy: 0.5465\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - ETA: 0s - loss: 0.9715 - categorical_accuracy: 0.54 - 1s 94us/step - loss: 0.9724 - categorical_accuracy: 0.5491 - val_loss: 0.9350 - val_categorical_accuracy: 0.5516\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9616 - categorical_accuracy: 0.5557 - val_loss: 0.9439 - val_categorical_accuracy: 0.5676\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9572 - categorical_accuracy: 0.5577 - val_loss: 0.9326 - val_categorical_accuracy: 0.5603\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9499 - categorical_accuracy: 0.5559 - val_loss: 0.9283 - val_categorical_accuracy: 0.5653\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 111us/step - loss: 0.9447 - categorical_accuracy: 0.5599 - val_loss: 0.9269 - val_categorical_accuracy: 0.5608\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9396 - categorical_accuracy: 0.5618 - val_loss: 0.9340 - val_categorical_accuracy: 0.5598\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9410 - categorical_accuracy: 0.5612 - val_loss: 0.9297 - val_categorical_accuracy: 0.5626\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9412 - categorical_accuracy: 0.5594 - val_loss: 0.9302 - val_categorical_accuracy: 0.5713\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9403 - categorical_accuracy: 0.5630 - val_loss: 0.9606 - val_categorical_accuracy: 0.5530\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9421 - categorical_accuracy: 0.5598 - val_loss: 0.9267 - val_categorical_accuracy: 0.5681\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9386 - categorical_accuracy: 0.5609 - val_loss: 0.9575 - val_categorical_accuracy: 0.5525\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9417 - categorical_accuracy: 0.5595 - val_loss: 0.9377 - val_categorical_accuracy: 0.5644\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9376 - categorical_accuracy: 0.5630 - val_loss: 0.9326 - val_categorical_accuracy: 0.5603\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 144us/step - loss: 0.9378 - categorical_accuracy: 0.5619 - val_loss: 0.9337 - val_categorical_accuracy: 0.5608\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9404 - categorical_accuracy: 0.5594 - val_loss: 0.9488 - val_categorical_accuracy: 0.5621\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9439 - categorical_accuracy: 0.5613 - val_loss: 0.9410 - val_categorical_accuracy: 0.5685\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9409 - categorical_accuracy: 0.5597 - val_loss: 0.9268 - val_categorical_accuracy: 0.5608\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9358 - categorical_accuracy: 0.5628 - val_loss: 0.9281 - val_categorical_accuracy: 0.5676\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9363 - categorical_accuracy: 0.5612 - val_loss: 0.9346 - val_categorical_accuracy: 0.5566\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9372 - categorical_accuracy: 0.5618 - val_loss: 0.9309 - val_categorical_accuracy: 0.5690\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9371 - categorical_accuracy: 0.5633 - val_loss: 0.9350 - val_categorical_accuracy: 0.5617\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 170us/step - loss: 0.9411 - categorical_accuracy: 0.5632 - val_loss: 0.9271 - val_categorical_accuracy: 0.5640\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9362 - categorical_accuracy: 0.5614 - val_loss: 0.9382 - val_categorical_accuracy: 0.5704\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9380 - categorical_accuracy: 0.5609 - val_loss: 0.9461 - val_categorical_accuracy: 0.5589\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 121us/step - loss: 0.9379 - categorical_accuracy: 0.5609 - val_loss: 0.9312 - val_categorical_accuracy: 0.5626\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 118us/step - loss: 0.9341 - categorical_accuracy: 0.5613 - val_loss: 0.9290 - val_categorical_accuracy: 0.5699\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 138us/step - loss: 0.9390 - categorical_accuracy: 0.5589 - val_loss: 0.9326 - val_categorical_accuracy: 0.5626\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 162us/step - loss: 0.9350 - categorical_accuracy: 0.5635 - val_loss: 0.9418 - val_categorical_accuracy: 0.5672\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 155us/step - loss: 0.9317 - categorical_accuracy: 0.5610 - val_loss: 0.9341 - val_categorical_accuracy: 0.5598\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 167us/step - loss: 0.9345 - categorical_accuracy: 0.5624 - val_loss: 0.9293 - val_categorical_accuracy: 0.5695\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 160us/step - loss: 0.9339 - categorical_accuracy: 0.5649 - val_loss: 0.9319 - val_categorical_accuracy: 0.5672\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9316 - categorical_accuracy: 0.5669 - val_loss: 0.9284 - val_categorical_accuracy: 0.5663\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9311 - categorical_accuracy: 0.5629 - val_loss: 0.9417 - val_categorical_accuracy: 0.5598\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 139us/step - loss: 0.9303 - categorical_accuracy: 0.5618 - val_loss: 0.9311 - val_categorical_accuracy: 0.5626\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 163us/step - loss: 0.9316 - categorical_accuracy: 0.5637 - val_loss: 0.9259 - val_categorical_accuracy: 0.5685\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 145us/step - loss: 0.9308 - categorical_accuracy: 0.5650 - val_loss: 0.9375 - val_categorical_accuracy: 0.5672\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 168us/step - loss: 0.9296 - categorical_accuracy: 0.5676 - val_loss: 0.9326 - val_categorical_accuracy: 0.5695\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 131us/step - loss: 0.9290 - categorical_accuracy: 0.5664 - val_loss: 0.9240 - val_categorical_accuracy: 0.5635\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9296 - categorical_accuracy: 0.5642 - val_loss: 0.9526 - val_categorical_accuracy: 0.5571\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9305 - categorical_accuracy: 0.5611 - val_loss: 0.9569 - val_categorical_accuracy: 0.5640\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 117us/step - loss: 0.9332 - categorical_accuracy: 0.5614 - val_loss: 0.9475 - val_categorical_accuracy: 0.5429\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 147us/step - loss: 0.9306 - categorical_accuracy: 0.5681 - val_loss: 0.9305 - val_categorical_accuracy: 0.5640\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9278 - categorical_accuracy: 0.5675 - val_loss: 0.9363 - val_categorical_accuracy: 0.5667\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 140us/step - loss: 0.9323 - categorical_accuracy: 0.5677 - val_loss: 0.9405 - val_categorical_accuracy: 0.5649\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9270 - categorical_accuracy: 0.5653 - val_loss: 0.9411 - val_categorical_accuracy: 0.5653\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9288 - categorical_accuracy: 0.5656 - val_loss: 0.9665 - val_categorical_accuracy: 0.5690\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9282 - categorical_accuracy: 0.5627 - val_loss: 0.9313 - val_categorical_accuracy: 0.5635\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 56.25%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 403us/step - loss: 1.3305 - categorical_accuracy: 0.4793 - val_loss: 1.2142 - val_categorical_accuracy: 0.4282\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 1.0661 - categorical_accuracy: 0.5172 - val_loss: 0.9903 - val_categorical_accuracy: 0.5167\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 1.0477 - categorical_accuracy: 0.5303 - val_loss: 1.0510 - val_categorical_accuracy: 0.5621\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9983 - categorical_accuracy: 0.5442 - val_loss: 0.9767 - val_categorical_accuracy: 0.5566\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 138us/step - loss: 0.9950 - categorical_accuracy: 0.5397 - val_loss: 1.0298 - val_categorical_accuracy: 0.5530\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 156us/step - loss: 0.9834 - categorical_accuracy: 0.5403 - val_loss: 0.9639 - val_categorical_accuracy: 0.5598\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 172us/step - loss: 0.9663 - categorical_accuracy: 0.5520 - val_loss: 0.9381 - val_categorical_accuracy: 0.5676\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9598 - categorical_accuracy: 0.5527 - val_loss: 0.9411 - val_categorical_accuracy: 0.5640\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9532 - categorical_accuracy: 0.5569 - val_loss: 0.9739 - val_categorical_accuracy: 0.5617\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9542 - categorical_accuracy: 0.5504 - val_loss: 0.9342 - val_categorical_accuracy: 0.5539\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9470 - categorical_accuracy: 0.5557 - val_loss: 0.9345 - val_categorical_accuracy: 0.5608\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9427 - categorical_accuracy: 0.5622 - val_loss: 0.9334 - val_categorical_accuracy: 0.5594\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9411 - categorical_accuracy: 0.5575 - val_loss: 0.9326 - val_categorical_accuracy: 0.5630\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9386 - categorical_accuracy: 0.5589 - val_loss: 0.9267 - val_categorical_accuracy: 0.5667\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 125us/step - loss: 0.9378 - categorical_accuracy: 0.5593 - val_loss: 0.9354 - val_categorical_accuracy: 0.5608\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9366 - categorical_accuracy: 0.5636 - val_loss: 0.9398 - val_categorical_accuracy: 0.5640\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9370 - categorical_accuracy: 0.5637 - val_loss: 0.9353 - val_categorical_accuracy: 0.5690\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9354 - categorical_accuracy: 0.5643 - val_loss: 0.9322 - val_categorical_accuracy: 0.5681\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9332 - categorical_accuracy: 0.5638 - val_loss: 0.9438 - val_categorical_accuracy: 0.5621\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9330 - categorical_accuracy: 0.5673 - val_loss: 0.9259 - val_categorical_accuracy: 0.5685\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9349 - categorical_accuracy: 0.5621 - val_loss: 0.9331 - val_categorical_accuracy: 0.5658\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9329 - categorical_accuracy: 0.5635 - val_loss: 0.9340 - val_categorical_accuracy: 0.5640\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9370 - categorical_accuracy: 0.5630 - val_loss: 0.9351 - val_categorical_accuracy: 0.5681\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9352 - categorical_accuracy: 0.5625 - val_loss: 0.9323 - val_categorical_accuracy: 0.5594\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9325 - categorical_accuracy: 0.5625 - val_loss: 0.9565 - val_categorical_accuracy: 0.5681\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9314 - categorical_accuracy: 0.5640 - val_loss: 0.9328 - val_categorical_accuracy: 0.5681\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9340 - categorical_accuracy: 0.5617 - val_loss: 0.9274 - val_categorical_accuracy: 0.5676\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9366 - categorical_accuracy: 0.5630 - val_loss: 0.9228 - val_categorical_accuracy: 0.5731\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9354 - categorical_accuracy: 0.5637 - val_loss: 0.9302 - val_categorical_accuracy: 0.5663\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9304 - categorical_accuracy: 0.5669 - val_loss: 0.9380 - val_categorical_accuracy: 0.5635\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9316 - categorical_accuracy: 0.5636 - val_loss: 0.9300 - val_categorical_accuracy: 0.5727\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9330 - categorical_accuracy: 0.5650 - val_loss: 0.9273 - val_categorical_accuracy: 0.5727\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9300 - categorical_accuracy: 0.5660 - val_loss: 0.9672 - val_categorical_accuracy: 0.5672\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9308 - categorical_accuracy: 0.5636 - val_loss: 0.9461 - val_categorical_accuracy: 0.5667\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9334 - categorical_accuracy: 0.5643 - val_loss: 0.9317 - val_categorical_accuracy: 0.5681\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9325 - categorical_accuracy: 0.5669 - val_loss: 0.9337 - val_categorical_accuracy: 0.5681\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9353 - categorical_accuracy: 0.5648 - val_loss: 0.9299 - val_categorical_accuracy: 0.5718\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9322 - categorical_accuracy: 0.5658 - val_loss: 0.9520 - val_categorical_accuracy: 0.5461\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 124us/step - loss: 0.9286 - categorical_accuracy: 0.5661 - val_loss: 0.9380 - val_categorical_accuracy: 0.5708\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 167us/step - loss: 0.9316 - categorical_accuracy: 0.5674 - val_loss: 0.9438 - val_categorical_accuracy: 0.5676\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 2s 177us/step - loss: 0.9295 - categorical_accuracy: 0.5677 - val_loss: 0.9238 - val_categorical_accuracy: 0.5640\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 146us/step - loss: 0.9333 - categorical_accuracy: 0.5659 - val_loss: 0.9370 - val_categorical_accuracy: 0.5672\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 155us/step - loss: 0.9285 - categorical_accuracy: 0.5683 - val_loss: 0.9394 - val_categorical_accuracy: 0.5658\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 148us/step - loss: 0.9271 - categorical_accuracy: 0.5646 - val_loss: 0.9284 - val_categorical_accuracy: 0.5598\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 123us/step - loss: 0.9261 - categorical_accuracy: 0.5681 - val_loss: 0.9469 - val_categorical_accuracy: 0.5676\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9358 - categorical_accuracy: 0.5646 - val_loss: 0.9447 - val_categorical_accuracy: 0.5649\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9237 - categorical_accuracy: 0.5712 - val_loss: 0.9295 - val_categorical_accuracy: 0.5681\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9272 - categorical_accuracy: 0.5679 - val_loss: 0.9326 - val_categorical_accuracy: 0.5626\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9293 - categorical_accuracy: 0.5669 - val_loss: 0.9521 - val_categorical_accuracy: 0.5617\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9306 - categorical_accuracy: 0.5674 - val_loss: 0.9437 - val_categorical_accuracy: 0.5585\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 56.25%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 474us/step - loss: 1.1519 - categorical_accuracy: 0.4875 - val_loss: 1.0430 - val_categorical_accuracy: 0.5044\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 1.0185 - categorical_accuracy: 0.5336 - val_loss: 1.0153 - val_categorical_accuracy: 0.5539\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 123us/step - loss: 0.9892 - categorical_accuracy: 0.5418 - val_loss: 0.9587 - val_categorical_accuracy: 0.5397\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9645 - categorical_accuracy: 0.5510 - val_loss: 0.9392 - val_categorical_accuracy: 0.5672\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9613 - categorical_accuracy: 0.5527 - val_loss: 0.9478 - val_categorical_accuracy: 0.5626\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9480 - categorical_accuracy: 0.5570 - val_loss: 0.9298 - val_categorical_accuracy: 0.5626\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9413 - categorical_accuracy: 0.5644 - val_loss: 0.9316 - val_categorical_accuracy: 0.5658\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9408 - categorical_accuracy: 0.5629 - val_loss: 0.9352 - val_categorical_accuracy: 0.5539\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9400 - categorical_accuracy: 0.5637 - val_loss: 0.9466 - val_categorical_accuracy: 0.5603\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9388 - categorical_accuracy: 0.5633 - val_loss: 0.9198 - val_categorical_accuracy: 0.5663\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9386 - categorical_accuracy: 0.5604 - val_loss: 0.9194 - val_categorical_accuracy: 0.5663\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9385 - categorical_accuracy: 0.5650 - val_loss: 0.9290 - val_categorical_accuracy: 0.5644\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9423 - categorical_accuracy: 0.5618 - val_loss: 0.9334 - val_categorical_accuracy: 0.5630\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 116us/step - loss: 0.9391 - categorical_accuracy: 0.5608 - val_loss: 0.9361 - val_categorical_accuracy: 0.5658\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 123us/step - loss: 0.9367 - categorical_accuracy: 0.5630 - val_loss: 0.9249 - val_categorical_accuracy: 0.5630\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 2s 184us/step - loss: 0.9359 - categorical_accuracy: 0.5653 - val_loss: 0.9236 - val_categorical_accuracy: 0.5658\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 170us/step - loss: 0.9397 - categorical_accuracy: 0.5591 - val_loss: 0.9308 - val_categorical_accuracy: 0.5640\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 145us/step - loss: 0.9364 - categorical_accuracy: 0.5649 - val_loss: 0.9315 - val_categorical_accuracy: 0.5676\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 141us/step - loss: 0.9379 - categorical_accuracy: 0.5616 - val_loss: 0.9204 - val_categorical_accuracy: 0.5649\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 96us/step - loss: 0.9353 - categorical_accuracy: 0.5665 - val_loss: 0.9293 - val_categorical_accuracy: 0.5690\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9345 - categorical_accuracy: 0.5609 - val_loss: 0.9303 - val_categorical_accuracy: 0.5690\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9324 - categorical_accuracy: 0.5659 - val_loss: 0.9257 - val_categorical_accuracy: 0.5690\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9356 - categorical_accuracy: 0.5636 - val_loss: 0.9381 - val_categorical_accuracy: 0.5630\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9364 - categorical_accuracy: 0.5659 - val_loss: 0.9236 - val_categorical_accuracy: 0.5699\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9345 - categorical_accuracy: 0.5648 - val_loss: 0.9271 - val_categorical_accuracy: 0.5672\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9353 - categorical_accuracy: 0.5627 - val_loss: 0.9368 - val_categorical_accuracy: 0.5718\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9349 - categorical_accuracy: 0.5643 - val_loss: 0.9465 - val_categorical_accuracy: 0.5612\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 138us/step - loss: 0.9310 - categorical_accuracy: 0.5632 - val_loss: 0.9365 - val_categorical_accuracy: 0.5635\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9312 - categorical_accuracy: 0.5633 - val_loss: 0.9250 - val_categorical_accuracy: 0.5676\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9307 - categorical_accuracy: 0.5679 - val_loss: 0.9345 - val_categorical_accuracy: 0.5649\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9307 - categorical_accuracy: 0.5663 - val_loss: 0.9266 - val_categorical_accuracy: 0.5750\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9279 - categorical_accuracy: 0.5674 - val_loss: 0.9271 - val_categorical_accuracy: 0.5754\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 110us/step - loss: 0.9300 - categorical_accuracy: 0.5660 - val_loss: 0.9304 - val_categorical_accuracy: 0.5658\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 160us/step - loss: 0.9287 - categorical_accuracy: 0.5673 - val_loss: 0.9269 - val_categorical_accuracy: 0.5653\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 144us/step - loss: 0.9337 - categorical_accuracy: 0.5627 - val_loss: 0.9429 - val_categorical_accuracy: 0.5667\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 134us/step - loss: 0.9311 - categorical_accuracy: 0.5644 - val_loss: 0.9311 - val_categorical_accuracy: 0.5640\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 123us/step - loss: 0.9268 - categorical_accuracy: 0.5681 - val_loss: 0.9318 - val_categorical_accuracy: 0.5708\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 114us/step - loss: 0.9312 - categorical_accuracy: 0.5656 - val_loss: 0.9348 - val_categorical_accuracy: 0.5695\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 142us/step - loss: 0.9283 - categorical_accuracy: 0.5703 - val_loss: 0.9266 - val_categorical_accuracy: 0.5608\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 116us/step - loss: 0.9297 - categorical_accuracy: 0.5671 - val_loss: 0.9459 - val_categorical_accuracy: 0.5608\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 111us/step - loss: 0.9286 - categorical_accuracy: 0.5682 - val_loss: 0.9339 - val_categorical_accuracy: 0.5663\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9296 - categorical_accuracy: 0.5661 - val_loss: 0.9382 - val_categorical_accuracy: 0.5548\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 105us/step - loss: 0.9310 - categorical_accuracy: 0.5682 - val_loss: 0.9299 - val_categorical_accuracy: 0.5699\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9287 - categorical_accuracy: 0.5673 - val_loss: 0.9403 - val_categorical_accuracy: 0.5653\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9284 - categorical_accuracy: 0.5665 - val_loss: 0.9548 - val_categorical_accuracy: 0.5511\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9281 - categorical_accuracy: 0.5668 - val_loss: 0.9383 - val_categorical_accuracy: 0.5663\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 117us/step - loss: 0.9257 - categorical_accuracy: 0.5683 - val_loss: 0.9247 - val_categorical_accuracy: 0.5681\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9239 - categorical_accuracy: 0.5679 - val_loss: 0.9435 - val_categorical_accuracy: 0.5626\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9288 - categorical_accuracy: 0.5669 - val_loss: 0.9409 - val_categorical_accuracy: 0.5640\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9277 - categorical_accuracy: 0.5668 - val_loss: 0.9524 - val_categorical_accuracy: 0.5727\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 62.5%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 420us/step - loss: 1.1886 - categorical_accuracy: 0.4686 - val_loss: 0.9957 - val_categorical_accuracy: 0.5511\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 1.0230 - categorical_accuracy: 0.5297 - val_loss: 0.9643 - val_categorical_accuracy: 0.5323\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9895 - categorical_accuracy: 0.5472 - val_loss: 0.9882 - val_categorical_accuracy: 0.5488\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9686 - categorical_accuracy: 0.5517 - val_loss: 0.9397 - val_categorical_accuracy: 0.5667\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 105us/step - loss: 0.9587 - categorical_accuracy: 0.5526 - val_loss: 0.9497 - val_categorical_accuracy: 0.5493\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9507 - categorical_accuracy: 0.5578 - val_loss: 0.9393 - val_categorical_accuracy: 0.5571\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9497 - categorical_accuracy: 0.5572 - val_loss: 0.9428 - val_categorical_accuracy: 0.5681\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9532 - categorical_accuracy: 0.5552 - val_loss: 0.9377 - val_categorical_accuracy: 0.5502\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9455 - categorical_accuracy: 0.5606 - val_loss: 0.9290 - val_categorical_accuracy: 0.5672\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 2s 186us/step - loss: 0.9442 - categorical_accuracy: 0.5603 - val_loss: 0.9447 - val_categorical_accuracy: 0.5676\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 129us/step - loss: 0.9429 - categorical_accuracy: 0.5569 - val_loss: 0.9266 - val_categorical_accuracy: 0.5663\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9439 - categorical_accuracy: 0.5601 - val_loss: 0.9377 - val_categorical_accuracy: 0.5608\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 98us/step - loss: 0.9373 - categorical_accuracy: 0.5633 - val_loss: 0.9256 - val_categorical_accuracy: 0.5644\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9387 - categorical_accuracy: 0.5591 - val_loss: 0.9307 - val_categorical_accuracy: 0.5685\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 124us/step - loss: 0.9354 - categorical_accuracy: 0.5628 - val_loss: 0.9315 - val_categorical_accuracy: 0.5644\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 2s 173us/step - loss: 0.9366 - categorical_accuracy: 0.5635 - val_loss: 0.9260 - val_categorical_accuracy: 0.5704\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 2s 240us/step - loss: 0.9413 - categorical_accuracy: 0.5626 - val_loss: 0.9292 - val_categorical_accuracy: 0.5699\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 135us/step - loss: 0.9376 - categorical_accuracy: 0.5630 - val_loss: 0.9255 - val_categorical_accuracy: 0.5672\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 153us/step - loss: 0.9362 - categorical_accuracy: 0.5611 - val_loss: 0.9265 - val_categorical_accuracy: 0.5621\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 125us/step - loss: 0.9344 - categorical_accuracy: 0.5635 - val_loss: 0.9326 - val_categorical_accuracy: 0.5640\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 105us/step - loss: 0.9355 - categorical_accuracy: 0.5577 - val_loss: 0.9237 - val_categorical_accuracy: 0.5658\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 104us/step - loss: 0.9345 - categorical_accuracy: 0.5663 - val_loss: 0.9360 - val_categorical_accuracy: 0.5676\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9345 - categorical_accuracy: 0.5603 - val_loss: 0.9284 - val_categorical_accuracy: 0.5630\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 116us/step - loss: 0.9344 - categorical_accuracy: 0.5621 - val_loss: 0.9397 - val_categorical_accuracy: 0.5608\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9350 - categorical_accuracy: 0.5626 - val_loss: 0.9254 - val_categorical_accuracy: 0.5663\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9338 - categorical_accuracy: 0.5624 - val_loss: 0.9374 - val_categorical_accuracy: 0.5653\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 116us/step - loss: 0.9339 - categorical_accuracy: 0.5606 - val_loss: 0.9369 - val_categorical_accuracy: 0.5713\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 128us/step - loss: 0.9382 - categorical_accuracy: 0.5597 - val_loss: 0.9326 - val_categorical_accuracy: 0.5676\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 138us/step - loss: 0.9317 - categorical_accuracy: 0.5637 - val_loss: 0.9302 - val_categorical_accuracy: 0.5663 0.9299 - categorical_accuracy: 0.\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 118us/step - loss: 0.9323 - categorical_accuracy: 0.5645 - val_loss: 0.9344 - val_categorical_accuracy: 0.5704\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 103us/step - loss: 0.9334 - categorical_accuracy: 0.5630 - val_loss: 0.9324 - val_categorical_accuracy: 0.5649\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9349 - categorical_accuracy: 0.5642 - val_loss: 0.9381 - val_categorical_accuracy: 0.5502\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 134us/step - loss: 0.9327 - categorical_accuracy: 0.5649 - val_loss: 0.9315 - val_categorical_accuracy: 0.5690\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 111us/step - loss: 0.9317 - categorical_accuracy: 0.5632 - val_loss: 0.9346 - val_categorical_accuracy: 0.5644\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 2s 216us/step - loss: 0.9278 - categorical_accuracy: 0.5687 - val_loss: 0.9307 - val_categorical_accuracy: 0.5612\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 2s 179us/step - loss: 0.9306 - categorical_accuracy: 0.5608 - val_loss: 0.9346 - val_categorical_accuracy: 0.5575\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 138us/step - loss: 0.9287 - categorical_accuracy: 0.5649 - val_loss: 0.9284 - val_categorical_accuracy: 0.5676\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 151us/step - loss: 0.9324 - categorical_accuracy: 0.5578 - val_loss: 0.9278 - val_categorical_accuracy: 0.5667\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9362 - categorical_accuracy: 0.5674 - val_loss: 0.9506 - val_categorical_accuracy: 0.5658\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9275 - categorical_accuracy: 0.5660 - val_loss: 0.9297 - val_categorical_accuracy: 0.5672\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9282 - categorical_accuracy: 0.5626 - val_loss: 0.9308 - val_categorical_accuracy: 0.5676\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9311 - categorical_accuracy: 0.5649 - val_loss: 0.9347 - val_categorical_accuracy: 0.5704\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9285 - categorical_accuracy: 0.5673 - val_loss: 0.9636 - val_categorical_accuracy: 0.5672\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 128us/step - loss: 0.9317 - categorical_accuracy: 0.5659 - val_loss: 0.9460 - val_categorical_accuracy: 0.5502\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 161us/step - loss: 0.9331 - categorical_accuracy: 0.5616 - val_loss: 0.9377 - val_categorical_accuracy: 0.5667\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 151us/step - loss: 0.9264 - categorical_accuracy: 0.5661 - val_loss: 0.9365 - val_categorical_accuracy: 0.5640\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 121us/step - loss: 0.9286 - categorical_accuracy: 0.5646 - val_loss: 0.9305 - val_categorical_accuracy: 0.5713\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 149us/step - loss: 0.9293 - categorical_accuracy: 0.5653 - val_loss: 0.9256 - val_categorical_accuracy: 0.5635\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 130us/step - loss: 0.9277 - categorical_accuracy: 0.5608 - val_loss: 0.9616 - val_categorical_accuracy: 0.5667\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 151us/step - loss: 0.9303 - categorical_accuracy: 0.5621 - val_loss: 0.9368 - val_categorical_accuracy: 0.5704\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 53.125%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 5s 579us/step - loss: 1.3299 - categorical_accuracy: 0.4765 - val_loss: 1.0342 - val_categorical_accuracy: 0.5433\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 2s 231us/step - loss: 1.0982 - categorical_accuracy: 0.5242 - val_loss: 1.0336 - val_categorical_accuracy: 0.5241\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 151us/step - loss: 1.0689 - categorical_accuracy: 0.5323 - val_loss: 1.1536 - val_categorical_accuracy: 0.4663\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 155us/step - loss: 1.0247 - categorical_accuracy: 0.5318 - val_loss: 0.9733 - val_categorical_accuracy: 0.5543\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 1.0247 - categorical_accuracy: 0.5332 - val_loss: 0.9759 - val_categorical_accuracy: 0.5589\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 2s 207us/step - loss: 0.9781 - categorical_accuracy: 0.5486 - val_loss: 0.9379 - val_categorical_accuracy: 0.5649\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9828 - categorical_accuracy: 0.5497 - val_loss: 1.0257 - val_categorical_accuracy: 0.5103\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9831 - categorical_accuracy: 0.5488 - val_loss: 0.9314 - val_categorical_accuracy: 0.5649\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 171us/step - loss: 0.9713 - categorical_accuracy: 0.5479 - val_loss: 0.9313 - val_categorical_accuracy: 0.5612\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 128us/step - loss: 0.9499 - categorical_accuracy: 0.5583 - val_loss: 0.9430 - val_categorical_accuracy: 0.5630\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 131us/step - loss: 0.9466 - categorical_accuracy: 0.5628 - val_loss: 0.9494 - val_categorical_accuracy: 0.5502\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 102us/step - loss: 0.9460 - categorical_accuracy: 0.5605 - val_loss: 0.9359 - val_categorical_accuracy: 0.5681\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9437 - categorical_accuracy: 0.5611 - val_loss: 0.9413 - val_categorical_accuracy: 0.5543\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9407 - categorical_accuracy: 0.5627 - val_loss: 0.9256 - val_categorical_accuracy: 0.5704\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9390 - categorical_accuracy: 0.5616 - val_loss: 0.9337 - val_categorical_accuracy: 0.5708\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9389 - categorical_accuracy: 0.5613 - val_loss: 0.9271 - val_categorical_accuracy: 0.5685\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9373 - categorical_accuracy: 0.5604 - val_loss: 0.9390 - val_categorical_accuracy: 0.5552\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9387 - categorical_accuracy: 0.5636 - val_loss: 0.9326 - val_categorical_accuracy: 0.5557\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9329 - categorical_accuracy: 0.5637 - val_loss: 0.9208 - val_categorical_accuracy: 0.5658\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9348 - categorical_accuracy: 0.5666 - val_loss: 0.9322 - val_categorical_accuracy: 0.5658\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9350 - categorical_accuracy: 0.5643 - val_loss: 0.9272 - val_categorical_accuracy: 0.5626\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9413 - categorical_accuracy: 0.5611 - val_loss: 0.9390 - val_categorical_accuracy: 0.5640\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9355 - categorical_accuracy: 0.5638 - val_loss: 0.9429 - val_categorical_accuracy: 0.5626\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9328 - categorical_accuracy: 0.5658 - val_loss: 0.9440 - val_categorical_accuracy: 0.5644\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9386 - categorical_accuracy: 0.5638 - val_loss: 0.9297 - val_categorical_accuracy: 0.5649\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9378 - categorical_accuracy: 0.5640 - val_loss: 0.9504 - val_categorical_accuracy: 0.5644\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9345 - categorical_accuracy: 0.5679 - val_loss: 0.9392 - val_categorical_accuracy: 0.5644\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9357 - categorical_accuracy: 0.5684 - val_loss: 0.9384 - val_categorical_accuracy: 0.5722\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9347 - categorical_accuracy: 0.5636 - val_loss: 0.9388 - val_categorical_accuracy: 0.5649\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9358 - categorical_accuracy: 0.5645 - val_loss: 0.9470 - val_categorical_accuracy: 0.5672\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9338 - categorical_accuracy: 0.5634 - val_loss: 0.9464 - val_categorical_accuracy: 0.5621\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9327 - categorical_accuracy: 0.5652 - val_loss: 0.9580 - val_categorical_accuracy: 0.5672\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9353 - categorical_accuracy: 0.5649 - val_loss: 0.9432 - val_categorical_accuracy: 0.5695\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9346 - categorical_accuracy: 0.5624 - val_loss: 0.9473 - val_categorical_accuracy: 0.5676\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9277 - categorical_accuracy: 0.5648 - val_loss: 0.9309 - val_categorical_accuracy: 0.5672\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9307 - categorical_accuracy: 0.5668 - val_loss: 0.9442 - val_categorical_accuracy: 0.5630\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9324 - categorical_accuracy: 0.5656 - val_loss: 0.9386 - val_categorical_accuracy: 0.5630\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9315 - categorical_accuracy: 0.5664 - val_loss: 0.9381 - val_categorical_accuracy: 0.5617\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9279 - categorical_accuracy: 0.5697 - val_loss: 0.9325 - val_categorical_accuracy: 0.5695\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9287 - categorical_accuracy: 0.5681 - val_loss: 0.9370 - val_categorical_accuracy: 0.5598\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9268 - categorical_accuracy: 0.5690 - val_loss: 0.9275 - val_categorical_accuracy: 0.5672\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9334 - categorical_accuracy: 0.5675 - val_loss: 0.9384 - val_categorical_accuracy: 0.5617\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9345 - categorical_accuracy: 0.5638 - val_loss: 0.9625 - val_categorical_accuracy: 0.5534\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9277 - categorical_accuracy: 0.5676 - val_loss: 0.9301 - val_categorical_accuracy: 0.5667\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9285 - categorical_accuracy: 0.5668 - val_loss: 0.9472 - val_categorical_accuracy: 0.5658\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9278 - categorical_accuracy: 0.5685 - val_loss: 0.9408 - val_categorical_accuracy: 0.5562\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9276 - categorical_accuracy: 0.5660 - val_loss: 0.9353 - val_categorical_accuracy: 0.5676\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9305 - categorical_accuracy: 0.5672 - val_loss: 0.9378 - val_categorical_accuracy: 0.5663\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9276 - categorical_accuracy: 0.5699 - val_loss: 0.9849 - val_categorical_accuracy: 0.5530\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9267 - categorical_accuracy: 0.5675 - val_loss: 0.9408 - val_categorical_accuracy: 0.5649\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 59.375%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 420us/step - loss: 1.3473 - categorical_accuracy: 0.4917 - val_loss: 1.0349 - val_categorical_accuracy: 0.5520\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 1.0923 - categorical_accuracy: 0.5196 - val_loss: 0.9793 - val_categorical_accuracy: 0.5589\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 1.0423 - categorical_accuracy: 0.5258 - val_loss: 0.9601 - val_categorical_accuracy: 0.5626\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 1.0360 - categorical_accuracy: 0.5347 - val_loss: 0.9578 - val_categorical_accuracy: 0.5438\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9904 - categorical_accuracy: 0.5417 - val_loss: 0.9887 - val_categorical_accuracy: 0.5236\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9914 - categorical_accuracy: 0.5433 - val_loss: 1.0383 - val_categorical_accuracy: 0.5635\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9843 - categorical_accuracy: 0.5426 - val_loss: 1.0092 - val_categorical_accuracy: 0.5429\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9645 - categorical_accuracy: 0.5489 - val_loss: 0.9441 - val_categorical_accuracy: 0.5530\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9561 - categorical_accuracy: 0.5559 - val_loss: 0.9470 - val_categorical_accuracy: 0.5502\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9567 - categorical_accuracy: 0.5548 - val_loss: 0.9657 - val_categorical_accuracy: 0.5447\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9496 - categorical_accuracy: 0.5569 - val_loss: 0.9406 - val_categorical_accuracy: 0.5548\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 100us/step - loss: 0.9477 - categorical_accuracy: 0.5587 - val_loss: 0.9377 - val_categorical_accuracy: 0.5608\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 101us/step - loss: 0.9468 - categorical_accuracy: 0.5606 - val_loss: 0.9373 - val_categorical_accuracy: 0.5653\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 94us/step - loss: 0.9376 - categorical_accuracy: 0.5656 - val_loss: 0.9273 - val_categorical_accuracy: 0.5635\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 88us/step - loss: 0.9336 - categorical_accuracy: 0.5671 - val_loss: 0.9223 - val_categorical_accuracy: 0.5663\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 91us/step - loss: 0.9362 - categorical_accuracy: 0.5666 - val_loss: 0.9248 - val_categorical_accuracy: 0.5663\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9365 - categorical_accuracy: 0.5633 - val_loss: 0.9449 - val_categorical_accuracy: 0.5672\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9346 - categorical_accuracy: 0.5651 - val_loss: 0.9437 - val_categorical_accuracy: 0.5598\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9357 - categorical_accuracy: 0.5643 - val_loss: 0.9256 - val_categorical_accuracy: 0.5649\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9353 - categorical_accuracy: 0.5616 - val_loss: 0.9317 - val_categorical_accuracy: 0.5663\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9325 - categorical_accuracy: 0.5677 - val_loss: 0.9285 - val_categorical_accuracy: 0.5635\n",
      "Epoch 22/50\n",
      "8724/8724 [==============================] - 1s 86us/step - loss: 0.9306 - categorical_accuracy: 0.5634 - val_loss: 0.9465 - val_categorical_accuracy: 0.5612\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9329 - categorical_accuracy: 0.5655 - val_loss: 0.9420 - val_categorical_accuracy: 0.5608\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 81us/step - loss: 0.9389 - categorical_accuracy: 0.5630 - val_loss: 0.9300 - val_categorical_accuracy: 0.5685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9322 - categorical_accuracy: 0.5655 - val_loss: 0.9228 - val_categorical_accuracy: 0.5667\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9343 - categorical_accuracy: 0.5652 - val_loss: 0.9294 - val_categorical_accuracy: 0.5676\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9343 - categorical_accuracy: 0.5663 - val_loss: 0.9450 - val_categorical_accuracy: 0.5699\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9330 - categorical_accuracy: 0.5669 - val_loss: 0.9400 - val_categorical_accuracy: 0.5598\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9321 - categorical_accuracy: 0.5636 - val_loss: 0.9280 - val_categorical_accuracy: 0.5621\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9320 - categorical_accuracy: 0.5624 - val_loss: 0.9430 - val_categorical_accuracy: 0.5663\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9298 - categorical_accuracy: 0.5671 - val_loss: 0.9384 - val_categorical_accuracy: 0.5653\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 85us/step - loss: 0.9279 - categorical_accuracy: 0.5688 - val_loss: 0.9304 - val_categorical_accuracy: 0.5621\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9302 - categorical_accuracy: 0.5657 - val_loss: 0.9339 - val_categorical_accuracy: 0.5685\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9287 - categorical_accuracy: 0.5640 - val_loss: 0.9525 - val_categorical_accuracy: 0.5603\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9336 - categorical_accuracy: 0.5657 - val_loss: 0.9295 - val_categorical_accuracy: 0.5630\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9306 - categorical_accuracy: 0.5660 - val_loss: 0.9360 - val_categorical_accuracy: 0.5626\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 87us/step - loss: 0.9292 - categorical_accuracy: 0.5653 - val_loss: 0.9378 - val_categorical_accuracy: 0.5635\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9322 - categorical_accuracy: 0.5651 - val_loss: 0.9437 - val_categorical_accuracy: 0.5626\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9277 - categorical_accuracy: 0.5668 - val_loss: 0.9388 - val_categorical_accuracy: 0.5644\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9332 - categorical_accuracy: 0.5604 - val_loss: 0.9322 - val_categorical_accuracy: 0.5603\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9285 - categorical_accuracy: 0.5640 - val_loss: 0.9323 - val_categorical_accuracy: 0.5672\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9261 - categorical_accuracy: 0.5689 - val_loss: 0.9444 - val_categorical_accuracy: 0.5612\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9297 - categorical_accuracy: 0.5676 - val_loss: 0.9434 - val_categorical_accuracy: 0.5608\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9333 - categorical_accuracy: 0.5649 - val_loss: 0.9402 - val_categorical_accuracy: 0.5585\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9292 - categorical_accuracy: 0.5690 - val_loss: 0.9416 - val_categorical_accuracy: 0.5612\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 82us/step - loss: 0.9284 - categorical_accuracy: 0.5672 - val_loss: 0.9329 - val_categorical_accuracy: 0.5658\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9235 - categorical_accuracy: 0.5675 - val_loss: 0.9350 - val_categorical_accuracy: 0.5685\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 83us/step - loss: 0.9261 - categorical_accuracy: 0.5703 - val_loss: 0.9419 - val_categorical_accuracy: 0.5571\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9291 - categorical_accuracy: 0.5687 - val_loss: 0.9394 - val_categorical_accuracy: 0.5630\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 84us/step - loss: 0.9241 - categorical_accuracy: 0.5722 - val_loss: 0.9519 - val_categorical_accuracy: 0.5653\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 50.0%\n",
      "Train on 8724 samples, validate on 2181 samples\n",
      "Epoch 1/50\n",
      "8724/8724 [==============================] - 4s 442us/step - loss: 1.2765 - categorical_accuracy: 0.4825 - val_loss: 1.1781 - val_categorical_accuracy: 0.5053\n",
      "Epoch 2/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 1.1017 - categorical_accuracy: 0.5177 - val_loss: 0.9925 - val_categorical_accuracy: 0.5461\n",
      "Epoch 3/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 1.0628 - categorical_accuracy: 0.5306 - val_loss: 0.9875 - val_categorical_accuracy: 0.5653\n",
      "Epoch 4/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 1.0473 - categorical_accuracy: 0.5269 - val_loss: 0.9741 - val_categorical_accuracy: 0.5465\n",
      "Epoch 5/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9991 - categorical_accuracy: 0.5369 - val_loss: 0.9519 - val_categorical_accuracy: 0.5539\n",
      "Epoch 6/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9728 - categorical_accuracy: 0.5485 - val_loss: 0.9527 - val_categorical_accuracy: 0.5424\n",
      "Epoch 7/50\n",
      "8724/8724 [==============================] - 1s 90us/step - loss: 0.9801 - categorical_accuracy: 0.5465 - val_loss: 0.9299 - val_categorical_accuracy: 0.5653\n",
      "Epoch 8/50\n",
      "8724/8724 [==============================] - 1s 95us/step - loss: 0.9529 - categorical_accuracy: 0.5563 - val_loss: 0.9478 - val_categorical_accuracy: 0.5406\n",
      "Epoch 9/50\n",
      "8724/8724 [==============================] - 1s 93us/step - loss: 0.9565 - categorical_accuracy: 0.5531 - val_loss: 0.9413 - val_categorical_accuracy: 0.5704\n",
      "Epoch 10/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9517 - categorical_accuracy: 0.5598 - val_loss: 0.9654 - val_categorical_accuracy: 0.5323\n",
      "Epoch 11/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9502 - categorical_accuracy: 0.5555 - val_loss: 0.9665 - val_categorical_accuracy: 0.5424\n",
      "Epoch 12/50\n",
      "8724/8724 [==============================] - 1s 131us/step - loss: 0.9440 - categorical_accuracy: 0.5562 - val_loss: 0.9308 - val_categorical_accuracy: 0.5640\n",
      "Epoch 13/50\n",
      "8724/8724 [==============================] - 1s 128us/step - loss: 0.9482 - categorical_accuracy: 0.5594 - val_loss: 0.9378 - val_categorical_accuracy: 0.5649\n",
      "Epoch 14/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9385 - categorical_accuracy: 0.5608 - val_loss: 0.9582 - val_categorical_accuracy: 0.5562\n",
      "Epoch 15/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9370 - categorical_accuracy: 0.5629 - val_loss: 0.9235 - val_categorical_accuracy: 0.5635\n",
      "Epoch 16/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9375 - categorical_accuracy: 0.5613 - val_loss: 0.9286 - val_categorical_accuracy: 0.5690\n",
      "Epoch 17/50\n",
      "8724/8724 [==============================] - 1s 120us/step - loss: 0.9326 - categorical_accuracy: 0.5660 - val_loss: 0.9294 - val_categorical_accuracy: 0.5663\n",
      "Epoch 18/50\n",
      "8724/8724 [==============================] - 1s 131us/step - loss: 0.9343 - categorical_accuracy: 0.5646 - val_loss: 0.9353 - val_categorical_accuracy: 0.5649\n",
      "Epoch 19/50\n",
      "8724/8724 [==============================] - 1s 121us/step - loss: 0.9327 - categorical_accuracy: 0.5648 - val_loss: 0.9285 - val_categorical_accuracy: 0.5740\n",
      "Epoch 20/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9371 - categorical_accuracy: 0.5622 - val_loss: 0.9545 - val_categorical_accuracy: 0.5621\n",
      "Epoch 21/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9350 - categorical_accuracy: 0.5595 - val_loss: 0.9250 - val_categorical_accuracy: 0.5621\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724/8724 [==============================] - 1s 118us/step - loss: 0.9370 - categorical_accuracy: 0.5630 - val_loss: 0.9256 - val_categorical_accuracy: 0.5667\n",
      "Epoch 23/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9345 - categorical_accuracy: 0.5648 - val_loss: 0.9304 - val_categorical_accuracy: 0.5580\n",
      "Epoch 24/50\n",
      "8724/8724 [==============================] - 1s 122us/step - loss: 0.9353 - categorical_accuracy: 0.5594 - val_loss: 0.9402 - val_categorical_accuracy: 0.5603\n",
      "Epoch 25/50\n",
      "8724/8724 [==============================] - 1s 116us/step - loss: 0.9366 - categorical_accuracy: 0.5619 - val_loss: 0.9340 - val_categorical_accuracy: 0.5589\n",
      "Epoch 26/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9373 - categorical_accuracy: 0.5617 - val_loss: 0.9273 - val_categorical_accuracy: 0.5695\n",
      "Epoch 27/50\n",
      "8724/8724 [==============================] - 1s 110us/step - loss: 0.9308 - categorical_accuracy: 0.5625 - val_loss: 0.9288 - val_categorical_accuracy: 0.5626\n",
      "Epoch 28/50\n",
      "8724/8724 [==============================] - 1s 107us/step - loss: 0.9317 - categorical_accuracy: 0.5658 - val_loss: 0.9340 - val_categorical_accuracy: 0.5658\n",
      "Epoch 29/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9332 - categorical_accuracy: 0.5641 - val_loss: 0.9348 - val_categorical_accuracy: 0.5644\n",
      "Epoch 30/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9314 - categorical_accuracy: 0.5652 - val_loss: 0.9417 - val_categorical_accuracy: 0.5663\n",
      "Epoch 31/50\n",
      "8724/8724 [==============================] - 1s 115us/step - loss: 0.9354 - categorical_accuracy: 0.5628 - val_loss: 0.9412 - val_categorical_accuracy: 0.5571\n",
      "Epoch 32/50\n",
      "8724/8724 [==============================] - 1s 113us/step - loss: 0.9347 - categorical_accuracy: 0.5653 - val_loss: 0.9442 - val_categorical_accuracy: 0.5704\n",
      "Epoch 33/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9324 - categorical_accuracy: 0.5638 - val_loss: 0.9509 - val_categorical_accuracy: 0.5539\n",
      "Epoch 34/50\n",
      "8724/8724 [==============================] - 1s 121us/step - loss: 0.9326 - categorical_accuracy: 0.5649 - val_loss: 0.9353 - val_categorical_accuracy: 0.5548\n",
      "Epoch 35/50\n",
      "8724/8724 [==============================] - 1s 119us/step - loss: 0.9313 - categorical_accuracy: 0.5657 - val_loss: 0.9356 - val_categorical_accuracy: 0.5685\n",
      "Epoch 36/50\n",
      "8724/8724 [==============================] - 1s 123us/step - loss: 0.9304 - categorical_accuracy: 0.5663 - val_loss: 0.9340 - val_categorical_accuracy: 0.5562\n",
      "Epoch 37/50\n",
      "8724/8724 [==============================] - 1s 126us/step - loss: 0.9342 - categorical_accuracy: 0.5642 - val_loss: 0.9340 - val_categorical_accuracy: 0.5598\n",
      "Epoch 38/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9313 - categorical_accuracy: 0.5672 - val_loss: 0.9425 - val_categorical_accuracy: 0.5585\n",
      "Epoch 39/50\n",
      "8724/8724 [==============================] - 1s 118us/step - loss: 0.9278 - categorical_accuracy: 0.5702 - val_loss: 0.9289 - val_categorical_accuracy: 0.5626\n",
      "Epoch 40/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9280 - categorical_accuracy: 0.5680 - val_loss: 0.9388 - val_categorical_accuracy: 0.5617\n",
      "Epoch 41/50\n",
      "8724/8724 [==============================] - 1s 110us/step - loss: 0.9305 - categorical_accuracy: 0.5650 - val_loss: 0.9398 - val_categorical_accuracy: 0.5658\n",
      "Epoch 42/50\n",
      "8724/8724 [==============================] - 1s 112us/step - loss: 0.9302 - categorical_accuracy: 0.5699 - val_loss: 0.9336 - val_categorical_accuracy: 0.5626\n",
      "Epoch 43/50\n",
      "8724/8724 [==============================] - 1s 109us/step - loss: 0.9329 - categorical_accuracy: 0.5667 - val_loss: 0.9426 - val_categorical_accuracy: 0.5635\n",
      "Epoch 44/50\n",
      "8724/8724 [==============================] - 1s 106us/step - loss: 0.9259 - categorical_accuracy: 0.5739 - val_loss: 0.9528 - val_categorical_accuracy: 0.5603\n",
      "Epoch 45/50\n",
      "8724/8724 [==============================] - 1s 151us/step - loss: 0.9266 - categorical_accuracy: 0.5692 - val_loss: 0.9393 - val_categorical_accuracy: 0.5644\n",
      "Epoch 46/50\n",
      "8724/8724 [==============================] - 1s 152us/step - loss: 0.9307 - categorical_accuracy: 0.5683 - val_loss: 0.9361 - val_categorical_accuracy: 0.5676\n",
      "Epoch 47/50\n",
      "8724/8724 [==============================] - 1s 99us/step - loss: 0.9319 - categorical_accuracy: 0.5632 - val_loss: 0.9352 - val_categorical_accuracy: 0.5612\n",
      "Epoch 48/50\n",
      "8724/8724 [==============================] - 1s 97us/step - loss: 0.9322 - categorical_accuracy: 0.5685 - val_loss: 0.9440 - val_categorical_accuracy: 0.5626\n",
      "Epoch 49/50\n",
      "8724/8724 [==============================] - 1s 89us/step - loss: 0.9269 - categorical_accuracy: 0.5705 - val_loss: 0.9453 - val_categorical_accuracy: 0.5626\n",
      "Epoch 50/50\n",
      "8724/8724 [==============================] - 1s 92us/step - loss: 0.9324 - categorical_accuracy: 0.5659 - val_loss: 0.9503 - val_categorical_accuracy: 0.5603\n",
      "Done\n",
      "Neural Network Prediction Accuracy (FIFA): 59.375%\n"
     ]
    }
   ],
   "source": [
    "sample_fifa = [np.nan]*10\n",
    "\n",
    "for sample in range(len(sample_fifa)):\n",
    "    model = run_nn(X_train_fifa, y_train_fifa, e=50)\n",
    "    \n",
    "    sample_fifa[sample] = test_nn(model, X_test_fifa, y_test_fifa, \"FIFA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53.125, 51.5625, 51.5625, 56.25, 56.25, 62.5, 53.125, 59.375, 50.0, 59.375]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_fifa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIFA Average Test Accuracy (10 Identical Neural Networks): 55.3125%\n"
     ]
    }
   ],
   "source": [
    "print(\"FIFA Average Test Accuracy (10 Identical Neural Networks): {0}%\".format(np.mean(sample_fifa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
